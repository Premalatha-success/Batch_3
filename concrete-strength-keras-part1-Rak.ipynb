{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part 1 of this notebook, a regression model will be built using Keras deep learning framework to predict the compressive strength of concrete, based on its ingredients. The model will be trained several times with different network properties such as the number of epochs and hidden layers, to increase the model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center> Building a Concrete Compressive Strength Model using Keras Framework </center></h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Concrete Ingredients:</strong>\n",
    "<ol type=\"1\">\n",
    "  <li>Cement</li>\n",
    "  <li>Blast Furnace Slag</li>\n",
    "  <li>Fly Ash</li>\n",
    "  <li>Water</li>\n",
    "  <li>Superplasticizer</li>\n",
    "  <li>Coarse Aggregate</li>\n",
    "  <li>Fine Aggregate</li>\n",
    "  <li>Age</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. OBTAIN - Obtain Data from its Source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shape of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 1030 rows and 9 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SCRUB - Clean / Preprocess Data to Format that Machine Understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                float64\n",
       "Blast Furnace Slag    float64\n",
       "Fly Ash               float64\n",
       "Water                 float64\n",
       "Superplasticizer      float64\n",
       "Coarse Aggregate      float64\n",
       "Fine Aggregate        float64\n",
       "Age                     int64\n",
       "Strength              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks very clean; no missing data and all data is in numerical form. \n",
    "\n",
    "Nothing much here, lets move to our next step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. EXPLORE - Find Significant Patterns and Trends using Statistical Method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/MAAAIkCAYAAABSsHuAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC4j0lEQVR4nOzdd1gUVxcG8HfpCAiCUlQUEEHsAhawIBawgyXRWBCxxt4NUewGNRYsUZNYUGPsJcbwoVhQ7IqgRhEFQSwgFkRApe1+fxg3riwr6OKWvL888zzu3TszZyY7wNl75o5AJBKJQEREREREREQqQ0PRARARERERERFR6TCZJyIiIiIiIlIxTOaJiIiIiIiIVAyTeSIiIiIiIiIVw2SeiIiIiIiISMUwmSciIiIiIiJSMUzmiYiIiIiIiFQMk3kiIiIiIiIiFcNknoiIiIiIiEjFMJknIiIiIiIiUjFM5omIiIiIiIj+cerUKXTt2hWVK1eGQCDAgQMHPrrOyZMn4eLiAj09PdjZ2WHdunVlHieTeSIiIiIiIqJ/5OTkoEGDBli9enWJ+iclJaFTp05o2bIlYmJi8P3332Ps2LHYu3dvmcYpEIlEojLdAxEREREREZEKEggE2L9/P3x9fYvtM23aNBw8eBBxcXHithEjRuDq1as4d+5cmcXGkXkiIiIiIiJSa7m5uXj58qXEkpubK5dtnzt3Dl5eXhJt3t7euHz5MvLz8+WyD2m0ymzL9J+U//SuokNQGwNdJik6BLVxv+ClokNQC121rBQdgtqo/6ZA0SGojUt6mooOQS08EOQpOgS14fOan0l5aflNjqJDUAtGIX8qOoRPJs/cInj1FsyZM0eibdasWZg9e/ZnbzstLQ0WFhYSbRYWFigoKMDTp09hZVU2f0MxmSciIiIiIiLlIyyU26YCAwMxceJEiTZdXV25bV8gEEi8fnc3+4ft8sRknoiIiIiIiNSarq6uXJP391laWiItLU2iLT09HVpaWjAzMyuTfQJM5omIiIiIiEgZiYSKjqBE3Nzc8OefkrczHDlyBK6urtDW1i6z/XICPCIiIiIiIlI+QqH8llLIzs5GbGwsYmNjAbx99FxsbCxSUlIAvC3Z9/PzE/cfMWIE7t27h4kTJyIuLg4bN27Ehg0bMHnyZLmdCmk4Mk9ERERERET0j8uXL8PT01P8+t299gMHDkRoaChSU1PFiT0A2NraIiwsDBMmTMBPP/2EypUrY+XKlejZs2eZxslknoiIiIiIiJSOSEFl9q1btxZPYCdNaGhokTYPDw9cuXKlDKMqisk8ERERERERKZ9Slsf/1/CeeSIiIiIiIiIVw5F5IiIiIiIiUj4qMpu9ojCZJyIiIiIiIuUjLFR0BEqNZfZEREREREREKoYj80RERERERKR8WGYvE5N5IiIiIiIiUj6czV4mltkTERERERERqRiOzBMREREREZHSEbHMXiYm82UoLS0NCxYswF9//YWHDx/C3NwcDRs2xPjx49G2bVtFhydT69at0bBhQ4SEhCg6FLm5HHsdm37fg5u3EvDk2XOsCA5C21buig5L6fQc3xtt+nrBwNgACTF3sCnoFzy8c7/Y/p592qNlz9awdqwGAEi6noidi7ch8eodcR8NTQ30nNAHzX1bwaSSCV6kZ+Dk7hM4sGo3RCJRmR+Tshg00Q/d+nWGkbERbsbEYdn0lUi+fa9E67bt5onZa2cgKvwMvh88s4wjVazm43ugQV9P6BobIDUmERFBoXh256HMdRw6NkaLSb1gUs0cL1LSEfXjbtw5fFn8vkBTA80n9EBtX3cYVDJBTvoL/L37FM6u+gMQiaChpYmWk3vBzrMhjKtVQl7WaySf/hunFu5EdvqLMj5i+bP2bw/bUV2ha26C7PgHuBW0BRkXbhXbv4KbE2rNGQBDx6rIfZyBpNV/4v6Wo+L3BVqasBvrgyq9PaBrWQE5iam4Pe93PD1xVdzHbqwPLDo1gUHNyih8k4cXl27j9rzfkZOYWqbHqiitxveAc9820DM2wMOYBIQHheKJjM9ppZpV4DGpF6zq2sLEuhIOz9mKixvDJfpUa1ILbsM7w6qeLYwsKmDX0GWIPxJd1oeiUF3Gf4WW37RDOWNDJMXewfag9Ui986DY/i36tEWzHh6o7GgNAEi5fhcHftyO5KsJ4j4dRvqikXdTWNaogrw3ebh7JR77Fm7D47uPyvx4voRq/u1h9971ffMj17epmxOc3ru+767+EynvXd8AYDOsI6oNbA/9KhWR9zwLaYcuIH7Bdghz8wEANf65vg3/ub4zLt1GvBpf3+/Tbt4JOm16QFC+AoRpKcjd/ysK796U2lfTvi7KjQ4u0p7zw7cQphf/uSYZWGYvE8vsy0hycjJcXFxw/PhxLF68GNevX0d4eDg8PT0xatQoRYf3n/T69Rs42tvh+4kjFR2K0uo6ojs6DumG0Jm/YkbXqch8koHvt82GnoFesevUdquDswejML9PEGZ1/w5PHz3Fd1tnoYKF6b/b/bYH2vXzRujMXzG57Rj8HrwFXYb7wtu/85c4LKXQd2Qf9B7WC8tnrMLQziPx/EkGlm9fDH0D/Y+ua1HFHCNnDkfs+WtfIFLFajKiC1yHdETEzM3Y2nUmcp68QO9t30FHxmewsrM9uq0ejRv7TiO04/e4se80uv00GlYNa4j7NP22Cxr2a4ujM7dgQ9upiAzejibDO8PF3wsAoKWvA4u6Nji78gC2dA7C/uEhMLW1Qo8NE8v8mOXN0scNTvMG4m7Ifpxt9x0yLtyCy/bvoFfFTGp//WqV4PL7NGRcuIWz7b7D3RUH4LTAHxadm4j71PyuN6z92uHm95twutVk3N98FI02TYJRXRtxnwpuTkjZdATnOwXh8lcLINDShOvO76FZTresD/mLcx/RBc2GdEL4zFBs6BqEnCeZ6LctUObnVEtfFxkp6Ti+aAey0jOk9tEup4vHcSkInxlaRpErF+8RPmg3uAt2zNyA4G7f4eWTFxj/WxB0ZZxHh2Z1cOngaSz7Zg4W9ZiO54+eYtzWGTB573eOQ9M6iNx6GAu7f48VA+ZBQ1MT47bMgI6+6n8WrXzcUHveQCSE7Mfpdt/h+YVbaPyR69v192l4fuEWTrf7DgkrDqD2An9Yvnd9V+7ZHI7Tv0HC0r041XISrk/4GVY+zeA4/RtxH1M3J9zbdARnOwXh4lcLoKGliSZqen2/T6tRC+h2H4K8iF14tWQcCu/egP7w2RCYVJK5XvaC4cgOGiBehE/U44skUj5M5svIyJEjIRAIcPHiRfTq1QsODg6oU6cOJk6ciPPnzwMAMjMzMWzYMJibm6N8+fJo06YNrl79d5Rj9uzZaNiwITZu3Ihq1arB0NAQ3377LQoLC7F48WJYWlrC3NwcCxYskNh3Sbe7detW2NjYwNjYGH369EFWVhYAwN/fHydPnsSKFSsgEAggEAiQnJxc9ietjLV0a4yxwwaifevmig5FaXUY3AV/rN6DS+Hn8eB2CtZOWgkdPV24+7Qqdp2fxoXg6NZw3LuZjEeJD/HrtDUQaAhQt3l9cZ+azo64HHERscej8fTBE1wMO4frUbGwrV+j2O2qm6+H9MCWlb/j1P9OIyk+GQvGL4Kuvh7ad5ddpaOhoYGZq7/HxiWbkZqi/iMgroM74NzqP3An/DKe3n6AsEk/Q0tPB04+xVfRuAZ0QPLpv3FhzZ94npiKC2v+xL0zN+Ea0EHcp4pzTSREROPu8Vi8fPAUt8MuISnqOizr2wIA8rJeY1f/RYj/6wKe301Fakwijs7aAsv6djCqLP2PZGVlM6IzHvx+Ag+2nUDOnUe4FbQFbx4+QzX/9lL7W/u1x5sHz3AraAty7jzCg20n8GD7CdiO7CLuU/mrFri74gCeHovF63vpuL85Ak8jr8L223+/kIv+ZiEe7jyJ7PgHyLqZguvj1kLfuhLK/3OO1UmTwR1wevUB3Aq/jCe3H+CPSeugraeDujI+p6nX7uLYD9tx48/zKMwtkNonMfIqIpfsxq3wy1LfVzdtAzrjfz/tQ8zhi3h0+z5CJ62Gjr4umvi0KHadjeNX4uRvR/DgZjIeJz7C1u9+hkAgQK3mdcV9Vg5cgHN7IpF65wEexN3D5ilrYFa1EqrXs/sSh1WmbEd0xv33ru+4f67v6sVc39X+ub7jZFzfJi4OyLh0G4/2ncHr+0/w9OQ1PNp/FsYN/j1flz64vq+p8fX9Pp3Wvsi/EIH880cgfPwAufvXQ/jiKbRbdJS5nig7E6KsF+KFM7J/BpFQfosaYjJfBp4/f47w8HCMGjUKBgYGRd43MTGBSCRC586dkZaWhrCwMERHR8PZ2Rlt27bF8+fPxX0TExPxv//9D+Hh4di+fTs2btyIzp0748GDBzh58iQWLVqEGTNmiL8gKM12Dxw4gEOHDuHQoUM4efIkFi5cCABYsWIF3NzcMHToUKSmpiI1NRXW1tZlfNZI0cytLVDB3BTXomLFbQV5BYi7cAMOLrVKvB1dfR1oaWsi+0W2uC3+UhzquteHpW1lAEA1Jxs4ujoh9oR6l4++Y1XNCmYWZrh08t8/0PPz8hF7/irqutaRua7/hAF48SwTf+34X1mHqXDG1pVgaG6C5Kjr4rbCvALcv3ALVVxqFrteZWd7JJ+6LtGWfOoaKr+3zoNLt1HdvQ4q2FoCACo5VUNVV0fcfa9M/EO6RvoQCYXIffnqUw/pixNoa6J8fVs8jZSs4nh68hpMXB2krmPiWhNPT37Q/8Q1lG9gB4GWJgBAQ0cbhf+U274jfJOHCk2K/9mgbVQOAJD/3s8CdWBiXQlG5hVw94PP6b0Lt1BVxueUJFW0NoexeQXcjPr3GizIK8DtCzdRw8WxxNvR0deBprYWcmR8zvT/+SzK6qMKiru+n8i4viu41sSTD67vJyeuwfi96zvj4i0Y17eFcaO3X7DrVzeHedtGSD96pdhYtNT0+pagqQWNqvYovBUj0Vx4KwaaNk4yVzWYvAIGczZDf+R8aNrXK8so1Z+wUH6LGuI982UgISEBIpEItWoV/0fOiRMncP36daSnp0NX922J0pIlS3DgwAHs2bMHw4YNAwAIhUJs3LgRRkZGqF27Njw9PREfH4+wsDBoaGjA0dERixYtQmRkJJo1a1aq7YaGhsLIyAgAMGDAABw7dgwLFiyAsbExdHR0UK5cOVhaWhZ7DLm5ucjNzZVo08jNFe+XVIuxuQkAIPPJC4n2l09foGIV2eVk7+vznR+epz3H32f+/QPtz7X7UM6oHJYcXwVhoRAamhrY9eM2nDt4Wh6hKz0z8woAgOdPJUtrM55kwLKqRbHr1XOtg87fdERA+2FlGp+yMPjnM/jqSaZE+6unmShfpWLx61UyQc5TyXVynmbCoJKx+PWFtX9C10gfQ44vFn8GT/24G3EHz0ndpqauNjy+642bf5xDXvbrTzyiL0/HtDw0tDSR98E5zHuSCd1/zu+HdM1NpPbX0NaCjqkRctNf4GnkNdgM74SMc3F4lfwYZi3rwtzbFQLN4scEas0dgOfnbyH7lnrdJ2r4z3nMflL0M2cs43NKkspXMgEAvPzgPGY9yYRp1ZKfxx7T+uFF2nPEnblebJ+vZgzEnYtxeHS7+PlfVMG76zv3M6/v3A+u79QD56BjVh5uB+cAAkBDWwv3Nh3B3VUHi43FSU2v7/cJDMpDoKkJYdYLiXZR1gtolDeRuo7wZQbe7FiFwgeJgJYWtF3bQH/kfLxe/T0K794o+6DpP4fJfBl4N6GXQCAotk90dDSys7NhZiZZvvn69WskJiaKX9vY2IgTbgCwsLCApqYmNDQ0JNrS09M/a7tWVlbibZRUcHAw5syZI9E2Y8pYzJw6rlTbIcVo7tsKg38YIX69eNAC6R0FghJPUtdluC/cu7XAvN5ByH9vFM+tawu06O6Bn8Yux4PbKahe2xYDZg1GxuMMRO098VnHoYzad2+LyYsmiF9P8/v+7T8+OI8CGedW30AfM1YFYvGUZcjMeFlmsSpSbV93eP0QIH69d9ASAECRMyIQfHjqivrgfYFAIHG+a3Vthtrdm+PPsWvw9PYDmNeujraz+iP78Qvc2Bslsa6Glia6rRoFgYYGImaElu6glMaHJwSyr+MP3xO8a37bHjcjFHWXDkPLM8sgEonwOvkxHuyIRNU+raVuzil4EIycquN8t1mfGL/yqOvrjs4/DBa/3j7oR+kdS/Gz8r+oiU8L9PthuPj16oC3k4QVOWcCSPkhIJ3X8G5o3K0FlvaZhYIPKkfe+WbuYFRxqoYfewV9SthKSto5K/n1Lfjg+jZ1rw378d3x93cbkHklAeVsLFF7/kDkPn6BhOX7imyujhpd3yVT5BdMsadblP4Q+en/ToSZmxwPDZOK0GnTHa+ZzH8aNS2Plxcm82WgZs2aEAgEiIuLg6+vr9Q+QqEQVlZWiIyMLPKeiYmJ+N/a2toS7wkEAqltwn9mevyc7QpLOVtkYGAgJk6UnBxKI0v2jNOkPKIjLiIh5rb4tZbO28+E8T+zzb9T3swYmR+MekrTeZgPfEb1wg/9ZuH+LckZ2vt+PxAH1+7DuT/fjsTfj09BxaqV4DOyh1om86ePnMXNmDjxa+1/zq1pJVM8S//3dheTiiZ4/vSF1G1UsamMytWssDB0vrhNQ+PtX2An7h1Bv1YD8eieat9DnxBxBY9i/v2SUVPn7a8kg0rGyHlvBvlyZuXxSsZnMOfJC4lR+Hfr5Dz990uQ1t9/gwtr/8StP9/ekvQ0/gGMq1ZEs5FdJZJ5DS1NdPtpDIytK2HHN8EqNSoPAHnPX0JYUAidf0Y939GpaFxkdO6d3PQX0DEv2l+YX4D8jLcltPnPshDjvxQautrQrmCI3LQMOMzoi1cpRb8EdvrBH+berrjoOxu5qc+LvK9qbkdcwcP3Pqda/3xODSsZSzzpwMCsfJEKEfrX1aOXkRT774zz786jsbkJXr5XEWZU0Rgvi/m5+L72Q7ui46geCOk3Fw9vpUjt02d2AOq3c8WSr2fhRZrqfxbfXd+6Uq7vD0fr3ynJ9e0w7Ws83B2FB9ve/j7OirsPzXK6qLdkKBJC9kt8GVD7n+v7vO9svFGD61sWUc5LiAoLoWFUAe//hSwwNH57H3wJFd6Lh5Zra3mH99/B2exlYjJfBkxNTeHt7Y2ffvoJY8eOLXLf/IsXL+Ds7Iy0tDRoaWnBxsZGbvuW13Z1dHRQWCj73hJdXd0iJfX5eU8/eZ/0Zb3JeYM3OWkSbRnpz1GvRQPcu5EEANDU1oJT0zrYvnCLzG11Ge4L39G9sNBvLpKuJxZ5X0dfF6IPfhgLC4UQaKjntB2vc17jYY5kEvjs8TM0buWCOzfe/jGrpa2Fhs0aYN0Pv0rdRkpCCvzaDJZoGzo1AOUM9bFi5k9If/SkbIL/gvJy3iAv541EW3b6C9i0qIv0G2+/ENLQ1oR101o4uXBnsdt5dCUB1VvWxeUN/z7my6ZVPTyK/vfxiNr6OhAJJYdS3n4G/62gepfIV7C1wI4+P+CNCt4LKsovxMtrSajoUQ/p/7skbq/Yqh7SD0ufVO3F5Tsw93KWaKvYuj5eXr0LUYHk7wFhbj5y0zIg0NKERZcmSDt4XuJ9px8GwaJTY1zsPhevU1T/MwpI/5xmpWfAtkU9pL33Oa3etBaOLdyhiBBVQm7OGzz54HdOZnoGnFrUx/0byQDe/s5xaFob+xb+JnNbXsO6odPonlgxcD7uXb8rtU+fOYPR0LsJlvWZhWcPSld5qKzev74fl/D6zijm+s587/rWlPLzUSQUvh3Cf69SovYPg2DZqTHOq9H1LVNhAYQPEqDp2AgF1//9Wafp2BAFf18o8WY0qthBlKneX3yQ4jCZLyNr1qyBu7s7mjRpgrlz56J+/fooKChAREQE1q5di5s3b8LNzQ2+vr5YtGgRHB0d8ejRI4SFhcHX1xeurq6ftN927drJZbs2Nja4cOECkpOTYWhoCFNTU4nSflX06tVrpDz499EgDx89xq3biTAubwQrS3MFRqY8wjccgs+oXkhLTkVaUip8RvdE3ptcnP3jlLjPt8vG4nnac+xc/PaPrS7DffHVpL5YPW4ZnjxIh/E/IwZvct4g99XbP4CvHL0En9G98PTRUzy4nQKbOnboNKQbIncd++LHqCi71u9D/zF9cT/pAR4kPcSAMX2R+/oNIvb/ew6mr5iGp6lP8fPCDcjLzUdSfLLENrJfvk0uP2xXJ5c3hKPZqG7ISH6MjKQ0NBvdDQVv8hD3x1lxn07LhiM7LQOnFu96u86mw+i7awaajOiChIho2Ld3QfXmdfB7r3nidRKOxsBttA9ePnqGp7cfwKKODRoP6Yjru04CePscep+1Y2FR1wZ7A5ZCQ1NDPNr/+kU2hPmqM3FO8rq/UH/1KGRevYsXl2/DekA76FWtiJTNb58r7TC9D3QtTXF9zBoAwP0tEag22Au15gzA/d+OwcTVAVX7euLqiJXibRo720PPsgJe3rgHPUtT2E/pBYGGAEmr/72ntvbCAFj1aI4rA5egIPs1dP45fwVZryB8I70EWlVd3BCOFqO64XlyGp4npaHFaB/kv8nD3+99Tn2WjUBWWgaOL377RZSGtiYq1awK4G0VipFlBVjUro68nDfIuPcYwNtH05na/DtXjYl1JVjUro7XL7Lx8tGzL3iEX8axjX+h46geSE9OQ3pSKjqO6oG817m4+Me/86n4Lx2NF4+f48Di3wG8La3vNrEPNoxbgWcPnojvvc9973fON/OGoIlPC6wZuhhvct6I+7x++Qr5uXlf9BjlLWndX2jwz/Wdcfk2qg1oB/2qFXHvn+vb8Z/r+9o/13fKlghUH+wFpzkDkPLbMVRwdYB1X0/Evnd9px+5ApsRnfDy7yS8uJIAAxtLOEz7Go+PRAP/JPl1Fgagco/miP4PXN/vy4s8AL1+E1F4/w6Eybeg7dYBGhUqIf/M20lpdbr4QcPYDG+2LQcAaHt0g+h5OgpT70GgpQ0t19bQbtgcrzf+oMjDUG0ss5eJyXwZsbW1xZUrV7BgwQJMmjQJqampqFSpElxcXLB27VoIBAKEhYVh+vTpCAgIwJMnT2BpaYlWrVrBwqL4CbE+Rl7bnTx5MgYOHIjatWvj9evXSEpKkmsFgSL8fesOAsZME79evOoXAIBPx3ZYMGOSosJSKn+u2w8dPR0Mmj8MBuUNkRh7B8H95+DNe6NSZpUrQfjeN/jtB3SEtq42JqybJrGtvct3YG/I2z9iN8/6FV9N6otB84bBuKIxMh5n4NjvR7Bvxa4vc2BK4Pc1O6Crp4NJP4yDobER4mLiMLHvNLx+bwTforJ5kdGR/5qL6w5BW08H7ef7Q698OaTGJmJX/0USI6PlK1eUOE+Pou/g4JjVaDnpK7Sc1AsvUh7j4OjVSI39t0rk2KwtaDGpF9rP80e5iuWR/TgDsb8fx9kV+wEARlamqOnlAgAYFC75R9f23gtw/3wcVEXaH+egXcEQ9hN7QtfCBFm37iO670K8efC2ckrXvAL035uo7XXKE0T3XYRac/1QbZAX3jzOQNz0UDz+66K4j4auNmp+1xv61c1RmPMGT47F4tqon1Dw3kz/1QZ5AQCaHpC8j/b62LV4uPNkWR7yF3d23SFo6emg43x/6Jc3wMPYRGzrv/CDz6mZxOfUyKIChv3v38+W+/AucB/eBcnnbmJrn7dzllSubwe/nTPEfbxmDgAAXN19Cgcn/1zWh/XFHV73B7T1dNB33hCUMzZAUmwCVgyYj9z3zqNplYoS99V7DPCGtq42RqybLLGtP0N24VDIbgBA6wHeAIDJOyXn9Qmd/BPO7Ykso6P5MlI/uL6zb93HpY9c35f7LoLTP9d37uMM3JweirT3ru+E5fsgEong8F1v6FmaIu/ZS6QfiUZ88L8VUdX/ub6bfXB9X1XD6/t9BTGnkVuuPHS9+0BQ3hTC1Ht4/fMciDLeViZolDeFoMK/kwQLNLWg020QBMZmQH4eCtNS8Orn2SiM+288vadMsMxeJoGIs7WQHOU/lV7uRqU30IVfMMjL/QL1nEDuS+uqZaXoENRG/TfSnzNOpXdJT1PRIaiFBwLVHrFWJj6v+ZmUl5bf5Cg6BLVgFPKnokP4ZLnXDsttW7r1veW2LWXBkXkiIiIiIiJSOiKR6tzmpghM5omIiIiIiEj58J55mVR7RjMiIiIiIiKi/yCOzBMREREREZHy4QR4MjGZJyIiIiIiIuXDMnuZWGZPREREREREpGI4Mk9ERERERETKR8jZ7GVhMk9ERERERETKh2X2MrHMnoiIiIiIiEjFcGSeiIiIiIiIlA9ns5eJyTwREREREREpH5bZy8QyeyIiIiIiIiIVw5F5IiIiIiIiUj4ss5eJyTwREREREREpHybzMrHMnoiIiIiIiEjFcGSe5GqgyyRFh6A2NkcvVXQIaqOH81hFh6AWXN7kKzoEtZGhwV+/8vI3chQdglrQECk6AvVxV0dX0SGoDaMdPJfy0DJE0RF8OpGoUKH7X7NmDX788UekpqaiTp06CAkJQcuWLYvtv23bNixevBh37tyBsbExOnTogCVLlsDMzKxM4uPIPBERERERESkfoVB+Synt3LkT48ePx/Tp0xETE4OWLVuiY8eOSElJkdr/9OnT8PPzw+DBg3Hjxg3s3r0bly5dwpAhQz73LBSLyTwRERERERHRe5YtW4bBgwdjyJAhcHJyQkhICKytrbF27Vqp/c+fPw8bGxuMHTsWtra2aNGiBYYPH47Lly+XWYxM5omIiIiIiEj5iIRyW3Jzc/Hy5UuJJTc3V+pu8/LyEB0dDS8vL4l2Ly8vnD17Vuo67u7uePDgAcLCwiASifD48WPs2bMHnTt3lvtpeYfJPBERERERESkfOZbZBwcHw9jYWGIJDg6WutunT5+isLAQFhYWEu0WFhZIS0uTuo67uzu2bduG3r17Q0dHB5aWljAxMcGqVavkflreYTJPREREREREai0wMBCZmZkSS2BgoMx1BAKBxGuRSFSk7Z2bN29i7NixmDlzJqKjoxEeHo6kpCSMGDFCbsfwIU6nS0RERERERMpHJL/nzOvq6kJXt2RPSKhYsSI0NTWLjMKnp6cXGa1/Jzg4GM2bN8eUKVMAAPXr14eBgQFatmyJ+fPnw8rK6vMOQAqOzBMREREREZHyUdBs9jo6OnBxcUFERIREe0REBNzd3aWu8+rVK2hoSKbXmpqaAN6O6JcFJvNERERERERE75k4cSLWr1+PjRs3Ii4uDhMmTEBKSoq4bD4wMBB+fn7i/l27dsW+ffuwdu1a3L17F2fOnMHYsWPRpEkTVK5cuUxiZJk9ERERERERKR85ltmXVu/evfHs2TPMnTsXqampqFu3LsLCwlC9enUAQGpqqsQz5/39/ZGVlYXVq1dj0qRJMDExQZs2bbBo0aIyi5HJPBERERERESmfUpbHy9vIkSMxcuRIqe+FhoYWaRszZgzGjBlTxlH9i2X2RERERERERCqGI/NERERERESkfBQ8Mq/smMwTERERERGR8lHgPfOqgGX2RERERERERCqGI/NERERERESkfFhmL5PcR+aTk5MhEAgQGxsr701TKcyePRsNGzZUdBhERERERESfRiSU36KGSpXM+/v7QyAQiBczMzN06NAB165dK6v4SpyUzp49WyK2d8vRo0fLLDZF2rt3L5o2bQpjY2MYGRmhTp06mDRpkqLDIiIiIiIioi+g1CPzHTp0QGpqKlJTU3Hs2DFoaWmhS5cuZRFbqdWpU0cc27ulVatWn7StvLw8OUcnP0ePHkWfPn3Qq1cvXLx4EdHR0ViwYIFSx0xERERERFQqQqH8FjVU6mReV1cXlpaWsLS0RMOGDTFt2jTcv38fT548kdq/sLAQgwcPhq2tLfT19eHo6IgVK1ZI9ImMjESTJk1gYGAAExMTNG/eHPfu3UNoaCjmzJmDq1evikfaQ0NDi41NS0tLHNu7RUdHR+rofkhICGxsbMSv/f394evri+DgYFSuXBkODg7iWwb27dsHT09PlCtXDg0aNMC5c+fE6z179gzffPMNqlatinLlyqFevXrYvn27xL6EQiEWLVoEe3t76Orqolq1aliwYIH4/YcPH6J3796oUKECzMzM4OPjg+Tk5GKP89ChQ2jRogWmTJkCR0dHODg4wNfXF6tWrSp2nUuXLqF9+/aoWLEijI2N4eHhgStXrkj0uXXrFlq0aAE9PT3Url0bR48ehUAgwIEDB4rdLhERERERUZlgmb1Mn3XPfHZ2NrZt2wZ7e3uYmZlJ7SMUClG1alXs2rULN2/exMyZM/H9999j165dAICCggL4+vrCw8MD165dw7lz5zBs2DAIBAL07t0bkyZNkhhx79279+eELNOxY8cQFxeHiIgIHDp0SNw+ffp0TJ48GbGxsXBwcMA333yDgoICAMCbN2/g4uKCQ4cO4e+//8awYcMwYMAAXLhwQbx+YGAgFi1ahKCgINy8eRO///47LCwsAACvXr2Cp6cnDA0NcerUKZw+fRqGhobo0KFDsSPtlpaWuHHjBv7+++8SH1tWVhYGDhyIqKgonD9/HjVr1kSnTp2QlZUF4O3/J19fX5QrVw4XLlzAL7/8gunTp5f6HBIREREREVHZK/Vs9ocOHYKhoSEAICcnB1ZWVjh06BA0NKR/L6CtrY05c+aIX9va2uLs2bPYtWsXvv76a7x8+RKZmZno0qULatSoAQBwcnIS9zc0NBSPuH/M9evXxbEBQO3atXHx4sUSH5uBgQHWr18PHR0dABCPjk+ePBmdO3cGAMyZMwd16tRBQkICatWqhSpVqmDy5MnibYwZMwbh4eHYvXs3mjZtiqysLKxYsQKrV6/GwIEDAQA1atRAixYtAAA7duyAhoYG1q9fD4FAAADYtGkTTExMEBkZCS8vryJxjhkzBlFRUahXrx6qV6+OZs2awcvLC/369YOurq7UY2vTpo3E659//hkVKlTAyZMn0aVLFxw5cgSJiYmIjIwUn+sFCxagffv2xZ6v3Nxc5ObmSrQVigqhKdAsdh0iIiIiIqISUdPyeHkp9ci8p6cnYmNjERsbiwsXLsDLywsdO3bEvXv3il1n3bp1cHV1RaVKlWBoaIhff/0VKSkpAABTU1P4+/vD29sbXbt2xYoVK5CamvpJB+Po6CiOLTY2Fnv37i3V+vXq1RMn8u+rX7+++N9WVlYAgPT0dABvbyNYsGAB6tevDzMzMxgaGuLIkSPi44uLi0Nubi7atm0rdZ/R0dFISEiAkZERDA0NYWhoCFNTU7x58waJiYlS1zEwMMBff/2FhIQEzJgxA4aGhpg0aRKaNGmCV69eSV0nPT0dI0aMgIODA4yNjWFsbIzs7GxxnPHx8bC2tpb40qRJkyYyz1dwcLB4W++Wm5m3Za5DRERERERUIrxnXqZSJ/MGBgawt7eHvb09mjRpgg0bNiAnJwe//vqr1P67du3ChAkTEBAQgCNHjiA2NhaDBg2SKCHftGkTzp07B3d3d+zcuRMODg44f/58qQ9GR0dHHJu9vT2sra3fHqSGBkQikUTf/Px8qccmjba2tvjf70bPhf98IJYuXYrly5dj6tSpOH78OGJjY+Ht7S0+Pn19fZkxC4VCuLi4SHwJERsbi9u3b6Nv374y161RowaGDBmC9evX48qVK7h58yZ27twpta+/vz+io6MREhKCs2fPIjY2FmZmZuI4RSKR+NhKKjAwEJmZmRJLbWOHUm2DiIiIiIiISq/UZfYfEggE0NDQwOvXr6W+HxUVBXd3d4wcOVLcJm3EuVGjRmjUqBECAwPh5uaG33//Hc2aNYOOjg4KCws/K8ZKlSohLS1NImGNjY39rG2+ExUVBR8fH/Tv3x/A2+T8zp074lsFatasCX19fRw7dgxDhgwpsr6zszN27twJc3NzlC9f/pPjsLGxQbly5ZCTk1NsnGvWrEGnTp0AAPfv38fTp0/F79eqVQspKSl4/Pix+H7+S5cuydynrq5ukbJ+ltgTEREREZFcfDAgS5JKPTKfm5uLtLQ0pKWlIS4uDmPGjEF2dja6du0qtb+9vT0uX76Mw4cP4/bt2wgKCpJIEpOSkhAYGIhz587h3r17OHLkCG7fvi1Ohm1sbJCUlITY2Fg8ffq0yD3aJdG6dWs8efIEixcvRmJiIn766Sf873//K/V2iju+iIgInD17FnFxcRg+fDjS0tLE7+vp6WHatGmYOnUqtmzZgsTERJw/fx4bNmwAAPTr1w8VK1aEj48PoqKikJSUhJMnT2LcuHF48OCB1H3Onj0bU6dORWRkJJKSkhATE4OAgADk5+cXe4+7vb09tm7diri4OFy4cAH9+vWTqBpo3749atSogYEDB+LatWs4c+aMeAK80o7YExERERERfTaW2ctU6mQ+PDwcVlZWsLKyQtOmTXHp0iXs3r0brVu3ltp/xIgR6NGjB3r37o2mTZvi2bNnEqP05cqVw61bt9CzZ084ODhg2LBhGD16NIYPHw4A6NmzJzp06ABPT09UqlSpyGPfSsLJyQlr1qzBTz/9hAYNGuDixYsSk9Z9jqCgIDg7O8Pb2xutW7eGpaUlfH19i/SZNGkSZs6cCScnJ/Tu3Vt8z325cuVw6tQpVKtWDT169ICTkxMCAgLw+vXrYkfqPTw8cPfuXfj5+aFWrVro2LEj0tLScOTIETg6OkpdZ+PGjcjIyECjRo0wYMAAjB07Fubm5uL3NTU1ceDAAWRnZ6Nx48YYMmQIZsyYAeDtFxJERERERESkPASiD28mJ/rHmTNn0KJFCyQkJIifNPAxfat3L+Oo/js2Ry9VdAhqo4fzWEWHoBbG50qfV4RKL0Pjs+9yo3/s1pF+exmVzmc9q5gkNBcafrwTlUiD/DeKDkEttEzbo+gQPtnrbUFy25Z+v3ly25ay4F8TJLZ//34YGhqiZs2aSEhIwLhx49C8efMSJ/JERERERERyI1LP8nh5YTJPYllZWZg6dSru37+PihUrol27dli6lKPDREREREREyobJPIn5+fnBz89P0WEQERERERGp7cR18sJknoiIiIiIiJQPp3eTifOdEBEREREREakYjswTERERERGR8mGZvUxM5omIiIiIiEj5MJmXiWX2RERERERERCqGI/NERERERESkfPiceZmYzBMREREREZHSEQk5m70sLLMnIiIiIiIiUjEcmSciIiIiIiLlwwnwZGIyT0RERERERMqH98zLxDJ7IiIiIiIiIhXDkXkiIiIiIiJSPpwATyYm8yRX9wteKjoEtdHDeayiQ1Ab+66sVHQIaiHAZbKiQ1AbIXXTFB2C2siKtVZ0CGrBvKBQ0SGojVP6PJfykqmhq+gQ1EJLRQfwOXjPvEwssyciIiIiIiJSMRyZJyIiIiIiIuXDkXmZmMwTERERERGR8hHxnnlZWGZPRERERERE9IE1a9bA1tYWenp6cHFxQVRUlMz+ubm5mD59OqpXrw5dXV3UqFEDGzduLLP4ODJPREREREREykeBZfY7d+7E+PHjsWbNGjRv3hw///wzOnbsiJs3b6JatWpS1/n666/x+PFjbNiwAfb29khPT0dBQUGZxchknoiIiIiIiJSPAh9Nt2zZMgwePBhDhgwBAISEhODw4cNYu3YtgoODi/QPDw/HyZMncffuXZiamgIAbGxsyjRGltkTERERERGRWsvNzcXLly8lltzcXKl98/LyEB0dDS8vL4l2Ly8vnD17Vuo6Bw8ehKurKxYvXowqVarAwcEBkydPxuvXr+V+LO8wmSciIiIiIiLlIxLKbQkODoaxsbHEIm2EHQCePn2KwsJCWFhYSLRbWFggLS1N6jp3797F6dOn8ffff2P//v0ICQnBnj17MGrUKLmflndYZk9ERERERETKR45l9oGBgZg4caJEm66ursx1BAKBxGuRSFSk7R2hUAiBQIBt27bB2NgYwNtS/V69euGnn36Cvr7+Z0QvHZN5IiIiIiIiUmu6urofTd7fqVixIjQ1NYuMwqenpxcZrX/HysoKVapUESfyAODk5ASRSIQHDx6gZs2anx58MVhmT0REREREREpHJBTKbSkNHR0duLi4ICIiQqI9IiIC7u7uUtdp3rw5Hj16hOzsbHHb7du3oaGhgapVq5b+4EuAyTwREREREREpH6FIfkspTZw4EevXr8fGjRsRFxeHCRMmICUlBSNGjADwtmzfz89P3L9v374wMzPDoEGDcPPmTZw6dQpTpkxBQEBAmZTYAyyzJyIiIiIiIpLQu3dvPHv2DHPnzkVqairq1q2LsLAwVK9eHQCQmpqKlJQUcX9DQ0NERERgzJgxcHV1hZmZGb7++mvMnz+/zGJkMk9ERERERETKR1S68nh5GzlyJEaOHCn1vdDQ0CJttWrVKlKaX5ZYZq8kWrdujfHjxys0Bn9/f/j6+io0BiIiIiIiIgAKLbNXBUzmvxB/f38IBIIiS0JCgtz35eXlBU1NTZw/f17u2yYiIiIiIiLFYzL/BXXo0AGpqakSi62trVz3kZKSgnPnzmH06NHYsGGDXLdNRERERET0xQiF8lvUEJP5L0hXVxeWlpYSi6amZpF+c+fORb169Yq0u7i4YObMmTL3sWnTJnTp0gXffvstdu7ciZycHIn39+zZg3r16kFfXx9mZmZo165dkT5LliyBlZUVzMzMMGrUKOTn53/C0RIREREREX0GltnLxGReCQUEBODmzZu4dOmSuO3atWuIiYmBv79/seuJRCJs2rQJ/fv3R61ateDg4IBdu3aJ309NTcU333yDgIAAxMXFITIyEj169IBI9O+H+8SJE0hMTMSJEyewefNmhIaGSp3cgYiIiIiIiBSHyfwXdOjQIRgaGoqXr776Smq/qlWrwtvbG5s2bRK3bdq0CR4eHrCzsyt2+0ePHsWrV6/g7e0NAOjfv79EqX1qaioKCgrQo0cP2NjYoF69ehg5ciQMDQ3FfSpUqIDVq1ejVq1a6NKlCzp37oxjx4597qETERERERGVjkgov0UNMZn/gjw9PREbGyteVq5cWWzfoUOHYvv27Xjz5g3y8/Oxbds2BAQEyNz+hg0b0Lt3b2hpvX3i4DfffIMLFy4gPj4eANCgQQO0bdsW9erVw1dffYVff/0VGRkZEtuoU6eOROm/lZUV0tPTpe4vNzcXL1++lFiEanqhEBERERHRF8Yye5mYzH9BBgYGsLe3Fy9WVlbF9u3atSt0dXWxf/9+/Pnnn8jNzUXPnj2L7f/8+XMcOHAAa9asgZaWFrS0tFClShUUFBRg48aNAABNTU1ERETgf//7H2rXro1Vq1bB0dERSUlJ4u1oa2tLbFcgEEBYzIQRwcHBMDY2lljuZyWX4owQERERERHRp2Ayr6S0tLQwcOBAbNq0CZs2bUKfPn1Qrly5Yvtv27YNVatWxdWrVyVG/0NCQrB582YUFBQAeJucN2/eHHPmzEFMTAx0dHSwf//+T4oxMDAQmZmZEou1kc0nbYuIiIiIiOh9IqFQbos60lJ0AFS8IUOGwMnJCQBw5swZmX03bNiAXr16oW7duhLt1atXx7Rp0/DXX3/B0tISx44dg5eXF8zNzXHhwgU8efJEvI/S0tXVha6urkSbhoDfDxERERERkRyoaXm8vDDzUmI1a9aEu7s7HB0d0bRp02L7RUdH4+rVq1LL8I2MjODl5YUNGzagfPnyOHXqFDp16gQHBwfMmDEDS5cuRceOHcvyMIiIiIiIiEjOODL/hXzs8W6RkZFF2kQiER4/fozhw4fLXNfFxUXi8XIfOnjwoPjf4eHhpYoxJCRE5r6JiIiIiIjKBEfmZWIyr6TS09OxdetWPHz4EIMGDVJ0OERERERERF8Wn5QlE5N5JWVhYYGKFSvil19+QYUKFRQdDhERERERESkRJvNKSlbZPBERERERkdpjmb1MTOaJiIiIiIhI6YiYzMvE2eyJiIiIiIiIVAxH5omIiIiIiEj5cGReJibzREREREREpHyEnM1eFpbZExEREREREakYjswTERERERGR8mGZvUxM5omIiIiIiEj5MJmXiWX2RERERERERCqGI/NERERERESkdEQijszLwmSeiIiIiIiIlA/L7GVimT0RERERERGRiuHIPBERERERESkfjszLxGSeiIiIiIiIlI6IybxMTOZJrrpqWSk6BLXh8iZf0SGojQCXyYoOQS1sjF6i6BDUhn7llooOQW2MqczfO/JwvDBF0SGojT9MDBQdgtqYklFO0SEQKTUm80RERERERKR8ODIvE5N5IiIiIiIiUj5CRQeg3DibPREREREREZGK4cg8ERERERERKR1OgCcbR+aJiIiIiIiIVAxH5omIiIiIiEj5cGReJo7MExERERERkfIRynH5BGvWrIGtrS309PTg4uKCqKioEq135swZaGlpoWHDhp+24xJiMk9ERERERET0np07d2L8+PGYPn06YmJi0LJlS3Ts2BEpKSky18vMzISfnx/atm1b5jEymSciIiIiIiKlIxKK5LaU1rJlyzB48GAMGTIETk5OCAkJgbW1NdauXStzveHDh6Nv375wc3P71MMuMSbzREREREREpHzkWGafm5uLly9fSiy5ublSd5uXl4fo6Gh4eXlJtHt5eeHs2bPFhrtp0yYkJiZi1qxZn3HQJcdknoiIiIiIiNRacHAwjI2NJZbg4GCpfZ8+fYrCwkJYWFhItFtYWCAtLU3qOnfu3MF3332Hbdu2QUvry8wzz9nsiYiIiIiISOnI8znzgYGBmDhxokSbrq6uzHUEAoFkPCJRkTYAKCwsRN++fTFnzhw4ODh8frAlxGSeiIiIiIiIlM8nzkIvja6u7keT93cqVqwITU3NIqPw6enpRUbrASArKwuXL19GTEwMRo8eDQAQCoUQiUTQ0tLCkSNH0KZNm88/iA+wzJ6IiIiIiIjoHzo6OnBxcUFERIREe0REBNzd3Yv0L1++PK5fv47Y2FjxMmLECDg6OiI2NhZNmzYtkzg5Mk9ERERERERKRyTHkfnSmjhxIgYMGABXV1e4ubnhl19+QUpKCkaMGAHgbdn+w4cPsWXLFmhoaKBu3boS65ubm0NPT69IuzxxZF5JrFu3DkZGRigoKBC3ZWdnQ1tbGy1btpToGxUVBYFAgNu3b8vcZmRkJAQCAV68eFEWIRMREREREZUdOc5mX1q9e/dGSEgI5s6di4YNG+LUqVMICwtD9erVAQCpqakffeZ8WWMyryQ8PT2RnZ2Ny5cvi9uioqJgaWmJS5cu4dWrV+L2yMhIVK5c+YtNriASiSS+ZCAiIiIiIlJ3I0eORHJyMnJzcxEdHY1WrVqJ3wsNDUVkZGSx686ePRuxsbFlGh+TeSXh6OiIypUrS3wgIiMj4ePjgxo1akg8zzAyMhKenp747bff4OrqCiMjI1haWqJv375IT08HACQnJ8PT0xMAUKFCBQgEAvj7+wN4m5wvXrwYdnZ20NfXR4MGDbBnzx6J7QsEAhw+fBiurq7Q1dVFVFRU2Z8EIiIiIiKif4iE8lvUEZN5JdK6dWucOHFC/PrEiRNo3bo1PDw8xO15eXk4d+4cPD09kZeXh3nz5uHq1as4cOAAkpKSxAm7tbU19u7dCwCIj49HamoqVqxYAQCYMWMGNm3ahLVr1+LGjRuYMGEC+vfvj5MnT0rEM3XqVAQHByMuLg7169f/AmeAiIiIiIjoHwoss1cFnABPibRu3RoTJkxAQUEBXr9+jZiYGLRq1QqFhYVYuXIlAOD8+fN4/fo1PD09YWdnJ17Xzs4OK1euRJMmTZCdnQ1DQ0OYmpoCeDv5gomJCQAgJycHy5Ytw/Hjx+Hm5iZe9/Tp0/j555/h4eEh3ubcuXPRvn37YuPNzc1Fbm6uRFuBqBBaAk25nA8iIiIiIiKSjiPzSsTT0xM5OTm4dOkSoqKi4ODgAHNzc3h4eODSpUvIyclBZGQkqlWrBjs7O8TExMDHxwfVq1eHkZERWrduDQAyJ2K4efMm3rx5g/bt28PQ0FC8bNmyBYmJiRJ9XV1dZcYbHBwMY2NjieVE5o3PPg9EREREREQss5eNI/NKxN7eHlWrVsWJEyeQkZEhHiW3tLSEra0tzpw5gxMnTqBNmzbIycmBl5cXvLy88Ntvv6FSpUpISUmBt7c38vLyit2HUPj2k/zXX3+hSpUqEu/p6upKvDYwMJAZb2BgICZOnCjRtrru8BIfLxERERERUXHUNQmXFybzSsbT0xORkZHIyMjAlClTxO0eHh44fPgwzp8/j0GDBuHWrVt4+vQpFi5cCGtrawCQmAkfAHR0dAAAhYWF4rbatWtDV1cXKSkpEiX1n0JXV7fIFwAssSciIiIiIip7TOaVjKenJ0aNGoX8/HyJZNvDwwPffvst3rx5A09PT+jp6UFHRwerVq3CiBEj8Pfff2PevHkS26pevToEAgEOHTqETp06QV9fH0ZGRpg8eTImTJgAoVCIFi1a4OXLlzh79iwMDQ0xcODAL33IRERERERERXBkXjbeM69kPD098fr1a9jb28PCwkLc7uHhgaysLNSoUQPW1taoVKkSQkNDsXv3btSuXRsLFy7EkiVLJLZVpUoVzJkzB9999x0sLCwwevRoAMC8efMwc+ZMBAcHw8nJCd7e3vjzzz9ha2v7RY+ViIiIiIioWCKB/BY1JBCJRCJFB0HqY3H1/ooOQW24vMlXdAhqI1SP51IeNkYv+XgnKhH9yi0VHYLaGMNzKRfH3xQ/eS6Vzh+WsuccopKbklFO0SGohd33/lB0CJ/s8T8TfMuDRWSk3LalLFhmT0REREREREqHZfayMZknIiIiIiIipSMSqmd5vLzwnnkiIiIiIiIiFcOReSIiIiIiIlI6LLOXjck8ERERERERKR2Rms5CLy8ssyciIiIiIiJSMRyZJyIiIiIiIqXDMnvZmMwTERERERGR0uFs9rKxzJ6IiIiIiIhIxXBknoiIiIiIiJSOSKToCJQbk3kiIiIiIiJSOiyzl41l9kREREREREQqhiPzREREREREpHQ4Mi8bk3kiIiIiIiJSOrxnXjaW2RMRERERERGpGI7MExERERERkdJhmb1sTOZJruq/KVB0CGojQ4OXp7yE1E1TdAhqQb9yS0WHoDZeP4pSdAhqY5DLZEWHoBa2G1RQdAhqY9kLQ0WHoDbW1ubv7/86kYjJvCwssyciIiIiIiJSMRz6IyIiIiIiIqUjEio6AuXGZJ6IiIiIiIiUjpBl9jKxzJ6IiIiIiIhIxXBknoiIiIiIiJQOJ8CTjck8ERERERERKR0+mk42ltkTERERERERqRiOzBMREREREZHSEYkUHYFyYzJPRERERERESodl9rKxzJ6IiIiIiIhIxTCZJyIiIiIiIqUjFAnktnyKNWvWwNbWFnp6enBxcUFUVFSxffft24f27dujUqVKKF++PNzc3HD48OFPPfQSYTJPRERERERESkckEshtKa2dO3di/PjxmD59OmJiYtCyZUt07NgRKSkpUvufOnUK7du3R1hYGKKjo+Hp6YmuXbsiJibmc09DsXjPPBEREREREam13Nxc5ObmSrTp6upCV1dXav9ly5Zh8ODBGDJkCAAgJCQEhw8fxtq1axEcHFykf0hIiMTrH374AX/88Qf+/PNPNGrUSD4H8QGOzBMREREREZHSEYnktwQHB8PY2FhikZaUA0BeXh6io6Ph5eUl0e7l5YWzZ8+WKHahUIisrCyYmpp+9nkoDpP5TxAZGQmBQIAXL16U2T6Sk5MhEAgQGxtbov7+/v7w9fUts3iIiIiIiIi+JHneMx8YGIjMzEyJJTAwUOp+nz59isLCQlhYWEi0W1hYIC0trUSxL126FDk5Ofj6668/+zwURyHJfHp6OoYPH45q1apBV1cXlpaW8Pb2xrlz5xQRjsJJS8Stra2RmpqKunXrlmgbK1asQGhoqPyDIyIiIiIiUnG6urooX768xFJcif07AoHkvfYikahImzTbt2/H7NmzsXPnTpibm39W3LIo5J75nj17Ij8/H5s3b4adnR0eP36MY8eO4fnz54oIRywvLw86OjoKjeEdTU1NWFpalri/sbFxGUajXOeGiIiIiIjU36dMXCcPFStWhKamZpFR+PT09CKj9R/auXMnBg8ejN27d6Ndu3ZlGeaXH5l/8eIFTp8+jUWLFsHT0xPVq1dHkyZNEBgYiM6dO0stL3/x4gUEAgEiIyMB/Fvm/tdff6FBgwbQ09ND06ZNcf36dYl9nT17Fq1atYK+vj6sra0xduxY5OTkiN+3sbHB/Pnz4e/vD2NjYwwdOlS8/x07dsDd3R16enqoU6eOeN/SPHv2DN988w2qVq2KcuXKoV69eti+fbtEnz179qBevXrQ19eHmZkZ2rVrh5ycHMyePRubN2/GH3/8AYFAID5Oaefhxo0b6Ny5M8qXLw8jIyO0bNkSiYmJACRH99+t++HSunXrzzo3REREREREX4o875kvDR0dHbi4uCAiIkKiPSIiAu7u7sWut337dvj7++P3339H586dP+WQS+WLJ/OGhoYwNDTEgQMHiswmWFpTpkzBkiVLcOnSJZibm6Nbt27Iz88HAFy/fh3e3t7o0aMHrl27hp07d+L06dMYPXq0xDZ+/PFH1K1bF9HR0QgKCpLY9qRJkxATEwN3d3d069YNz549kxrHmzdv4OLigkOHDuHvv//GsGHDMGDAAFy4cAEAkJqaim+++QYBAQGIi4tDZGQkevToAZFIhMmTJ+Prr79Ghw4dkJqaitTUVKkfkIcPH6JVq1bQ09PD8ePHER0djYCAABQUFBTp+65E/90SExMDMzMztGrVSi7nhoiIiIiISJ1NnDgR69evx8aNGxEXF4cJEyYgJSUFI0aMAAAEBgbCz89P3H/79u3w8/PD0qVL0axZM6SlpSEtLQ2ZmZllFuMXL7PX0tJCaGgohg4dinXr1sHZ2RkeHh7o06cP6tevX6ptzZo1C+3btwcAbN68GVWrVsX+/fvx9ddf48cff0Tfvn0xfvx4AEDNmjWxcuVKeHh4YO3atdDT0wMAtGnTBpMnTxZvMzk5GQAwevRo9OzZEwCwdu1ahIeHY8OGDZg6dWqROKpUqSKxjTFjxiA8PBy7d+9G06ZNkZqaioKCAvTo0QPVq1cHANSrV0/cX19fH7m5uTLL6n/66ScYGxtjx44d0NbWBgA4ODhI7ft+if6bN2/g6+sLNzc3zJ49GwA++dx8SNrjHfJEhdARaBa7DhERERERUUkIFVRmDwC9e/fGs2fPMHfuXPFcZmFhYeJ8LjU1VeKZ8z///DMKCgowatQojBo1Stw+cODAMpvbTGH3zHfu3BlRUVE4d+4cwsPDsXjxYqxfv16iFPxj3NzcxP82NTWFo6Mj4uLiAADR0dFISEjAtm3bxH1EIhGEQiGSkpLg5OQEAHB1df3otrW0tODq6ire9ocKCwuxcOFC7Ny5Ew8fPhQnuQYGBgCABg0aoG3btqhXrx68vb3h5eWFXr16oUKFCiU+1tjYWLRs2VKcyJfU4MGDkZWVhYiICGhovC3E+Nxz805wcDDmzJkj0davXB30NyzZpH1ERERERETFUdQ98++MHDkSI0eOlPrehwm6rNuyy4rCHk2np6eH9u3bY+bMmTh79iz8/f0xa9YsccIpeu/Ghnel8yXxbnZBoVCI4cOHIzY2VrxcvXoVd+7cQY0aNcT93yXcpdn2h5YuXYrly5dj6tSpOH78OGJjY+Ht7Y28vDwAb0fKIyIi8L///Q+1a9fGqlWr4OjoiKSkpBLvW19fv8R935k/fz7Cw8Nx8OBBGBkZidvldW6kPd7hawOnUsdJREREREREpaM0z5mvXbs2cnJyUKlSJQBvyxbeKe5Z6+fPnxf/OyMjA7dv30atWrUAAM7Ozrhx4wbs7e2LLCWZlf39bRcUFCA6Olq87Q9FRUXBx8cH/fv3R4MGDWBnZ4c7d+5I9BEIBGjevDnmzJmDmJgY6OjoYP/+/QDeTrBQWFgoM5769esjKiqqxF9s7N27F3PnzsWuXbskEnTg88/NO9Ie78ASeyIiIiIikgd5PmdeHX3xZP7Zs2do06YNfvvtN1y7dg1JSUnYvXs3Fi9eDB8fH+jr66NZs2ZYuHAhbt68iVOnTmHGjBlStzV37lwcO3YMf//9N/z9/VGxYkXxjO7Tpk3DuXPnMGrUKMTGxuLOnTs4ePAgxowZU6I4f/rpJ+zfvx+3bt3CqFGjkJGRgYCAAKl97e3tERERgbNnzyIuLg7Dhw+XeIzBhQsX8MMPP+Dy5ctISUnBvn378OTJE3E5u42NDa5du4b4+Hg8ffpUasI+evRovHz5En369MHly5dx584dbN26FfHx8UX6/v333/Dz88O0adNQp04d8eQL7x7997nnhoiIiIiIqKyJ5LioI4XMZt+0aVMsX74crVq1Qt26dREUFIShQ4di9erVAICNGzciPz8frq6uGDduHObPny91WwsXLsS4cePg4uKC1NRUHDx4UDyyXL9+fZw8eRJ37txBy5Yt0ahRIwQFBcHKyqpEcS5cuBCLFi1CgwYNEBUVhT/++AMVK1aU2jcoKAjOzs7w9vZG69atYWlpKf5SAQDKly+PU6dOoVOnTnBwcMCMGTOwdOlSdOzYEQAwdOhQODo6wtXVFZUqVcKZM2eK7MPMzAzHjx9HdnY2PDw84OLigl9//VXqPfSXL1/Gq1evMH/+fFhZWYmXHj16yOXcEBERERERkWIJRKLSPnVP8SIjI+Hp6YmMjAyYmJjIddvJycmwtbVFTEwMGjZsKNdt/xeEW/RRdAhqI1uDtyzIi6fzA0WHoBYsIhIUHYLaeP0oStEhqI1BLsU/dYVK7nutz3tcMP1rXaGhokNQGzOd0j7eiT6q4v9OKjqET3bWqqfctuWeuldu21IWCpnNnoiIiIiIiEgWRc9mr+yUZgI8IiIiIiIiIioZlRyZb926Ncrq7gAbG5sy2zYRERERERGVjFDRASg5lUzmiYiIiIiISL2JwDJ7WVhmT0RERERERKRiODJPRERERERESkfIu59lYjJPRERERERESkfIMnuZWGZPREREREREpGI4Mk9ERERERERKhxPgycZknoiIiIiIiJQOH00nG8vsiYiIiIiIiFQMR+aJiIiIiIhI6bDMXjYm80RERERERKR0WGYvG8vsiYiIiIiIiFQMR+aJiIiIiIhI6XBkXjYm80RERERERKR0eM+8bEzmSa4u6WkqOgS18TdyFB2C2siKtVZ0CGphTGUrRYegNga5TFZ0CGpjU/QSRYegFqa6fq/oENSGcz7/vJaXxXGVFR2CWlis6ACozPCnDRERERERESkdIQfmZWIyT0REREREREpHyDJ7mTibPREREREREZGK4cg8ERERERERKR2RogNQckzmiYiIiIiISOnw0XSyscyeiIiIiIiISMVwZJ6IiIiIiIiUjlDACfBkYTJPRERERERESof3zMvGMnsiIiIiIiIiFcOReSIiIiIiIlI6nABPNibzREREREREpHSEvGVeJpbZExEREREREakYjswTERERERGR0hGCQ/OycGSeiIiIiIiIlI5IjsunWLNmDWxtbaGnpwcXFxdERUXJ7H/y5Em4uLhAT08PdnZ2WLdu3SfuuWSYzBMRERERERG9Z+fOnRg/fjymT5+OmJgYtGzZEh07dkRKSorU/klJSejUqRNatmyJmJgYfP/99xg7diz27t1bZjF+VjKflpaGMWPGwM7ODrq6urC2tkbXrl1x7NgxecWnEMOGDYOmpiZ27Nih6FDKRGhoKExMTBQdBhERERERUbGEAvktpbVs2TIMHjwYQ4YMgZOTE0JCQmBtbY21a9dK7b9u3TpUq1YNISEhcHJywpAhQxAQEIAlS5Z85lko3icn88nJyXBxccHx48exePFiXL9+HeHh4fD09MSoUaPkGWMReXl5ZbbtV69eYefOnZgyZQo2bNhQZvv5UFkeExERERERkaoRynHJzc3Fy5cvJZbc3Fyp+83Ly0N0dDS8vLwk2r28vHD27Fmp65w7d65If29vb1y+fBn5+fmfcPQf98nJ/MiRIyEQCHDx4kX06tULDg4OqFOnDiZOnIjz58+L+6WkpMDHxweGhoYoX748vv76azx+/Fj8fmJiInx8fGBhYQFDQ0M0btwYR48eldiXjY0N5s+fD39/fxgbG2Po0KHIy8vD6NGjYWVlBT09PdjY2CA4OFi8TmZmJoYNGwZzc3OUL18ebdq0wdWrVz96XLt370bt2rURGBiIM2fOIDk5WeL9goICjB07FiYmJjAzM8O0adMwcOBA+Pr6ivtkZWWhX79+MDAwgJWVFZYvX47WrVtj/PjxMo8JAM6ePYtWrVpBX18f1tbWGDt2LHJycsTrpaamonPnztDX14etrS1+//132NjYICQkRNxn2bJlqFevHgwMDGBtbY2RI0ciOzsbABAZGYlBgwYhMzMTAoEAAoEAs2fPBvD2Qzt16lRUqVIFBgYGaNq0KSIjIz96zoiIiIiIiJRZcHAwjI2NJZb388f3PX36FIWFhbCwsJBot7CwQFpamtR10tLSpPYvKCjA06dP5XMQH/ikZP758+cIDw/HqFGjYGBgUOT9dyXcIpEIvr6+eP78OU6ePImIiAgkJiaid+/e4r7Z2dno1KkTjh49ipiYGHh7e6Nr165F7kX48ccfUbduXURHRyMoKAgrV67EwYMHsWvXLsTHx+O3336DjY2NeL+dO3dGWloawsLCEB0dDWdnZ7Rt2xbPnz+XeWwbNmxA//79YWxsjE6dOmHTpk0S7y9atAjbtm3Dpk2bcObMGbx8+RIHDhyQ6DNx4kScOXMGBw8eREREBKKionDlypUi+/rwmK5fvw5vb2/06NED165dw86dO3H69GmMHj1avI6fnx8ePXqEyMhI7N27F7/88gvS09MltquhoYGVK1fi77//xubNm3H8+HFMnToVAODu7o6QkBCUL18eqampSE1NxeTJkwEAgwYNwpkzZ7Bjxw5cu3YNX331FTp06IA7d+7IPGdERERERETyJs8J8AIDA5GZmSmxBAYGyty/QCBZny8SiYq0fay/tHZ5+aRH0yUkJEAkEqFWrVoy+x09ehTXrl1DUlISrK2tAQBbt25FnTp1cOnSJTRu3BgNGjRAgwYNxOvMnz8f+/fvx8GDByWS2DZt2oiTTuDtiH/NmjXRokULCAQCVK9eXfzeiRMncP36daSnp0NXVxcAsGTJEhw4cAB79uzBsGHDpMZ7584dnD9/Hvv27QMA9O/fH2PHjsWsWbOgofH2e49Vq1YhMDAQ3bt3BwCsXr0aYWFh4m1kZWVh8+bN+P3339G2bVsAwKZNm1C5cuUi+/vwmPz8/NC3b1/xCH7NmjWxcuVKeHh4YO3atUhOTsbRo0dx6dIluLq6AgDWr1+PmjVrSmz3/QoAW1tbzJs3D99++y3WrFkDHR0dGBsbQyAQwNLSUtwvMTER27dvx4MHD8SxTp48GeHh4di0aRN++OGHIvHn5uYWKU0pEBVCS6Ap9fwSERERERGV1Kfc614cXV1dcW74MRUrVoSmpmaRUfj09PQio+/vWFpaSu2vpaUFMzOzTwv6Iz5pZL6k3zDExcXB2tpanMgDQO3atWFiYoK4uDgAQE5ODqZOnSpuNzQ0xK1bt4qMzL9LXt/x9/dHbGwsHB0dMXbsWBw5ckT8XnR0NLKzs2FmZgZDQ0PxkpSUhMTExGLj3bBhA7y9vVGxYkUAQKdOnZCTkyMu+8/MzMTjx4/RpEkT8TqamppwcXERv7579y7y8/Ml+hgbG8PR0bHI/j48pujoaISGhkrE7O3tDaFQiKSkJMTHx0NLSwvOzs7idezt7VGhQgWJ7Zw4cQLt27dHlSpVYGRkBD8/Pzx79kyiXP9DV65cgUgkgoODg8T+T548Wew5k1aqcirzRrH7ICIiIiIiUnY6OjpwcXFBRESERHtERATc3d2lruPm5lak/5EjR+Dq6gptbe0yifOTRuZr1qwJgUCAuLg4iXvFP1RcGcL77VOmTMHhw4exZMkS2NvbQ19fH7169SoyIdyH5fzOzs5ISkrC//73Pxw9ehRff/012rVrhz179kAoFMLKykrq/d7FzeJeWFiILVu2IC0tDVpaWhLtGzZskJjMoLjyiff/LatPccckFAoxfPhwjB07tkjfatWqIT4+Xmrs72/73r176NSpE0aMGIF58+bB1NQUp0+fxuDBg2VOvCAUCqGpqYno6GhoakqOrBsaGkpdJzAwEBMnTpRoW1pXetUDERERERFRaQgVuO+JEydiwIABcHV1hZubG3755RekpKRgxIgRAN7mQg8fPsSWLVsAACNGjMDq1asxceJEDB06FOfOncOGDRuwffv2Movxk5J5U1NTeHt746effsLYsWOLJKUvXryAiYkJateujZSUFNy/f188On/z5k1kZmbCyckJABAVFQV/f39x2Xp2dnaRSeeKU758efTu3Ru9e/dGr1690KFDBzx//hzOzs7ipPzdffQfExYWhqysLMTExEgks7du3UK/fv3w7NkzmJmZwcLCAhcvXkTLli0BvE32Y2Ji0LBhQwBAjRo1oK2tjYsXL4qP+eXLl7hz5w48PDxkxuDs7IwbN27A3t5e6vu1atVCQUEBYmJixNUACQkJePHihbjP5cuXUVBQgKVLl4pvDdi1a5fEdnR0dFBYWCjR1qhRIxQWFiI9PV18bB8jrVSFJfZERERERCQPikzme/fujWfPnmHu3LlITU1F3bp1ERYWJr69OzU1VaKa3NbWFmFhYZgwYQJ++uknVK5cGStXrkTPnj3LLMZPSuYBYM2aNXB3d0eTJk0wd+5c1K9fHwUFBYiIiMDatWsRFxeHdu3aoX79+ujXrx9CQkJQUFCAkSNHwsPDQ1xibm9vj3379qFr164QCAQICgqCUPjx/23Lly+HlZUVGjZsCA0NDezevRuWlpYwMTFBu3bt4ObmBl9fXyxatAiOjo549OgRwsLC4OvrW6S8HXhbYt+5c2eJ+/cBoE6dOhg/fjx+++03jBs3DmPGjEFwcDDs7e1Rq1YtrFq1ChkZGeKReCMjIwwcOBBTpkyBqakpzM3Nxffcf+y2hGnTpqFZs2YYNWoUhg4dCgMDA8TFxSEiIgKrVq1CrVq10K5dOwwbNgxr166FtrY2Jk2aBH19ffG2a9SogYKCAqxatQpdu3bFmTNnsG7dOon92NjYIDs7G8eOHUODBg1Qrlw5ODg4oF+/fvDz88PSpUvRqFEjPH36FMePH0e9evXQqVOnj/4/ISIiIiIiUhcjR47EyJEjpb4XGhpapM3Dw0PqxOdl5ZMfTWdra4srV67A09MTkyZNQt26ddG+fXscO3YMa9euBfC21PzAgQOoUKECWrVqhXbt2sHOzg47d+4Ub2f58uWoUKEC3N3d0bVrV3h7e0vcE14cQ0NDLFq0CK6urmjcuDGSk5MRFhYmTprDwsLQqlUrBAQEwMHBAX369EFycrLUCQseP36Mv/76S+q3JgKBAD169BA/c37atGn45ptv4OfnBzc3N/F97Xp6euJ1li1bBjc3N3Tp0gXt2rVD8+bN4eTkJNFHmvr16+PkyZO4c+cOWrZsiUaNGiEoKAhWVlbiPlu2bIGFhQVatWqF7t27Y+jQoTAyMhJvu2HDhli2bBkWLVqEunXrYtu2bUUeueDu7o4RI0agd+/eqFSpEhYvXgzg7UR9fn5+mDRpEhwdHdGtWzdcuHBBYs4DIiIiIiKiL0EkkN+ijgQiaTdzU4kJhUI4OTnh66+/xrx586T2ycnJQZUqVbB06VIMHjxYrvt/8OABrK2tcfToUfHs+Yo0r3o/RYegNv5G8RMWUul0KJA+7wOVzjXtAkWHoDaeiPI+3olKZFP0EkWHoBamun6v6BDURoP8Ty58pQ/c1C78eCf6qMXJZXfPdllbY91fbtsaef83uW1LWfCnTSndu3cPR44cgYeHB3Jzc7F69WokJSWhb9++4j4xMTG4desWmjRpgszMTMydOxcA4OPj89n7P378OLKzs1GvXj2kpqZi6tSpsLGxQatWrT5720RERERERKQamMyXkoaGBkJDQzF58mSIRCLUrVsXR48eFU/o986SJUsQHx8vfqxBVFSU+JF3nyM/Px/ff/897t69CyMjI7i7u2Pbtm1l9rgDIiIiIiIiRVDkBHiqgMl8KVlbW+PMmTMy+zRq1AjR0dFlsn9vb294e3uXybaJiIiIiIiUBe8Hl+2TJ8AjIiIiIiIiIsXgyDwREREREREpHaGazkIvL0zmiYiIiIiISOnwnnnZWGZPREREREREpGI4Mk9ERERERERKhyPzsjGZJyIiIiIiIqXD2exlY5k9ERERERERkYrhyDwREREREREpHc5mLxuTeSIiIiIiIlI6vGdeNpbZExEREREREakYjswTERERERGR0uEEeLIxmSciIiIiIiKlI2Q6LxOTeZKrB4I8RYegNjT4s0tuzAsKFR2CWjhemKLoENTGdoMKig5BbUx1/V7RIaiFxZd/UHQIamOG63RFh6A2eL80kWxM5omIiIiIiEjp8Asd2ZjMExERERERkdJhoapsnM2eiIiIiIiISMVwZJ6IiIiIiIiUDsvsZWMyT0REREREREpHKFB0BMqNZfZEREREREREKoYj80RERERERKR0+Jx52ZjMExERERERkdJhKi8by+yJiIiIiIiIVAxH5omIiIiIiEjpcDZ72ZjMExERERERkdLhPfOyscyeiIiIiIiISMVwZJ6IiIiIiIiUDsflZWMyT0REREREREqH98zLxjJ7IiIiIiIiIhWjEsl869atMX78eEWHQURERERERF+IECK5LepIaZJ5f39/CASCIktCQgL27duHefPmfbFYvLy8oKmpifPnz3+xfX5Js2fPRsOGDRUdBhERERERUbFEclzUkdIk8wDQoUMHpKamSiy2trYwNTWFkZHRF4khJSUF586dw+jRo7Fhw4Yvsk8AyM/P/2L7IiIiIiIiItWmVMm8rq4uLC0tJRZNTc0iZfY2Njb44YcfEBAQACMjI1SrVg2//PKLxLYePnyI3r17o0KFCjAzM4OPjw+Sk5M/GsOmTZvQpUsXfPvtt9i5cydycnIk3s/KykK/fv1gYGAAKysrLF++vEh8qamp6Ny5M/T19WFra4vff/8dNjY2CAkJEfcRCARYt24dfHx8YGBggPnz5wMA/vzzT7i4uEBPTw92dnaYM2cOCgoKxOvdunULLVq0gJ6eHmrXro2jR49CIBDgwIED4j7Tpk2Dg4MDypUrBzs7OwQFBYm/LAgNDcWcOXNw9epVcfVDaGgoACAzMxPDhg2Dubk5ypcvjzZt2uDq1asfPWdERERERETyJpTjUlYyMjIwYMAAGBsbw9jYGAMGDMCLFy+K7Z+fn49p06ahXr16MDAwQOXKleHn54dHjx6Vet9KlcyXxtKlS+Hq6oqYmBiMHDkS3377LW7dugUAePXqFTw9PWFoaIhTp07h9OnTMDQ0RIcOHZCXl1fsNkUiETZt2oT+/fujVq1acHBwwK5duyT6TJw4EWfOnMHBgwcRERGBqKgoXLlyRaLPu/8ZkZGR2Lt3L3755Rekp6cX2d+sWbPg4+OD69evIyAgAIcPH0b//v0xduxY3Lx5Ez///DNCQ0OxYMECAIBQKISvry/KlSuHCxcu4JdffsH06dOLbNfIyAihoaG4efMmVqxYgV9//RXLly8HAPTu3RuTJk1CnTp1xNUPvXv3hkgkQufOnZGWloawsDBER0fD2dkZbdu2xfPnz0v3P4eIiIiIiOgzieT4X1np27cvYmNjER4ejvDwcMTGxmLAgAHF9n/16hWuXLmCoKAgXLlyBfv27cPt27fRrVu3Uu9bqR5Nd+jQIRgaGopfd+zYEbt375bat1OnThg5ciSAtyPRy5cvR2RkJGrVqoUdO3ZAQ0MD69evh0AgAPB2xN3ExASRkZHw8vKSus2jR4/i1atX8Pb2BgD0798fGzZswKBBgwC8HZXfvHkzfv/9d7Rt21a83cqVK4u3cevWLRw9ehSXLl2Cq6srAGD9+vWoWbNmkf317dsXAQEB4tcDBgzAd999h4EDBwIA7OzsMG/ePEydOhWzZs3CkSNHkJiYiMjISFhaWgIAFixYgPbt20tsd8aMGeJ/29jYYNKkSdi5cyemTp0KfX19GBoaQktLS7wNADh+/DiuX7+O9PR06OrqAgCWLFmCAwcOYM+ePRg2bFiR+HNzc5GbmyvRVigqhKZAU+r5JSIiIiIiUgRpuYuurq449/kUcXFxCA8Px/nz59G0aVMAwK+//go3NzfEx8fD0dGxyDrGxsaIiIiQaFu1ahWaNGmClJQUVKtWrcT7V6qReU9PT8TGxoqXlStXFtu3fv364n8LBAJYWlqKR7+jo6ORkJAAIyMjGBoawtDQEKampnjz5g0SExOL3eaGDRvQu3dvaGm9/Y7jm2++wYULFxAfHw8AuHv3LvLz89GkSRPxOsbGxhL/k+Lj46GlpQVnZ2dxm729PSpUqFBkf++S/Xeio6Mxd+5cccyGhoYYOnQoUlNT8erVK8THx8Pa2loiCX8/lnf27NmDFi1awNLSEoaGhggKCkJKSkqxx/1u39nZ2TAzM5PYf1JSUrHnLDg4WFxO8m6Jybwlcz9EREREREQlIc8ye2m5S3Bw8GfFd+7cORgbG4sTeQBo1qwZjI2Ncfbs2RJvJzMzEwKBACYmJqXav1KNzBsYGMDe3r5EfbW1tSVeCwQCCIVv74YQCoVwcXHBtm3biqxXqVIlqdt7/vw5Dhw4gPz8fKxdu1bcXlhYiI0bN2LRokUQiUTifb3vXfuH/y6uzzsGBgYSr4VCIebMmYMePXoU6aunpweRSFRk3x86f/48+vTpgzlz5sDb2xvGxsbYsWMHli5dKnM9oVAIKysrREZGFnmvuA9VYGAgJk6cKNE2sZ6/zP0QERERERGVhDwfKSctd/mcUXkASEtLg7m5eZF2c3NzpKWllWgbb968wXfffYe+ffuifPnypdq/UiXz8uLs7IydO3eKJ3IriW3btqFq1aoSE8kBwLFjxxAcHIwFCxagRo0a0NbWxsWLF2FtbQ0AePnyJe7cuQMPDw8AQK1atVBQUICYmBi4uLgAABISEmROgvB+3PHx8cV+oVGrVi2kpKTg8ePHsLCwAABcunRJos+ZM2dQvXp1iXvp7927J9FHR0cHhYWFRfadlpYGLS0t2NjYfDRWQHpZCkvsiYiIiIhI2ZSmpH727NmYM2eOzD7v8jBpg60lGYQF3k6G16dPHwiFQqxZs6ZEsb1PLZP5fv364ccff4SPjw/mzp2LqlWrIiUlBfv27cOUKVNQtWrVIuts2LABvXr1Qt26dSXaq1evjmnTpuGvv/6Cj48PBg4ciClTpsDU1BTm5uaYNWsWNDQ0xP+zatWqhXbt2mHYsGFYu3YttLW1MWnSJOjr63/0f+jMmTPRpUsXWFtb46uvvoKGhgauXbuG69evY/78+Wjfvj1q1KiBgQMHYvHixcjKyhIn7e+2bW9vj5SUFOzYsQONGzfGX3/9hf3790vsx8bGBklJSYiNjUXVqlVhZGSEdu3awc3NDb6+vli0aBEcHR3x6NEjhIWFwdfXt8gtAURERERERGVJUc+HHz16NPr06SOzj42NDa5du4bHjx8Xee/Jkyfiwdfi5Ofn4+uvv0ZSUhKOHz9e6lF5QMnumZeXcuXK4dSpU6hWrRp69OgBJycnBAQE4PXr11JPUnR0NK5evYqePXsWec/IyAheXl7iZ84vW7YMbm5u6NKlC9q1a4fmzZvDyckJenp64nW2bNkCCwsLtGrVCt27d8fQoUNhZGQk0Ucab29vHDp0CBEREWjcuDGaNWuGZcuWoXr16gAATU1NHDhwANnZ2WjcuDGGDBkinuzu3bZ9fHwwYcIEjB49Gg0bNsTZs2cRFBQksZ+ePXuiQ4cO8PT0RKVKlbB9+3YIBAKEhYWhVatWCAgIgIODA/r06YPk5OSPfhCJiIiIiIjkTQiR3JbSqFixImrVqiVz0dPTg5ubGzIzM3Hx4kXxuhcuXEBmZibc3d2L3f67RP7OnTs4evQozMzMPun8CETF3eRNJZKTk4MqVapg6dKlGDx4sNQ+Dx48gLW1NY4ePSqeBV9ezpw5gxYtWiAhIQE1atSQ67Y/xXCbrxQdgtp4KcpXdAhqo/8bfUWHoBa+F9z7eCcqke0GRSdFpU/za6GRokNQC4sv/6DoENTGDNeijw2mT1P48S5UAkuStys6hE8mz9zi52TpT0n7XB07dsSjR4/w888/AwCGDRuG6tWr488//xT3qVWrFoKDg9G9e3cUFBSgZ8+euHLlCg4dOiQxcGpqagodHZ0S71sty+zLUkxMDG7duoUmTZogMzMTc+fOBfB2RPyd48ePIzs7G/Xq1UNqaiqmTp0KGxsbtGrV6rP3v3//fhgaGqJmzZpISEjAuHHj0Lx5c6VI5ImIiIiIiORFqOgASmDbtm0YO3as+PHn3bp1w+rVqyX6xMfHIzMzE8Dbgd6DBw8CABo2bCjR78SJE2jdunWJ981k/hMsWbIE8fHx0NHRgYuLC6KiolCxYkXx+/n5+fj+++9x9+5dGBkZwd3dHdu2bSsyA/+nyMrKwtSpU3H//n1UrFgR7dq1++hM9URERERERKpGpLC75kvO1NQUv/32m8w+7xfD29jYFPsEtNJiMl9KjRo1QnR0tMw+3t7e8Pb2LpP9+/n5wc/Pr0y2TURERERERKqByTwREREREREpHVUos1ckJvNERERERESkdFShzF6R1PLRdERERERERETqjCPzREREREREpHRYZi8bk3kiIiIiIiJSOkI5zfqurlhmT0RERERERKRiODJPRERERERESofj8rIxmSciIiIiIiKlI2Q6LxPL7ImIiIiIiIhUDEfmiYiIiIiISOnwOfOyMZknIiIiIiIipcNH08nGMnsiIiIiIiIiFcOReZIrn9eaig5BbdzV0VV0CGrjlH6hokNQC3+YGCg6BLWx7IWhokNQG875/FNGHma4Tld0CGpj/uUFig5BbTzrEaDoEEjBOAGebPwNSEREREREREqH98zLxjJ7IiIiIiIiIhXDkXkiIiIiIiJSOpwATzYm80RERERERKR0RCKW2cvCMnsiIiIiIiIiFcOReSIiIiIiIlI6nM1eNibzREREREREpHR4z7xsLLMnIiIiIiIiUjEcmSciIiIiIiKlw+fMy8ZknoiIiIiIiJQO75mXjWX2RERERERERCqGI/NERERERESkdPicedmYzBMREREREZHS4Wz2srHMnoiIiIiIiEjFcGSeiIiIiIiIlA5ns5eNI/Nq5OzZs9DU1ESHDh0UHQoREREREdFnEUIkt0UdMZlXIxs3bsSYMWNw+vRppKSkKDocIiIiIiIiKiNM5tVETk4Odu3ahW+//RZdunRBaGioxPsHDx5EzZo1oa+vD09PT2zevBkCgQAvXrwQ9zl79ixatWoFfX19WFtbY+zYscjJyfmyB0JERERERIS3s9nLa1FHTObVxM6dO+Ho6AhHR0f0798fmzZtEn9ok5OT0atXL/j6+iI2NhbDhw/H9OnTJda/fv06vL290aNHD1y7dg07d+7E6dOnMXr0aEUcDhERERER/cexzF42JvNqYsOGDejfvz8AoEOHDsjOzsaxY8cAAOvWrYOjoyN+/PFHODo6ok+fPvD395dY/8cff0Tfvn0xfvx41KxZE+7u7li5ciW2bNmCN2/eSN1nbm4uXr58KbHkiwrL9DiJiIiIiIiIybxaiI+Px8WLF9GnTx8AgJaWFnr37o2NGzeK32/cuLHEOk2aNJF4HR0djdDQUBgaGooXb29vCIVCJCUlSd1vcHAwjI2NJZZdOXFlcIRERERERPRfI5Ljf+qIybwa2LBhAwoKClClShVoaWlBS0sLa9euxb59+5CRkQGRSASBQCCxzof3jQiFQgwfPhyxsbHi5erVq7hz5w5q1Kghdb+BgYHIzMyUWL42cCqz4yQiIiIiov8OoUgkt6WsZGRkYMCAAeLBzQEDBkjMS/Yxw4cPh0AgQEhISKn3zefMq7iCggJs2bIFS5cuhZeXl8R7PXv2xLZt21CrVi2EhYVJvHf58mWJ187Ozrhx4wbs7e1LvG9dXV3o6upKtGkLNEt5BERERERERKqpb9++ePDgAcLDwwEAw4YNw4ABA/Dnn39+dN0DBw7gwoULqFy58iftm8m8ijt06BAyMjIwePBgGBsbS7zXq1cvbNiwAfv27cOyZcswbdo0DB48GLGxseLZ7t+N2E+bNg3NmjXDqFGjMHToUBgYGCAuLg4RERFYtWrVlz4sIiIiIiL6j1P24vi4uDiEh4fj/PnzaNq0KQDg119/hZubG+Lj4+Ho6Fjsug8fPsTo0aNx+PBhdO7c+ZP2zzJ7Fbdhwwa0a9euSCIPvB2Zj42NRUZGBvbs2YN9+/ahfv36WLt2rXg2+3cj6/Xr18fJkydx584dtGzZEo0aNUJQUBCsrKy+6PEQEREREREB8p3NXtrk3bm5uZ8V37lz52BsbCxO5AGgWbNmMDY2xtmzZ4s/LqEQAwYMwJQpU1CnTp1P3j9H5lWcrPINZ2dn8b3xzs7O6Natm/i9BQsWoGrVqtDT0xO3NW7cGEeOHCm7YImIiIiIiBQgODgYc+bMkWibNWsWZs+e/cnbTEtLg7m5eZF2c3NzpKWlFbveokWLoKWlhbFjx37yvgEm8/8Za9asQePGjWFmZoYzZ87gxx9/5DPkiYiIiIhIacnz+fCBgYGYOHGiRNuH83+9M3v27CKJ/4cuXboEAEUmGgcgdQLyd6Kjo7FixQpcuXKl2D4lxWT+P+LOnTuYP38+nj9/jmrVqmHSpEkIDAxUdFhERERERERlTtrk3cUZPXq0+LHfxbGxscG1a9fw+PHjIu89efIEFhYWUteLiopCeno6qlWrJm4rLCzEpEmTEBISguTk5BLFCDCZ/89Yvnw5li9frugwiIiIiIiISuTDx2l/KRUrVkTFihU/2s/NzQ2ZmZm4ePEimjRpAgC4cOECMjMz4e7uLnWdAQMGoF27dhJt3t7eGDBgAAYNGlSqOJnMExERERERkdKRZ5l9WXByckKHDh0wdOhQ/PzzzwDePpquS5cuEjPZ16pVC8HBwejevTvMzMxgZmYmsR1tbW1YWlrKnP1eGs5mT0RERERERPQJtm3bhnr16sHLywteXl6oX78+tm7dKtEnPj4emZmZct83R+aJiIiIiIhI6YiUfGQeAExNTfHbb7/J7POx2wVKc5/8+5jMExERERERkdJR1D3zqoJl9kREREREREQqhiPzREREREREpHSUfQI8RWMyT0REREREREqHZfayscyeiIiIiIiISMVwZJ6IiIiIiIiUDsvsZWMyT0REREREREpHFR5Np0gssyciIiIiIiJSMRyZJyIiIiIiIqUj5AR4MjGZJyIiIiIiIqXDMnvZmMyTXLX8JkfRIagNox26ig5BbWRq8FzKw5SMcooOQW2srZ2m6BDUxuK4yooOQS0IFR2AGnnWI0DRIagNs30bFR0CkVJjMk9ERERERERKh2X2sjGZJyIiIiIiIqXDMnvZOJs9ERERERERkYrhyDwREREREREpHZbZy8ZknoiIiIiIiJQOy+xlY5k9ERERERERkYrhyDwREREREREpHZbZy8ZknoiIiIiIiJQOy+xlY5k9ERERERERkYrhyDwREREREREpHZFIqOgQlBqTeSIiIiIiIlI6QpbZy8QyeyIiIiIiIiIVw5F5IiIiIiIiUjoizmYvE5N5IiIiIiIiUjoss5eNZfYEAAgNDYWJiYmiwyAiIiIiIqISYDL/mdLT0zF8+HBUq1YNurq6sLS0hLe3N86dOwcAEAgEOHDggGKD/ICNjQ1CQkIUHQYREREREVGxRCKR3BZ1xDL7z9SzZ0/k5+dj8+bNsLOzw+PHj3Hs2DE8f/68xNvIz8+HtrZ2GUZJRERERESkWoRqmoTLC0fmP8OLFy9w+vRpLFq0CJ6enqhevTqaNGmCwMBAdO7cGTY2NgCA7t27QyAQiF/Pnj0bDRs2xMaNG2FnZwddXV2IRCJkZmZi2LBhMDc3R/ny5dGmTRtcvXpVvL93623duhU2NjYwNjZGnz59kJWVJe6TlZWFfv36wcDAAFZWVli+fDlat26N8ePHAwBat26Ne/fuYcKECRAIBBAIBBLHdPjwYTg5OcHQ0BAdOnRAampqmZ5DIiIiIiIiKj0m85/B0NAQhoaGOHDgAHJzc4u8f+nSJQDApk2bkJqaKn4NAAkJCdi1axf27t2L2NhYAEDnzp2RlpaGsLAwREdHw9nZGW3btpUY5U9MTMSBAwdw6NAhHDp0CCdPnsTChQvF70+cOBFnzpzBwYMHERERgaioKFy5ckX8/r59+1C1alXMnTsXqampEsn6q1evsGTJEmzduhWnTp1CSkoKJk+eLLfzRUREREREVFIiOf6njlhm/xm0tLQQGhqKoUOHYt26dXB2doaHhwf69OmD+vXro1KlSgAAExMTWFpaSqybl5eHrVu3ivscP34c169fR3p6OnR1dQEAS5YswYEDB7Bnzx4MGzYMACAUChEaGgojIyMAwIABA3Ds2DEsWLAAWVlZ2Lx5M37//Xe0bdsWwNsvEipXrizer6mpKTQ1NWFkZFQkpvz8fKxbtw41atQAAIwePRpz584t9vhzc3OLfImRV1AIXS3N0p1IIiIiIiKiD6jrve7ywpH5z9SzZ088evQIBw8ehLe3NyIjI+Hs7IzQ0FCZ61WvXl2cyANAdHQ0srOzYWZmJh7xNzQ0RFJSEhITE8X9bGxsxIk8AFhZWSE9PR0AcPfuXeTn56NJkybi942NjeHo6FiiYylXrpw4kf9w29IEBwfD2NhYYll6OaFE+yIiIiIiIqJPx5F5OdDT00P79u3Rvn17zJw5E0OGDMGsWbPg7+9f7DoGBgYSr4VCIaysrBAZGVmk7/uPjPtwojyBQAChUAjg32+uPrwPvqTfaEnbtqx1AwMDMXHiRIm2vO/7lGhfREREREREsvA587IxmS8DtWvXFj+OTltbG4WFhR9dx9nZGWlpadDS0hJPlFdaNWrUgLa2Ni5evAhra2sAwMuXL3Hnzh14eHiI++no6JQopo/R1dUV3xLwThZL7ImIiIiISA5YZi8by+w/w7Nnz9CmTRv89ttvuHbtGpKSkrB7924sXrwYPj4+AN6WxR87dgxpaWnIyMgodlvt2rWDm5sbfH19cfjwYSQnJ+Ps2bOYMWMGLl++XKJ4jIyMMHDgQEyZMgUnTpzAjRs3EBAQAA0NDYnRehsbG5w6dQoPHz7E06dPP+8kEBERERER0RfHZP4zGBoaomnTpli+fDlatWqFunXrIigoCEOHDsXq1asBAEuXLkVERASsra3RqFGjYrclEAgQFhaGVq1aISAgAA4ODujTpw+Sk5NhYWFR4piWLVsGNzc3dOnSBe3atUPz5s3h5OQEPT09cZ+5c+ciOTkZNWrUkLhvn4iIiIiISFkIRSK5LepIIGLtglrLyclBlSpVsHTpUgwePLjM95c1vmuZ7+O/InaH7sc7UYmc0uW5lIdYZCs6BLWxtvYLRYegNhbHVf54J/oooaIDUCOTq6V+vBOViNm+jYoOQS1oV7RTdAifrIKhvdy2lZFdNhN1Z2RkYOzYsTh48CAAoFu3bli1apXEvGfSxMXFYdq0aTh58iSEQiHq1KmDXbt2oVq1aiXeN0fm1UxMTAy2b9+OxMREXLlyBf369QMAcdk/ERERERERyUffvn0RGxuL8PBwhIeHIzY2FgMGDJC5TmJiIlq0aIFatWohMjISV69eRVBQkEQ1dUlwAjw1tGTJEsTHx0NHRwcuLi6IiopCxYoVFR0WERERERFRiclzNvvc3Fzk5uZKtEmb0Ls04uLiEB4ejvPnz6Np06YAgF9//RVubm6Ij48v9hHh06dPR6dOnbB48WJxm51d6SsoODKvZho1aiR+Zv3z588RERGBevXqKTosIiIiIiKiUhGJRHJbgoODYWxsLLEEBwd/Vnznzp2DsbGxOJEHgGbNmsHY2Bhnz56Vuo5QKMRff/0FBwcHeHt7w9zcHE2bNhU/Da00mMwTERERERGRWgsMDERmZqbEEhgY+FnbTEtLg7m5eZF2c3NzpKWlSV0nPT0d2dnZWLhwITp06IAjR46ge/fu6NGjB06ePFmq/bPMnoiIiIiIiJSOPGehL01J/ezZszFnzhyZfS5dugQAEo8Af0ckEkltB96OzANv5zSbMGECAKBhw4Y4e/Ys1q1bBw8PjxLFCDCZJyIiIiIiIiUkkuM986UxevRo9OnTR2YfGxsbXLt2DY8fPy7y3pMnT4p9vHjFihWhpaWF2rVrS7Q7OTnh9OnTpYqTyTwRERERERHRPypWrFiiCcTd3NyQmZmJixcvokmTJgCACxcuIDMzE+7u7lLX0dHRQePGjREfHy/Rfvv2bVSvXr1UcfKeeSIiIiIiIlI6QpFIbktZcHJyQocOHTB06FCcP38e58+fx9ChQ9GlSxeJmexr1aqF/fv3i19PmTIFO3fuxK+//oqEhASsXr0af/75J0aOHFmq/TOZJyIiIiIiIqUjz9nsy8q2bdtQr149eHl5wcvLC/Xr18fWrVsl+sTHxyMzM1P8unv37li3bh0WL16MevXqYf369di7dy9atGhRqn2zzJ6IiIiIiIjoE5iamuK3336T2UfalwkBAQEICAj4rH0zmSciIiIiIiKlo6gJ8FQFk3kiIiIiIiJSOmVZHq8OeM88ERERERERkYrhyDwREREREREpHY7My8ZknoiIiIiIiJQOU3nZWGZPREREREREpGIEItYu0H9Mbm4ugoODERgYCF1dXUWHo7J4HuWH51J+eC7lg+dRfngu5YfnUj54HuWH55IUjck8/ee8fPkSxsbGyMzMRPny5RUdjsrieZQfnkv54bmUD55H+eG5lB+eS/ngeZQfnktSNJbZExEREREREakYJvNEREREREREKobJPBEREREREZGKYTJP/zm6urqYNWsWJyr5TDyP8sNzKT88l/LB8yg/PJfyw3MpHzyP8sNzSYrGCfCIiIiIiIiIVAxH5omIiIiIiIhUDJN5IiIiIiIiIhXDZJ6IiIiIiIhIxTCZJyIiIiIiIlIxTOaJiEglFRYW4uTJk8jIyFB0KERURl68eIH169cjMDAQz58/BwBcuXIFDx8+VHBkRESKx9nsSe2lpKTA2toaAoFAol0kEuH+/fuoVq2agiJTLQcPHpTaLhAIoKenB3t7e9ja2n7hqFRTYWEhQkNDcezYMaSnp0MoFEq8f/z4cQVFpnr09PQQFxfHz95nys/Px7BhwxAUFAQ7OztFh6PyEhMTsWnTJiQmJmLFihUwNzdHeHg4rK2tUadOHUWHpzKuXbuGdu3awdjYGMnJyYiPj4ednR2CgoJw7949bNmyRdEhqpS8vDwkJSWhRo0a0NLSUnQ4RCQHHJkntWdra4snT54UaX/+/DkTgFLw9fVF9+7d4evrW2Tx9vaGvb09PDw8OEpaAuPGjcO4ceNQWFiIunXrokGDBhILlVy9evVw9+5dRYeh8rS1tbF//35Fh6EWTp48iXr16uHChQvYt28fsrOzAbxNTGfNmqXg6FTLxIkT4e/vjzt37kBPT0/c3rFjR5w6dUqBkamWV69eYfDgwShXrhzq1KmDlJQUAMDYsWOxcOFCBUeneh4/fowBAwagcuXK0NLSgqampsRC9CXxazlSeyKRqMioPABkZ2dL/HFAskVERGD69OlYsGABmjRpAgC4ePEiZsyYgaCgIBgbG2P48OGYPHkyNmzYoOBolduOHTuwa9cudOrUSdGhqLwFCxZg8uTJmDdvHlxcXGBgYCDxfvny5RUUmerp3r07Dhw4gIkTJyo6FJX23XffYf78+Zg4cSKMjIzE7Z6enlixYoUCI1M9ly5dws8//1ykvUqVKkhLS1NARKopMDAQV69eRWRkJDp06CBub9euHWbNmoXvvvtOgdGpHn9/f6SkpCAoKAhWVlZS/8Yk+lKYzJPaevcHqUAgQFBQEMqVKyd+r7CwEBcuXEDDhg0VFJ3qGTduHH755Re4u7uL29q2bQs9PT0MGzYMN27cQEhICAICAhQYpWrQ0dGBvb29osNQC+/+MO3WrZvEH1TvvsQrLCxUVGgqx97eHvPmzcPZs2elfjEyduxYBUWmWq5fv47ff/+9SHulSpXw7NkzBUSkuvT09PDy5csi7fHx8ahUqZICIlJNBw4cwM6dO9GsWTOJn5O1a9dGYmKiAiNTTadPn0ZUVBT/hiSlwGSe1FZMTAyAt3/UX79+HTo6OuL3dHR00KBBA0yePFlR4amcxMREqaOc5cuXF5c516xZE0+fPv3SoamcSZMmYcWKFVi9ejW/0f9MJ06cUHQIamP9+vUwMTFBdHQ0oqOjJd4TCARM5kvIxMQEqampRW7jiomJQZUqVRQUlWry8fHB3LlzsWvXLgBvP4cpKSn47rvv0LNnTwVHpzqePHkCc3PzIu05OTn8HfQJrK2twSnHSFlwAjxSe4MGDcKKFStYbvuZWrRoASMjI2zZskU8IvLkyRP4+fkhJycHp06dwtGjRzFy5Ejcvn1bwdEqnx49eki8Pn78OExNTVGnTh1oa2tLvLdv374vGRoRydHUqVNx7tw57N69Gw4ODrhy5QoeP34MPz8/+Pn58b75Unj58iU6deqEGzduICsrC5UrV0ZaWhrc3NwQFhZWpHqEpPPw8ECvXr0wZswYGBkZ4dq1a7C1tcXo0aORkJCA8PBwRYeoUo4cOYKlS5fi559/ho2NjaLDof84JvNEVCLx8fHw8fFBUlKS+OkAKSkpsLOzwx9//AEHBwccOHAAWVlZGDBggKLDVTqDBg0qcd9NmzaVYSTqJyoqCj///DPu3r2L3bt3o0qVKti6dStsbW3RokULRYencjjj9efJz8+Hv78/duzYAZFIBC0tLRQWFqJv374IDQ3lBFmf4Pjx47hy5QqEQiGcnZ3Rrl07RYekUs6ePYsOHTqgX79+CA0NxfDhw3Hjxg2cO3cOJ0+ehIuLi6JDVHoVKlSQqGLIyclBQUEBypUrV+QL+XePUCT6EpjMk9rLycnBwoULi30MGGfCLjmRSITDhw/j9u3bEIlEqFWrFtq3bw8NDT4YgxRj7969GDBgAPr164etW7fi5s2bsLOzw5o1a3Do0CGEhYUpOkSV8erVK4wZMwabN28GANy+fRt2dnYYO3YsKleuzEmySunu3bviBLRRo0aoWbOmokNSOVu2bEHv3r2hq6sr0Z6Xl4cdO3bAz89PQZGpnuvXr2PJkiWIjo4Wfykybdo01KtXT9GhqYR3PxdLYuDAgWUYCZEkJvOk9r755hucPHkSAwYMkDrr6Lhx4xQUGf1XvX79GiKRSDwp471797B//37Url0bXl5eCo5OtTRq1AgTJkyAn58fjIyMcPXqVdjZ2SE2NhYdOnTgjNelMG7cOJw5cwYhISHo0KEDrl27Bjs7Oxw8eBCzZs0Sz0NCss2dOxeTJ0+WmHQVeHvd//jjj5g5c6aCIlM9mpqaSE1NLXK/97Nnz2Bubs4JLonoP4/JPKk9ExMT/PXXX2jevLmiQ1F5OTk5OHnyJFJSUpCXlyfxHifHKjkvLy/06NEDI0aMwIsXL+Do6AgdHR08ffoUy5Ytw7fffqvoEFVGuXLlcPPmTdjY2Egk83fv3kXt2rXx5s0bRYeoMqpXry6e8fr9c5mQkABnZ2eps4pTUUxA5UdDQwOPHz8uMnP91atX4enpyXLmEiru2hUIBNDV1ZWYIJg+jtc4KRPeDEdqr0KFCjA1NVV0GCovJiYGnTp1wqtXr5CTkwNTU1M8ffoU5cqVg7m5OZP5Urhy5QqWL18OANizZw8sLS0RExODvXv3YubMmUzmS8HKygoJCQlFJiE6ffo07OzsFBOUiuKM1/Lx7rGIH7p69Sp/F5VQo0aNIBAIIBAI0LZtW4m5GwoLC5GUlCTxvHSSzcTEROY1XLVqVfj7+2PWrFm8ba4EihsHzc3N5Rcj9MUxmSe1N2/ePMycORObN28uUvZIJTdhwgR07doVa9euhYmJCc6fPw9tbW3079+ftyqU0qtXr2BkZATg7ay4PXr0gIaGBpo1a4Z79+79v727j6v57v8A/jrlpnVfoyZaqVQiN5HF3KUkbCts2jIkm7iu0ZUxXIaxMVxuu8bcVWO3cjMXFxtdUhQJpxs3SXS3RWqUpFDnnN8fHs5vZ8WOoU/f0+v5eFyPx3U+n/PH69Fjxznv7+fzeX8Ep5OWsLAwhIeHIzo6GjKZDFevXsWJEycwY8YMbmd+Qp6enti/fz+mTp0KAOof/5s3b0bv3r1FRpOEhw2yZDIZnJ2dNYonhUKByspKTJ48WWBC6QgMDAQApKenY8iQITA2NlbPtWjRAvb29rya7gl89dVXmDt3LkJCQtCrVy+oVCqcOnUKW7duxccff4zS0lKsWLECLVu2xD//+U/RcRutyMhIAA/+bdyyZYvGf5cKhQJHjx6Fq6urqHjURHGbPem87t2748qVK1CpVLC3t6/TdVQulwtKJi3m5uY4efIkXFxcYG5ujhMnTqBjx444efIkxo8fj4sXL4qOKBldunTBe++9hxEjRqBz5874+eef0bt3b5w5cwbDhw/nOe8nNHfuXKxevVq9pb5ly5aYMWMGPv30U8HJpIUdr5/O1q1boVKpEBoaijVr1sDMzEw997AA5UORJ7N161YEBQXBwMBAdBRJ8/HxQVhYGEaPHq0xHhsbi40bN+Lw4cP4+uuvsXjxYn6XP0b79u0BPOhz065dO42bKR5+xhctWoRXXnlFVERqgljMk85buHDhY+d55692WrdujeTkZDg7O8PFxQWRkZEYMmQILl68CA8PD1RVVYmOKBk7d+5EcHAwFAoFfHx8cOjQIQDA559/jqNHj+Knn34SnFB6qqqqcOHCBSiVSri5uWmsmJD22PH66SUmJqJPnz51HhwTiWJoaIiMjIw6Nyrk5OSga9euqKqqQl5eHjp16sTvci14e3tj9+7dsLCwEB2FiMU8EWnHz88PISEhCA4OxuTJk5GWloZp06bh66+/RllZGU6ePCk6oqQUFxfj2rVr6Nq1q/qMYmpqKszMzODi4iI4nXSEhoZi7dq16mMLD925cwdTp05FdHS0oGREDzrY19TUaIyZmpoKSiM9CoUCq1evRmxsbL2NV9kATzvOzs4YOXIkli5dqjE+e/Zs/Pjjj8jOzsbp06cREBCAoqIiQSmJ6K9gMU9NQnl5OXbu3IkrV65g5syZsLS0hFwuh7W1Ndq2bSs6niScPn0at2/fhre3N0pLSzF+/HgkJSXByckJMTEx6Nq1q+iIkqZUKrF//35ERUVhz549ouNIxqO6Cv/222946aWXUFtbKyiZ9AwaNAgDBgyos1uprKwMo0aNQnx8vKBk0lJVVYWPPvoIsbGxuHHjRp15drrW3vz587FlyxZMnz4d8+bNw9y5c5Gfn489e/Zg/vz5bLyqpb179+Ktt96Cq6srPD09IZPJcOrUKWRlZWHXrl147bXX8OWXXyInJwerVq0SHbfRmz59er3jMpkMBgYGcHJyQkBAABteUoNgMU86LzMzE76+vjAzM0N+fj6ys7Ph4OCAefPmoaCgANu2bRMdkZqwnJwcREdHY+vWrSgrK8OQIUNYzGuhoqICKpUKFhYWyMnJ0bi6SqFQYN++fZg9ezauXr0qMKW06Onp4cUXX8Srr76Kb7/9FkZGRgCA69evw8bGhkWolv7+97/jyJEjWLRoEcaNG4d169ahqKgIGzduxNKlSzFmzBjRESXD0dERkZGRGD58OExMTJCenq4eS0lJwXfffSc6omQUFBTgyy+/xKVLl6BSqeDq6oqwsDCUl5ejW7duouNJire3N+RyORQKBVxcXKBSqZCTkwN9fX24uroiOzsbMpkMSUlJcHNzEx2XdByLedJ5vr6+8PDwwPLlyzXuTj5+/DiCg4ORn58vOiI1MdXV1YiNjUVUVBRSUlLUW0lDQ0N51ltLenp6j71qSSaTYeHChZg7d24DppI2PT09pKWlISwsDHfu3MG+fftgb2/PYv4Jvfzyy9i2bRsGDhwIU1NTyOVyODk54euvv8b333+PAwcOiI4oGUZGRsjKysLLL7+MNm3aYP/+/fDw8EBubi66d++OW7duiY4oSeXl5fj2228RHR2N9PR0fraf0Jo1a3Ds2DHExMSoj81UVFRg4sSJ6Nu3L95//30EBwejuroaBw8eFJyWdB2vpiOdd+rUKWzcuLHOeNu2bdk1/E88vOtXG7wV4M+lpqZiy5Yt2L59O5ydnfHuu+9ix44daNeuHXx9fVnIP4EjR45ApVJh0KBB2LVrl8Z2xhYtWsDOzg42NjYCE0pTmzZtkJiYiNDQUHh6emLHjh3o2LGj6FiScvPmTXXXa1NTU/W57r59+2LKlCkio0lOu3btcO3aNbz88stwcnLCoUOH4OHhgVOnTqFly5ai40lOfHw8oqOjsXv3btjZ2WHUqFHYsmWL6FiS869//QtxcXEa/S9MTU3xySefwM/PD+Hh4Zg/fz78/PwEpqSmgsU86TwDAwNUVFTUGc/OztbYmkt1Pbzrl56NPn36YOrUqUhNTWWTu6c0YMAAAEBeXh5sbW3VTQTpr3v44K5ly5b49ttv8dlnn8Hf3x+zZs0SnExaHBwckJ+fDzs7O7i5uSE2Nha9evXCvn37YG5uLjqepIwYMQKHDx/GK6+8gvDwcLzzzjuIiopCYWEhIiIiRMeThF9//RVfffUVoqOjcefOHYwePRo1NTXYtWsXt4D/Rbdu3UJJSUmdv19paan696a5uXmdho1EzwO32ZPOmzRpEkpLSxEbGwtLS0tkZmZCX18fgYGB6N+/P9asWSM6IjURfn5+SElJweuvv46xY8diyJAhkMlkaN68OTIyMvjD6ilUVVXV2+26S5cughJJj56eHoqLizWaCe7atQvjx49HdXU1t+JqafXq1dDX18e0adNw5MgRDB8+HAqFArW1tVi1ahXCw8NFR5SslJQUHD9+HE5OTnjjjTdEx2n0hg0bhqSkJLz22msYM2YM/P39oa+vz++cpzRmzBicOHECK1euVDcUTE1NxYwZM9CnTx98/fXX+OGHH7BixQqcPn1adFzScSzmSedVVFRg2LBhOH/+PG7fvg0bGxsUFxejd+/eOHDggLrJE2nv7t272L59O+7cuYPBgwfXubuWHu2XX35BTEwMYmJiUF1djaCgIKxfvx6ZmZnczvwXlJaWYsKECfjpp5/qnWcBqr2CgoJ6dzmcO3cOZ86cwfjx4wUlk7bCwkKcPn0ajo6OvPWDGlSzZs0wbdo0TJkyReN7msX806msrERERAS2bdumvjGlWbNmGD9+PFavXg0jIyOkp6cDAJsL0nPHYp6ajPj4eMjlciiVSnh4eMDX11d0JEmYOXMm7t+/j7Vr1wIA7t+/j169euHChQswNDREbW0tDh06hD59+ghOKj1xcXGIjo7Gnj17YGtrizfffBNvvvkmPDw8REeTjDFjxiA/Px9r1qyBt7c3fvzxR1y/fh2fffYZVq5cieHDh4uOSER/0d69e+sd//0VYA/7E1BdJ06cQHR0NGJjY+Hq6oqxY8ciKCgINjY2LOafgcrKSuTm5kKlUsHR0ZF9b0gIFvNE9FidO3fGkiVL1FsaY2Ji8OGHHyItLQ0vv/wyQkNDUVJSgv379wtOKl1lZWX45ptvEB0djczMTK4mP4E2bdrgP//5D3r16gVTU1OcPn0azs7O2Lt3L5YvX46kpCTRERu1kSNH4quvvoKpqSlGjhz52Pfu3r27gVJJW2RkZL3jvy9A+/fvD319/QZOJj0Pb63440/Vh2MymQx9+/bFnj17YGFhIShl41dVVYUffvgB0dHRSE1NhUKhwKpVqxAaGgoTExPR8YjoKbCYpyYhNTUVCQkJKCkpgVKp1JhbtWqVoFTS8PurlQDgnXfegYmJCTZt2gQASE9Px7Bhw3if9zMil8u5Mv8ETE1NkZmZCXt7e9jb2+Pbb7/Fq6++iry8PHTq1AlVVVWiIzZqEyZMQGRkJExMTDBhwoTHvjcmJqaBUklb+/btUVpaiqqqKlhYWEClUqG8vByGhoYwNjZGSUkJHBwccOTIEdja2oqO26gdPnwYc+fOxeLFi9GrVy8AD77PP/74Y8ybNw9mZmYICwvDK6+8gqioKMFppSE7OxtRUVH4+uuvUV5ejsGDBz9yBwTV786dO1i6dCkOHz5c7+/K3NxcQcmoKWI3e9J5S5YswccffwwXFxdYW1trXLWm7bVrTZmenp7GqkhKSgrmzZunfm1ubo6ysjIR0XQSC/kn4+LiguzsbNjb26Nbt27YuHEj7O3tsWHDBrRp00Z0vEbv9wU6i/VnY8mSJdi0aRO2bNkCR0dHAMDly5cRFhaGSZMm4dVXX8Xbb7+NiIgI7Ny5U3Daxi08PBybNm3SOMbl4+MDAwMDTJo0CefPn8eaNWsQGhoqMKW0uLi4YPny5fj888+xb98+REdHi44kOe+99x4SExMxduxYtGnThr8lSSiuzJPOs7a2xrJlyxASEiI6iiR5eXlh9OjRmD59Os6fP48uXbrg8uXL6nOKiYmJGD9+PPLz88UGpSbl8uXLcHJywrfffouamhqEhIQgLS0NQ4YMwY0bN9CiRQt89dVXCAoKEh1VMvLy8lBbW1unoWVOTg6aN28Oe3t7McEkxtHREbt27arT+CotLQ2jRo1Cbm4ujh8/jlGjRuHatWtiQkrECy+8gFOnTqFz584a42fPnkWvXr1QXV2NgoICdOzYkbtwqMGYm5tj//79ePXVV0VHIQIv5iWdp6enx39wn8LMmTMxe/Zs+Pj4wMfHB8OGDdNoOHTgwAH19keihuLs7AxbW1scPHgQKpUK+fn56N69O/Lz83Hq1Cn88ssvLOSfUEhICI4fP15n/OTJk3wY+gSuXbum7nD9e7W1tSguLgYA2NjY4Pbt2w0dTXJ69OiBmTNnorS0VD1WWlqKjz76CJ6engAePGxq166dqIjUBFlYWMDS0lJ0DCIALOapCYiIiMC6detEx5CsUaNG4cCBA+jSpQsiIiKwfft2jXlDQ0P87W9/E5SOmqrExESEhYXh6tWr+OCDD+Do6Ij27dtj6tSpuHDhAu7duyc6ouSkpaXV++DTy8tLfc0S/Tlvb2+EhYUhLS1NPZaWloYpU6Zg0KBBAB6sLLML+5+LiopCXl4e2rVrBycnJ3To0AHt2rVDfn4+tmzZAuBBR/HfH/0iet4+/fRTzJ8/n7tBqFHgNnvSeUqlEsOHD8elS5fg5uaG5s2ba8yzQzM1tE8++QQTJkyAnZ2d6Cg6oaamBidOnEBCQgISEhKQkpKCe/fuwcnJCdnZ2aLjSYaZmRkSEhLQvXt3jfEzZ85g4MCBXEnWUnFxMcaOHYvDhw+rv29qa2vh4+ODr7/+GtbW1jhy5Ahqamrg5+cnOG3jp1KpcPDgQVy6dAkqlQqurq4YPHgw9PS4HkVidO/eHVeuXIFKpYK9vX2d35VyuVxQMmqKWMyTzvv73/+OqKgoeHt712mAB7DpEzW8Hj16ICMjAwMGDMDEiRMxcuRIGBgYiI4ledXV1UhKSsLBgwexefNmVFZW8pq/J/Daa6/B0NAQ33//vfraNIVCgaCgINy5cwc//fST4ITScvHiRY0C1MXFRXQkSbt79y5atmzJZmMk3MKFCx87v2DBggZKQsRinpoAExMT/PDDDxg+fLjoKERqmZmZiImJwXfffYf79+/j7bffRmhoqPocKP25u3fv4vjx4zhy5AgSEhJw6tQptG/fHgMGDED//v0xYMAAtG3bVnRMybhw4QL69+8Pc3Nz9OvXDwBw7NgxVFRUID4+vk4TMnq8+/fvIy8vD46OjmjWjJcH/RVKpRKLFy/Ghg0bcP36dVy6dAkODg6YN28e7O3tMXHiRNERiYiE4h4l0nmWlpbq64GIGosuXbpg9erVKCoqQnR0NIqKivDqq6/C3d0da9euxa1bt0RHbNQGDBgAS0tLhIeH4+bNm5g6dSoKCgqQlZWFDRs2IDg4mIX8E3Jzc0NmZiZGjx6NkpIS3L59G+PGjcPFixdZyD+BqqoqTJw4EYaGhujUqRMKCwsBANOmTcPSpUsFp5OWzz77DF999RWWL1+OFi1aqMfd3d3VZ+aJRCgvL8eWLVswZ84c3Lx5E8CD7fVFRUWCk1FTw2KedN4nn3yCBQsWsFEJNUpKpRL379/HvXv3oFKpYGlpiS+//BK2trZ1mg3S/zt+/DhatWoFb29v+Pj4YNCgQbC2thYdS/JsbGywZMkS7N+/Hzt37sT8+fPZtfkJzZkzBxkZGUhISNA4PuPr68vP9BPatm0bNm3ahDFjxqiPfgAPHoZevHhRYDJqyjIzM+Hs7Ixly5ZhxYoVKC8vBwD8+OOPmDNnjthw1ORw3xfpvMjISFy5cgXW1tZsVPKUamtrkZCQgCtXriA4OBgmJia4evUqTE1NYWxsLDqepJw5cwYxMTH4/vvv0bJlS4wbNw7r1q2Dk5MTAGDlypWYNm0ar1d7hPLychw7dgwJCQlYtmwZ3nnnHTg7O2PAgAEYOHAgBgwYgNatW4uO2ehlZmaic+fO0NPTQ2Zm5mPf26VLlwZKJW179uzB9u3b4eXlpXG+283NDVeuXBGYTHqKiorU/yb+nlKpRE1NjYBERMD06dMREhKC5cuXw8TERD0+dOhQBAcHC0xGTRGLedJ5gYGBoiPohIKCAvj7+6OwsBD37t3D4MGDYWJiguXLl+Pu3bvYsGGD6IiS0aVLF2RlZcHPzw9RUVF4/fXXNVadAGDcuHGYOXOmoISNn5GREfz9/eHv7w8AuH37NpKSknDkyBEsX74cY8aMQYcOHXDu3DnBSRu3bt26obi4GFZWVujWrRtkMhnqa6Ujk8nYTFBLpaWlsLKyqjN+584dNm97Qp06dcKxY8fq3PyxY8eOOrcuEDWUU6dOYePGjXXG27Zti+LiYgGJqCljMU86j11Fn43w8HD07NkTGRkZePHFF9XjI0aMwHvvvScwmfS89dZbCA0NfeyZ7tatW0OpVDZgKmkzMjKCpaUlLC0tYWFhgWbNmiErK0t0rEYvLy9PvYMhLy9PcBrd4Onpif3792Pq1KkAoC7gN2/ejN69e4uMJjkLFizA2LFjUVRUBKVSid27dyM7Oxvbtm3Df//7X9HxqIkyMDBARUVFnfHs7GzuCKMGx2KemoTy8nLs3LkTV65cwcyZM2FpaQm5XA5ra2s2ydJSUlISkpOTNZoQAYCdnR0bvjyhefPmiY4geUqlEqdPn0ZCQgKOHDmC5ORk3LlzB23btoW3tzfWrVsHb29v0TEbvd+veBYUFKBPnz51Oq/X1tbi+PHjdVZHqX6ff/45/P39ceHCBdTW1mLt2rU4f/48Tpw4gcTERNHxJOX111/H9u3bsWTJEshkMsyfPx8eHh7Yt28fBg8eLDoeNVEBAQFYtGgRYmNjATx4YFdYWIjZs2dj1KhRgtNRU8Or6UjnZWZmwtfXF2ZmZsjPz0d2drb6apuCggJs27ZNdERJsLS0RFJSEtzc3GBiYoKMjAw4ODggKSkJo0aNwvXr10VHbNSmT5+u9XtXrVr1HJPoBlNTU9y5cwdt2rTBwIEDMXDgQHh7e/Pmiqegr6+Pa9eu1dkifuPGDVhZWXGb/RM4d+4c/vWvf+HMmTNQKpXw8PDArFmz4O7uLjqaZNTW1mLx4sUIDQ2Fra2t6DhEahUVFRg2bBjOnz+P27dvw8bGBsXFxejduzcOHDgAIyMj0RGpCWExTzrP19cXHh4e6kYlD4vQ48ePIzg4GPn5+aIjSkJQUBDMzMywadMmmJiYIDMzE61bt0ZAQABefvllxMTEiI7YqGm7SiyTyRAfH/+c00jfxo0b4e3tDWdnZ9FRdIaenh6uX79eZ5vopUuX0LNnz3q3lZKmmpoaTJo0CfPmzYODg4PoOJJnbGyMc+fOwd7eXnQUojri4+Mhl8vVD+x8fX1FR6ImiMU86TwzMzPI5XI4OjpqFPMFBQVwcXHB3bt3RUeUhKtXr8Lb2xv6+vrIyclBz549kZOTg1atWuHo0aP1NnwiosZv5MiRAID//Oc/8Pf3R8uWLdVzCoUCmZmZcHFxwc8//ywqoqSYm5tDLpezmH8GAgMDERgYiJCQENFRiAA82DFiYGCA9PR0dO7cWXQcIp6ZJ93HRiXPho2NDdLT0/HDDz+ot45OnDgRY8aMwQsvvCA6niTk5uaiffv27GhNjYqZmRkAQKVSwcTEROPz3KJFC3h5eeH9998XFU9yRowYgT179jzR0Rqq39ChQzFnzhycO3cOPXr0qLN9+Y033hCUjJqqZs2awc7OjseOqNHgyjzpvEmTJqG0tBSxsbGwtLREZmYm9PX1ERgYiP79+2PNmjWiI1IT8cczyUFBQYiMjIS1tbXgZETAwoULMWPGDJ73fEqLFy/GihUr4OPjU28BOm3aNEHJpEdPT++Rc7wukUSJiYnBjh078M0338DS0lJ0HGriWMyTzntUoxIvLy/89NNP/OGqpc8//xzW1tYIDQ3VGI+OjkZpaSlmzZolKJl06Onpqe/0BqBx7INItOrqaqhUKhgaGgJ40N3+xx9/hJubG/z8/ASnk4727ds/ck4mkyE3N7cB0xDRs9a9e3dcvnwZNTU1sLOzq/M7Ui6XC0pGTRG32ZPOMzU1RVJSEhuVPKWNGzfiu+++qzPeqVMnvP322yzmiSQuICAAI0eOxOTJk1FeXo5evXqhRYsW+O2337Bq1SpMmTJFdERJyMvLEx2BiJ6jgIAAHpejRoMr86Sz4uPj8cEHHyAlJQWmpqYac7du3UKfPn2wYcMG9OvXT1BCaTEwMEBWVladVafc3Fy4ubmxkaAW9PX1UVxcrO7V8PBWgMet5BE1lFatWiExMRGdOnXCli1b8O9//xtpaWnYtWsX5s+fj6ysLNERqYmJjIysd1wmk8HAwABOTk7o378/9PX1GzgZEVHjwJV50llr1qzB+++/X6eQBx40fAoLC8OqVatYzGvJ1tYWycnJdQrP5ORk2NjYCEolLSqVCiEhIepu4Xfv3sXkyZPrbNHbvXu3iHjUxFVVVcHExAQAcOjQIYwcORJ6enrw8vJCQUGB4HTS8ajGd78vQAMCAnjWVgurV69GaWkpqqqqYGFhAZVKhfLychgaGsLY2BglJSVwcHDAkSNHeBc9NRgHBwecOnUKL774osZ4eXk5PDw8eJSGGtSjO4sQSVxGRgb8/f0fOe/n54czZ840YCJpe++99/CPf/wDMTExKCgoQEFBAaKjoxEREcFO11oaP348rKysYGZmBjMzM7z77ruwsbFRv374PyIRnJycsGfPHvzyyy84ePCg+px8SUlJvQ9FqX5paWmIiorCpk2bkJiYiISEBGzevBlRUVE4fPgwpk+fDicnJ1y4cEF01EZvyZIl8PT0RE5ODm7cuIGbN2/i0qVLeOWVV7B27VoUFhbipZdeQkREhOio1ITk5+fX23zx3r17+PXXXwUkoqaM2+xJZxkYGODcuXNwcnKqd/7y5ctwd3dHdXV1AyeTJpVKhdmzZyMyMhL3798H8OBvPGvWLMyfP19wOiJ6Wjt37kRwcDAUCgV8fHxw6NAhAA+aXx49ehQ//fST4ITSsGbNGhw7dgwxMTHqhyAVFRWYOHEi+vbti/fffx/BwcGorq7GwYMHBadt3BwdHbFr1y5069ZNYzwtLQ2jRo1Cbm4ujh8/jlGjRuHatWtiQlKTsXfvXgBAYGAgtm7dqvHwXaFQ4PDhw4iLi0N2draoiNQEsZgnneXo6IgVK1ZgxIgR9c7v3r0bM2bM4HaoJ1RZWYmsrCy88MIL6NChg3rLOBFJX3FxMa5du4auXbuqrwVLTU2FqakpXF1dBaeThrZt2yIuLg5ubm4a4+fPn4efnx+Kioogl8vh5+eH3377TVBKaTA0NMTRo0fRs2dPjfFTp05hwIABqKqqQn5+Pjp37ozKykpBKampePhvokwmwx/Lp+bNm8Pe3h4rV67Ea6+9JiIeNVHcZk86a9iwYZg/f369jdmqq6uxYMEC/oP7FxgbG8PT0xOdO3dmIU+kY1566SV0795d437vXr16sZB/Ardu3UJJSUmd8dLSUlRUVAAAzM3N1Tuc6NG8vb0RFhaGtLQ09VhaWhqmTJmCQYMGAQDOnj3LJqLUIJRKJZRKJV5++WWUlJSoXyuVSty7dw/Z2dn8XUkNjg3wSGd9/PHH2L17N5ydnfHBBx/AxcUFMpkMWVlZWLduHRQKBebOnSs6pqScOnUKO3bsQGFhYZ0fomzaRiR9/Iw/vYCAAISGhmLlypXw9PSETCZDamoqZsyYgcDAQAAPdjs4OzuLDSoBUVFRGDt2LHr06IHmzZsDAGpra+Hj44OoqCgADx4wr1y5UmRMaiJOnjyJmzdvalw/uW3bNixYsAB37txBYGAg/v3vf3OhgxoUt9mTTisoKMCUKVNw8OBB9ZYomUyGIUOGYP369bC3txcbUEJ++OEHjBs3Dn5+foiLi4Ofnx9ycnJQXFyMESNGICYmRnREInoK/Iw/G5WVlYiIiMC2bdtQW1sLAGjWrBnGjx+P1atXw8jICOnp6QBQ5yw41e/ixYu4dOkSVCoVXF1d4eLiIjoSNUH+/v7w9vbGrFmzADzYFeLh4YGQkBB07NgR//rXvxAWFoZPPvlEbFBqUljMU5NQVlaGy5cvQ6VSoUOHDrCwsBAdSXK6dOmCsLAw/P3vf4eJiQkyMjLQvn17hIWFoU2bNli4cKHoiET0FPgZf7YqKyuRm5sLlUoFR0dHGBsbi45ERE+hTZs22Ldvn7qHw9y5c5GYmIikpCQAwI4dO7BgwQLeVEENisU8EWnFyMgI58+fh729PVq1aoUjR47A3d0dWVlZGDRoEDsJE0kcP+PU2EyfPr3ecZlMBgMDAzg5OSEgIACWlpYNnIyaIgMDA+Tk5MDW1hYA0LdvX/j7++Pjjz8G8ODKOnd3d9y+fVtkTGpieGaeiLRiaWmp/oJq27Ytzp07B3d3d5SXl6OqqkpwOiJ6WvyMPxsjRoyATCarM/77AjQ4OJhbxbWQlpYGuVwOhUIBFxcXqFQq5OTkQF9fH66urli/fj0+/PBDJCUl1bk9gOhZs7a2Rl5eHmxtbXH//n3I5XKNHUu3b99W93YgaijsZk9EWunXrx/i4uIAAKNHj0Z4eDjef/99vPPOO/Dx8RGcjoieFj/jz4aZmRni4+Mhl8vVRX1aWhri4+NRW1uL7du3o2vXrkhOThactPELCAiAr68vrl69ijNnzkAul6OoqAiDBw/GO++8g6KiIvTv3x8RERGio1IT4O/vj9mzZ+PYsWOYM2cODA0N0a9fP/V8ZmYmHB0dBSakpojb7IlIKzdv3sTdu3dhY2MDpVKJFStWICkpCU5OTpg3bx77EBBJHD/jz8bs2bNRUVGBL774Qn3Fn1KpRHh4OExMTLB48WJMnjwZ58+fV5+1pfq1bdsWcXFxdVbdz58/Dz8/PxQVFUEul8PPzw+//faboJTUVJSWlmLkyJFITk6GsbExtm7dihEjRqjnfXx84OXlhcWLFwtMSU0Ni3kiIiKiZ6R169ZITk6uc/XcpUuX0KdPH/z22284e/Ys+vXrh/LycjEhJcLY2Bj//e9/MXDgQI3xhIQEvP7667h9+zZyc3PRrVs3VFRUiAlJTc6tW7dgbGwMfX19jfGbN2/C2NgYLVq0EJSMmiKemScirSmVSly+fBklJSVQKpUac/379xeUioj+qicpgExNTZ9jEt1RW1uLixcv1inmL168CIVCAeBBI636ztWTpoCAAISGhmLlypXw9PSETCZDamoqZsyYgcDAQABAampqnb810fNkZmZW7zgbMZIILOaJSCspKSkIDg5GQUEB/rihRyaTqX+kEpF0mJub/2lRqVKp+Bl/AmPHjsXEiRPxz3/+U6MAXbJkCcaNGwcASExMRKdOnQQnbfw2btyIiIgIvP3226itrQUANGvWDOPHj8eqVasAAK6urtiyZYvImEREwnCbPRFppVu3bnB2dsbChQvRpk2bOgXAo55UE1HjlZiYqPV7BwwY8ByT6A6FQoGlS5fiiy++wPXr1wE86II9depUzJo1C/r6+igsLISenh7atWsnOK00VFZWIjc3FyqVCo6OjjA2NhYdiYioUWAxT0RaMTIyQkZGBpycnERHISKShIfHGHhE4dlRKpXYv38/oqKisGfPHtFxiIiE4jZ7ItLKK6+8gsuXL7OYJ9JhZWVliIqKQlZWFmQyGTp27IgJEybwLOhf9LCILysrwzfffIOoqCikp6eLDSVROTk5iI6OxtatW1FWVoYhQ4aIjkREJByLeSLSytSpU/Hhhx+iuLgY7u7uaN68ucZ8ly5dBCUjomchMTERb7zxBszMzNCzZ08AQGRkJBYtWoS9e/dym/1f8L///U+9gtyqVSuMHDlSdCRJqa6uRmxsLKKiopCSkgKFQoHVq1cjNDSUW+2JiMBt9kSkpYf3Jf+eTCZjcywiHdG5c2f06dMHX375pfrKJYVCgb/97W9ITk7GuXPnBCeUhsLCQsTExCAmJgaVlZUoKytDbGwsRo0aJTqaZKSmpmLLli3Yvn07nJ2d8e677+Ltt99Gu3btkJGRUefeeSKipoor80Sklby8PNERiOg5unLlCnbt2qVxd7K+vj6mT5+Obdu2CUwmDbGxsdiyZQuSk5MxbNgwrF27FkOHDoWRkRE6duwoOp6k9OnTB1OnTkVqaipcXFxExyEiarRYzBPRn6qpqYG3tzf++9//ckWESEd5eHggKyurTvGUlZWFbt26iQklIcHBwfjoo4+wa9cumJiYiI4jaYMGDUJUVBRKSkowduxYDBky5E+vUCQiaopYzBPRn2revDnu3bvHH1NEOmzatGkIDw/H5cuX4eXlBQBISUnBunXrsHTpUmRmZqrfyx4ZdYWGhmL9+vVITEzE2LFjERQUBAsLC9GxJOnQoUP45ZdfEBMTgylTpqC6uhpBQUEAwO8hIqLf4Zl5ItLK0qVLcfHiRWzZsgXNmvE5IJGuqa8vxu+xR8afe9iwLTo6GidPnsSQIUOwf/9+pKeno3PnzqLjSVZcXByio6OxZ88e2Nra4s0338Sbb74JDw8P0dGIiIRiMU9EWhkxYgQOHz4MY2NjuLu7w8jISGN+9+7dgpIR0bNQUFCg9Xvt7OyeYxLd8PAqtW3btqGyshLDhw/Hm2++yY72T+HhFX/R0dHIzMzkQyUiavJYzBORViZMmPDY+ZiYmAZKQkTPWk1NDSZNmoR58+bBwcFBdBydolQqsX//fkRFReGnn37CvXv3REfSCXK5nCvzRNTksZgnIiIimJubQy6Xs5h/jkpKSmBlZSU6BhER6YjHH5AjIiKiJmHEiBHYs2eP6Bg6jYU8ERE9S+xiRURaad++/WO7COfm5jZgGiJ61pycnPDpp5/i+PHj6NGjR52+GNOmTROUjIiIiOrDbfZEpJW1a9dqvK6pqUFaWhp+/vlnzJw5E7NnzxaUjIiehfbt2z9yTiaT8YEdERFRI8Ninoieyrp163D69Gk2wCMiomeutrYWCQkJuHLlCoKDg2FiYoKrV6/C1NQUxsbGouMREQnFYp6Inkpubi66deuGiooK0VGI6Bm4f/8+8vLy4OjoiGbNeBrvrygvL8fOnTtx5coVzJw5E5aWlpDL5bC2tkbbtm1Fx5OMgoIC+Pv7o7CwEPfu3cOlS5fg4OCAf/zjH7h79y42bNggOiIRkVBsgEdET2Xnzp2wtLQUHYOInlJVVRUmTpwIQ0NDdOrUCYWFhQAenJVfunSp4HTSkZmZCWdnZyxbtgwrVqxAeXk5AODHH3/EnDlzxIaTmPDwcPTs2RNlZWV44YUX1OMjRozA4cOHBSYjImoc+MidiLTSvXt3jQZ4KpUKxcXFKC0txfr16wUmI6JnYc6cOcjIyEBCQgL8/f3V476+vliwYAH7Ymhp+vTpCAkJwfLly2FiYqIeHzp0KIKDgwUmk56kpCQkJyejRYsWGuN2dnYoKioSlIqIqPFgMU9EWgkMDNR4raenh9atW2PgwIFwdXUVE4qInpk9e/Zg+/bt8PLy0nhw5+bmhitXrghMJi2nTp3Cxo0b64y3bdsWxcXFAhJJl1KphEKhqDP+66+/ajwoISJqqljME9FjxcfHo3///liwYIHoKET0HJWWltZ7D/qdO3ceey0laTIwMKi3h0h2djZat24tIJF0DR48GGvWrMGmTZsAPLhVobKyEgsWLMCwYcMEpyMiEo9n5onosQYPHoybN2+qX3t5eXF7I5EO8vT0xP79+9WvHxbwmzdvRu/evUXFkpyAgAAsWrQINTU1AB78HQsLCzF79myMGjVKcDppWb16NRITE+Hm5oa7d+8iODgY9vb2KCoqwrJly0THIyISjt3sieix9PT0UFxcrF6xMzExQUZGBhwcHAQnI6Jn6fjx4/D398eYMWPw1VdfISwsDOfPn8eJEyeQmJiIHj16iI4oCRUVFRg2bBjOnz+P27dvw8bGBsXFxejduzcOHDgAIyMj0RElpbq6Gt9//z3kcjmUSiU8PDwwZswYjYZ4RERNFYt5InosFvNETcfZs2exYsUKnDlzRl04zZo1C+7u7qKjSU58fLxGAerr6ys6EhER6RgW80T0WPr6+iguLlaf9TQ1NUVGRgbat28vOBkRkTSUl5fD3NxcdAxJunTpEhISElBSUgKlUqkxN3/+fEGpiIgaBxbzRPRYenp66Ny5M5o1e9AvMzMzE66urnWuCpLL5SLiEdEzpFAo8OOPPyIrKwsymQwdO3ZEQECA+vNPf27ZsmWwt7dHUFAQAGD06NHYtWsXXnrpJRw4cABdu3YVnFA6Nm/ejClTpqBVq1Z46aWXNBoxymQyfu8QUZPHYp6IHmvhwoVavY/d7omk7dy5cwgICEBxcTFcXFwAPFgVbd26Nfbu3cut9lpycHDAN998gz59+iAuLg6jR4/G9u3bERsbi8LCQhw6dEh0RMmws7PD3/72N8yaNUt0FCKiRonFPBEREcHLywtWVlbYunUrLCwsAABlZWUICQlBSUkJTpw4ITihNLzwwgu4dOkSbG1tER4ejrt372Ljxo24dOkSXnnlFZSVlYmOKBmmpqZIT09njxYiokfg1XRERESEjIwMfP755+pCHgAsLCywePFipKeniwsmMRYWFvjll18AAD///LO68Z1KpYJCoRAZTXLeeust7mQgInoMHoIjIiIiuLi44Pr16+jUqZPGeElJCZycnASlkp6RI0ciODgYHTp0wI0bNzB06FAAQHp6Ov+OT8jJyQnz5s1DSkoK3N3d0bx5c435adOmCUpGRNQ4cJs9ERER4cCBA/joo4/wySefwMvLCwCQkpKCRYsWYenSpejbt6/6vaampqJiNno1NTWIjIxEYWEhQkJC0L17dwDAmjVrYGxsjPfee09wQul43K0pMpkMubm5DZiGiKjxYTFPRERE0NP7/5N3D7uGP/yJ8PvXMpmM28UfoaamBpMmTcK8efN4zpuIiJ47FvNEpJVt27YhKCgILVu21Bi/f/8+fvjhB4wbN05QMiJ6FhITE7V+74ABA55jEmkzNzeHXC5nMU9ERM8di3ki0oq+vj6uXbsGKysrjfEbN27AysqKK3VERAAmTJgAd3d3TJ8+XXQUSZo+fTo+/fRTGBkZ/enfcNWqVQ2UioiocWIDPCLSysPttX/066+/wszMTEAiInqWjh49+tj5/v37N1ASaXNycsKnn36K48ePo0ePHjAyMtKYZ9O2x0tLS0NNTY36/z9Kfd9HRERNDVfmieixunfvDplMhoyMDHTq1AnNmv3/M0CFQoG8vDz4+/sjNjZWYEoielq/PzP/0O8LJu6+0Q6btj293NxctG/fngU7EdGf4Mo8ET1WYGAggAfXKg0ZMgTGxsbquRYtWsDe3h6jRo0SlI6InpWysjKN1zU1NUhLS8O8efOwePFiQamkJy8vT3QEyevQoYPGsa6goCBERkbC2tpacDIiosaFK/NEpJWtW7fi7bffrtMAj4h029GjRxEREYEzZ86IjkJNhJ6eHoqLi9XFvImJCTIyMthUkIjoD7gyT0RaGTRoEEpLS9GuXTsAQGpqKr777ju4ublh0qRJgtMR0fPSunVrZGdni44hKb/++iv27t2LwsJC3L9/X2OOTduIiOhZYTFPRFoJDg7GpEmTMHbsWBQXF8PX1xedO3fGN998g+LiYsyfP190RCJ6CpmZmRqvVSoVrl27hqVLl6Jr166CUknP4cOH8cYbb6B9+/bIzs5G586dkZ+fD5VKBQ8PD9HxJEEmk9U5L8/z80REdXGbPRFpxcLCAikpKXBxcUFkZCS2b9+O5ORkHDp0CJMnT2ZTJyKJ09PTg0wmwx9/Fnh5eSE6Ohqurq6CkklLr1694O/vj0WLFqm3h1tZWWHMmDHw9/fHlClTREds9PT09DB06FD1sa59+/Zh0KBBdW4G2L17t4h4RESNBlfmiUgrNTU16h9W//vf//DGG28AAFxdXXHt2jWR0YjoGfhj4zY9PT20bt0aBgYGghJJU1ZWFr7//nsAQLNmzVBdXQ1jY2MsWrQIAQEBLOa1MH78eI3X7777rqAkRESNG4t5ItJKp06dsGHDBgwfPhxxcXH49NNPAQBXr17Fiy++KDgdEf1VJ0+exM2bNzF06FD12LZt27BgwQLcuXMHgYGB+Pe//83ml1oyMjLCvXv3AAA2Nja4cuUKOnXqBAD47bffREaTjJiYGNERiIgkoe6lskRE9Vi2bBk2btyIgQMH4p133lGfod27dy969eolOB0R/VWffPKJxnn5s2fPYuLEifD19cXs2bOxb98+fP755wITSouXlxeSk5MBAMOHD8eHH36IxYsXIzQ0FF5eXoLTERGRLuGZeSLSmkKhQEVFBSwsLNRj+fn5MDQ0VF8hRETS0qZNG+zbtw89e/YEAMydOxeJiYlISkoCAOzYsQMLFizAhQsXRMaUjNzcXFRWVqJLly6oqqrCjBkzkJSUBCcnJ6xevRp2dnaiIxIRkY5gMU9ERNSEGRgYICcnB7a2tgCAvn37wt/fHx9//DGABw/s3N3dcfv2bZExiYiI6A94Zp6ItLZz507ExsbWe3eyXC4XlIqInoa1tTXy8vJga2uL+/fvQy6XY+HCher527dvo3nz5gITStOZM2eQlZUFmUwGNzc3dO/eXXQkIiLSMTwzT0RaiYyMxIQJE2BlZYW0tDT06tULL774InJzczUaZxGRtPj7+2P27Nk4duwY5syZA0NDQ/Tr1089n5mZCUdHR4EJpaWkpASDBg2Cp6cnpk2bhg8++AA9evSAj48PSktLRccjIiIdwmKeiLSyfv16bNq0CV988QVatGiBjz76CHFxcZg2bRpu3bolOh4R/UWfffYZ9PX1MWDAAGzevBmbN29GixYt1PPR0dHw8/MTmFBapk6dioqKCpw/fx43b95EWVkZzp07h4qKCkybNk10PCIi0iE8M09EWjE0NERWVhbs7OxgZWWFuLg4dO3aFTk5OfDy8sKNGzdERySip3Dr1i0YGxtDX19fY/zmzZswNjbWKPDp0czMzPC///0Pnp6eGuOpqanw8/NDeXm5mGBERKRzuDJPRFp56aWX1AW7nZ0dUlJSAAB5eXngM0Ei6TMzM6tTyAOApaUlC/knoFQq6+0x0Lx5cyiVSgGJiIhIV7GYJyKtDBo0CPv27QMATJw4ERERERg8eDCCgoIwYsQIwemIiBqHQYMGITw8HFevXlWPFRUVISIiAj4+PgKTERGRruE2eyLSilKphFKpRLNmDy7BiI2NVd+dPHnyZK7cEREB+OWXXxAQEIBz587B1tYWMpkMhYWFcHd3x3/+8x+0a9dOdEQiItIRLOaJiIiInrG4uDhcvHgRKpUKbm5u8PX1FR2JiIh0DIt5InqkzMxMrd/bpUuX55iEiIiIiIh+j8U8ET2Snp4eZDLZnza4k8lkUCgUDZSKiKjxiY+PxwcffICUlBSYmppqzN26dQt9+vTBhg0b0K9fP0EJiYhI1zQTHYCIGq+8vDzREYiIJGHNmjV4//336xTywIObAsLCwrBq1SoW80RE9MxwZZ6IiIjoKdnZ2eHnn39Gx44d652/ePEi/Pz8UFhY2MDJiIhIV3Flnoi0cuPGDbz44osAHnRr3rx5M6qrq/HGG29wpYmImrzr16/Xe7/8Q82aNUNpaWkDJiIiIl3He+aJ6LHOnj0Le3t7WFlZwdXVFenp6fD09MTq1auxadMmeHt7Y8+ePaJjEhEJ1bZtW5w9e/aR85mZmWjTpk0DJiIiIl3HYp6IHuujjz6Cu7s7EhMTMXDgQLz22msYNmwYbt26hbKyMoSFhWHp0qWiYxIRCTVs2DDMnz8fd+/erTNXXV2NBQsW4LXXXhOQjIiIdBXPzBPRY7Vq1Qrx8fHo0qULKisrYWpqitTUVPTs2RPAg3OgXl5eKC8vFxuUiEig69evw8PDA/r6+vjggw/g4uICmUyGrKwsrFu3DgqFAnK5HNbW1qKjEhGRjmAxT0SPpaenh+LiYlhZWQEATExMkJGRAQcHBwAPfsDa2NjwajoiavIKCgowZcoUHDx4UH2lp0wmw5AhQ7B+/XrY29uLDUhERDqFDfCI6E/JZLLHviYiogcd7Q8cOICysjJcvnwZKpUKHTp0gIWFhehoRESkg1jME9GfCgkJQcuWLQEAd+/exeTJk2FkZAQAuHfvnshoRESNjoWFBTw9PUXHICIiHcdt9kT0WBMmTNDqfTExMc85CRERERERPcRinoiIiIiIiEhieDUdERERERERkcSwmCciIiIiIiKSGBbzRERERERERBLDYp6IiIiIiIhIYljMExEREREREUkMi3kiIiIiIiIiiWExT0RERERERCQxLOaJiIiIiIiIJOb/APtmFkHX1MFoAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our objective is mainly to build the model, we will just touch a few in this EDA (exploratory data analysis) section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. MODEL - Construct Model to Predict and Forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The part where the magic happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data to Predictors and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  \n",
       "3             932.0           594.0  365  \n",
       "4             978.4           825.5  360  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.99\n",
       "1    61.89\n",
       "2    40.27\n",
       "3    41.05\n",
       "4    44.30\n",
       "Name: Strength, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:,-1]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save number of feature columns, <strong><i>n_cols</i></strong> to use later in model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = X.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing SKLEARN and KERAS Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><font color=\"red\">A. BASELINE MODEL</font></strong>\n",
    "\n",
    "<strong>Network Properties:</strong>\n",
    "<ul>\n",
    "  <li>Hidden Layer: 1</li>\n",
    "  <li>Nodes: 10</li>\n",
    "  <li>Activation Function: ReLU</li>\n",
    "  <li>Optimizer: Adam</li>\n",
    "  <li>Loss Function: Mean Squared Error</li>\n",
    "  <li>Epochs: 50</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 7252.3252\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4898.9438\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3674.4858\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2543.8376\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1843.2791\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1350.4230\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 953.3451 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 801.6514 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 637.6248 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 577.5709\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 436.3085\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 446.5672 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 397.9169 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 352.7913 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 329.1432\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 285.6126\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 257.8083\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 254.7867\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 210.1497\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 198.4364\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 185.9499\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 178.2808 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162.5417\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156.9098 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153.5045 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145.5345 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 135.2850\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 135.4518\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 118.3545\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 120.4930 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 128.4676\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.7156\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111.6537\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109.4660\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 103.0095\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.5520 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114.2171 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 113.0467 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 117.8872 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 105.8744\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 111.2969\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 104.2807\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 104.2722\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 105.2422\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 97.7210\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 108.5898 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 103.1947\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 98.0253 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 98.8221\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 95.0438 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 673603.5625\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 381339.9375\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 194225.9219\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 88306.7031  \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39670.8633 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25970.5664 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22530.2090 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20612.5879 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20015.1680 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19534.8633 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16163.0605\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15434.0234\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15749.2803 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15604.5293 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13573.8740\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14026.2266 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12322.1816 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11362.1094\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10295.6309\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10370.1436\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10624.8555\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8254.4375\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7696.0171\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8204.6416\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7147.6089\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7476.3398\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7033.0400\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5783.1392\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5487.0190\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5816.6157\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5086.8726\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4968.5342\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4627.2153\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3794.6628\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3855.3076\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3389.7119\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3327.7292\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3014.3972\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3197.3052\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2965.0144\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2404.4136\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2438.5989\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2256.0247\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2219.1516\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1973.6428\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2081.4131\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1930.0769\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1684.3154\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1682.0378\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1637.2506\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2803.2104\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1942.0569\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1247.8015\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1060.7778\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 776.0693 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 688.8000 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 615.0596 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 560.8455 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 471.7939 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 433.2972 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 389.2648 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 348.7780 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 282.9059 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 290.2779 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 269.4634 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 248.1380 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 195.6232 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 186.6611 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 198.1938 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163.5592 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 157.2751 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135.5667 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141.1360 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134.6684 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 133.6144\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 123.2558\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 128.1111\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 117.8740\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 112.5785\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 116.6907\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.5749 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125.2604 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 103.1871\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118.2004 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 111.1576\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 103.7694 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 112.4957 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 103.9146\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 102.5767\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 102.3799\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 106.7103\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 104.4490\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 103.6561 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 103.0126 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 98.9361\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 110.8096 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 107.2397\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 114.2925\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 105.6425 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.3499 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 29847.0312\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4937.4131\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2526.1707\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2348.5625\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1702.2133\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1587.7540\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1349.1287\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1082.4027\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 950.2645  \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 835.2515 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 740.5342 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 602.1344 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 539.3079 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 459.6980 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 416.0292 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 361.4407 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 309.5353 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 300.4517\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 258.8468 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 242.3554 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 229.0204 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 211.6826 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 186.4677 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 183.3270\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 190.2031 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173.4476 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 180.3757 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 172.5390 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164.5523 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 156.1796\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 158.1989\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 144.0495\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 165.2750 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 150.3997\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161.2474 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135.6853\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140.6435 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152.3241 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144.0336 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131.3082\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141.4083 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130.3294 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 138.4442 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140.7108 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140.1740\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142.6080 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127.0604 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 132.2737 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 125.4584\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 129.7367\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 2635.2310\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1296.4167\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 776.3445 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561.9420 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 550.8473 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 367.9787 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 320.1259 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 281.0759 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 252.0731 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 204.1148 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 187.5028 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 183.3664 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161.5576 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134.2644\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131.9936\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119.4153 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.1038 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 105.0154\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109.5509 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110.4494 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 99.4237 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.0413 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 101.5789\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 104.1037\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 105.1847 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 99.4579  \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 100.8155\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 94.7249\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 102.2262\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 94.9000\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 96.1315\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 95.6551\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 94.7966 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 102.0425\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 87.5929\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 91.3194 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 89.7883\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 90.4643\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 93.6582\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 91.7641\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 93.1400 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 93.7326\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 97.2807\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 103.4875\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 100.3455\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 90.4231 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 95.1065\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 92.6735 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 80.7483\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 89.5799\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 469757.5625\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 233440.8594\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 109714.1094\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45419.1055\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18220.2871 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6483.1641\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3114.7949\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1876.3473\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1821.6213\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1503.5640\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1408.9199\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1332.1382\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1298.2994\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1257.4038\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1121.5221\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1241.9016\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1159.4142\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1000.6350\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 957.6130 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 905.3760  \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 825.0331 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 865.3580 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 808.1506 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 779.6901 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 778.7153 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 693.9855 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 657.4144 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 637.6157 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 642.9238 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 644.1588 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 590.2267 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 593.7385 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 530.6351 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 568.0063 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 537.7061 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 511.7386 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 493.6188 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 498.0559 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 466.3183\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 423.0628 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 455.5867 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 465.8722 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 391.2457 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 424.7342 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 376.0503 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 388.6330 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 372.0264 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 411.6948 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 354.9880 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 353.1016 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 2894.6213\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 663.8934\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 605.1644\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 606.1995\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 540.4904\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 554.5833\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 484.7273\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463.0049 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 417.6016\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 447.9711 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 393.9366 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 400.4181\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 359.7168 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 332.8792\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 325.6579\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 315.5220\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 298.1214\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 262.9765\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 276.0122 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 261.0287 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 261.5966 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 240.9441 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 221.4447 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 226.7372 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 209.4266\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 201.9273 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 189.5198 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 175.9935 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 180.4210 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 172.2104 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157.8241 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153.5356 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156.7548 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146.5667 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142.2503 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146.8094 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131.9603\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 133.8710 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130.1344 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119.4238 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121.3226 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130.7055 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.6537\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121.8292 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119.4108\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.3404\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111.2946 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111.2187\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 106.6528 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 108.1868 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 15997.0537\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11908.2334 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8921.2100\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7824.9731\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6069.1245\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5094.7627\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4589.3994\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3641.0762\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3125.8115\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2660.3293\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2330.1042\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2154.1965\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1956.5934\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1539.1045\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1500.3234\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1254.6670\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1172.0723\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1052.4812\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 934.9003  \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 855.6058 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 717.6123 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 746.9457 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 632.2281 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 579.1578 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 548.8579 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 504.4591 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 419.6292\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 408.2972 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 365.4818 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 323.7864 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 270.3508 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 276.1078 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 249.0757 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 236.4864 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 237.9262 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 200.7332 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 204.0078 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 192.7383 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 172.9546 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161.8134 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161.9624 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164.2671 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149.3421 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137.7480 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135.9806 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134.2639 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 132.0821 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134.7779 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129.5785 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127.2983\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 62944.3047\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11463.2285 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1409.6143\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1233.7334\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1180.9038\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1127.9006\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1144.7491\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1137.3792\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1061.8375\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1099.1581\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1021.6717\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 891.1891 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 924.6013 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 872.6425  \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1013.9564\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 825.0896 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 843.0721 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 802.0955 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 759.8327 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 782.3802 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 773.8187 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 795.4664 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 659.5204 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 716.7289 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 653.4315 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 660.7592 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 647.2029 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 628.2484 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 609.4028 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 608.2175 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 584.5629 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 595.7889 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 538.7774 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 579.7141 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 559.8948 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 489.2859 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 513.4575 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 496.6230 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 472.1077 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 479.6953 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 484.9492 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 424.5188 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 451.7228 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 404.7068 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 388.6471 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 404.4453 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 360.4858 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 400.8686 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 355.2003 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 317.8728 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 37670.6562\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4062.7239\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1736.5869\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1593.4974\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1390.5081\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1374.4802\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1219.9885\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1165.4547\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1010.9879\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 924.7261 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 859.0248 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 729.4250 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 688.2182 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 591.6025 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 539.3050 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 505.6079 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 423.4666 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 380.6516 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 404.7347 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 361.9938 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 344.9442 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 330.7482 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 309.8863 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 287.5480 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 297.1563 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 257.7069 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 247.9404 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 241.3939 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 229.2508 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 211.7296 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 221.8582 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 212.6878 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 216.1589 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 201.8999 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 184.0132 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 185.1531\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 190.9410 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 195.8389\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 171.5667 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173.2961 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163.2496 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169.8674 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 175.3626 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163.8962 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164.6797 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152.4891\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156.1832 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152.4262 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145.1053 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 147.6307 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 284589.0312\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154031.6094\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 74783.8906\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33632.6172 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13745.5801 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6180.3613\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3288.6824\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2668.7480\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2188.8103\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2104.6628\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2348.8560\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2075.7859\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2306.0420\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1815.9965\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2113.8750\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1774.9215\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1846.9946\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1760.2651\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1730.6305\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1770.4938\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1658.0115\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1544.1719\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1577.5278\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1516.4722\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1552.6512\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1473.3536\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1405.8524\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1296.3765\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1222.1089\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1252.8896\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1150.0491\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1086.0647\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1062.2976\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 985.0308  \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1009.3295\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 901.2229 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 932.9653  \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 779.7406 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 792.1906 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 827.7957  \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 691.1653 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 703.9256 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 640.4605 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 621.9499 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 673.4175 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 619.8403 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 576.7780 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 605.1620 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533.9112 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 539.9672 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 122196.2578\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55225.4492 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18226.8145 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4428.3076\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1165.3564\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 663.4056\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 637.8402 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 603.6391 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 590.7776\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 524.0332\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 536.4223 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 465.6838 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 452.3929\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 447.6812 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 433.8795\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 430.0527 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 425.9431\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 374.9247\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 344.6667 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 320.1472\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 299.7357\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 290.2457\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 297.1710\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 260.8964 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 265.8016\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 248.2194\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 237.6334 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 215.4133\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 222.5487 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 199.6442\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 193.9410\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 174.1734\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 190.9947 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 166.0338\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158.1443\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 171.6120\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164.6704\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146.5213 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142.5596 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150.6946 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154.8658 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154.7861 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141.8687 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126.3014 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129.5387 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126.3016\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140.1468 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126.8902\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130.4705 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119.4697 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2100.6812\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1563.1372\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1328.6224\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 992.9512 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 787.0096 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 646.9126 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 567.7576\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 595.7100 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 482.5788 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 456.7402\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 421.3042 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 420.1262 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 367.5217 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 390.8467\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 357.9734 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 317.9348\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 330.4460 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 319.7762\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 272.2630 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 286.4788 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 285.6333 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 253.4113 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 239.9016 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 255.0364 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 232.6734 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 254.8899 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 245.1679 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 218.9312 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 233.4890 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 215.7337 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 222.9411 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 226.0129 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 218.8974 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 215.3779 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 215.1247 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 198.6910 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 198.9656 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 215.2212 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 197.2700 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 184.0685\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 181.6159 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 173.9966 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 183.8558\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 184.3342 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 178.6667\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 171.2651 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 180.7309\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 176.6228 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 173.1059\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 179.2411 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 5491.1494\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 628.5147\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 615.7330 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 568.6359 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 510.8658\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 462.0450 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 411.5746\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 392.1838 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 387.9247 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 371.8889\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 344.6855 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 321.4513 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 273.7896 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 263.8847\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 252.2528 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 229.6182\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 199.3649\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 179.3469\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 195.5910 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 179.1485 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 174.7372 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161.4198 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157.4827 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 145.1553 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 143.1944\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142.6715 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141.7603 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140.8831 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 137.6413 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 134.4577\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 130.2174\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 131.7588\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 130.3352 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141.3093 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130.4126 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127.0243 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 127.4461 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 114.6661\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 125.2689\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 129.8146\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 121.4273\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 114.5279\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 127.4220\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134.2707 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131.4261 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118.6426 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126.5806\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 122.1908 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120.6575 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127.0339 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 662104.6875\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 376055.3750\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 189725.4062\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 98900.9219\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44545.1797 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25362.7656 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16757.1309 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12372.1123\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11491.9316 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10893.6309 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10975.0684 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10155.7422\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8887.0098\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8754.3594\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9566.6553\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8692.0127\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8500.7773\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7168.6416\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7143.0259\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6495.4321\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6385.6069\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5896.7769\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6043.1943\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5355.1343\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5222.2388\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4769.8193\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4862.9004\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4922.4224\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3915.7400\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3867.5647\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4329.5825\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3928.2053\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3650.7737\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3307.6606\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3274.9170\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2661.0386\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2771.3552\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2456.7390\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2442.4138\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2488.6094\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2130.1113\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2124.0122\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2204.1011\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1723.7933\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1790.3651\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1576.4554\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1649.1793\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1418.4464\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1535.9341\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1395.4701\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 177787.1719\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 50790.7109 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12427.5596 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6268.9854\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5900.2700\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5828.8530\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5399.2710\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4690.3999\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4849.7715\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4764.4219\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4185.3188\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3871.4841\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3724.0857\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3435.3713\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3398.1389\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3402.8740\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2954.4565\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2988.8352\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2765.5422\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2609.7778\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2502.9351\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2471.1758\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2328.7864\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2018.8590\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2180.6401\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1876.6339\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1850.0735\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1822.8712\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1702.7015\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1669.2126\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1581.8394\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1514.5009\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1416.9788\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1382.6375\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1343.2592\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1280.5215\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1189.6501\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1191.6251\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1056.8311\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1177.5574\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1047.8910\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1005.0029\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 926.3414\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 831.4478 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 863.4025  \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 853.6501 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 721.7815 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 710.9691 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 676.8400 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 675.3457 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 623007.5000\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 425616.5938\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 285489.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 196690.7812\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 129478.6250\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 83055.4922  \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 53864.2812 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33944.3320 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20554.2559 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12395.5830 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8397.9580\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5453.6821\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3677.8506\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2776.6580\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2475.7964\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2264.2061\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2073.8083\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1973.4407\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2000.7114\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2157.6208\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1890.6187\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2044.5594\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1858.5680\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1748.3351\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1931.5963\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1818.4365\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1676.2484\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1550.6962\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1563.7120\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1400.8137\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1382.1136\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1444.6779\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1401.1333\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1288.9576\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1290.1477\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1246.8109\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1133.4364\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1286.6989\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1119.3687\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1148.3268\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1101.8065\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1009.3571\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1050.3859\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1016.0206\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 876.2938 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 914.7740 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 859.2443 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 838.0686 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 857.2030  \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 811.9030 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 83305.0391\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25670.0605 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5143.4238\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2340.3066\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2102.2910\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2164.6997\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1991.3746\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1857.0276\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1764.4227\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1508.1224\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1348.8976\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1299.2061\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1284.0385\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1161.0470\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1053.2476\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 998.3560  \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1020.4109\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 842.5760 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 858.6157 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 770.9451 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 685.1962 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 699.6403 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 689.8896 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 704.1035 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 644.3109 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 641.4246\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 614.8949 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 577.7216 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 525.5121 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533.0203 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 511.0124 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 529.5981 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 478.6494 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 481.6773 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 472.8556 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 433.3286 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 407.6558 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 425.4268 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 396.1472 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 384.6570 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 390.7006 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 387.9526 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 364.4893 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 371.3064 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 347.3641 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 362.1022 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 316.1848 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 293.0934 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 327.6853 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 319.7707\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11647.7529\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4405.4536\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1860.1088\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1501.8646\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1251.5491\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1280.7965\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1153.1365\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1080.3401\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 959.3755 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 836.4892 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 854.6501 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 768.9676 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 745.9176 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 688.2129 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 649.9957 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 595.0042\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 594.0244 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 597.9036\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 532.3349 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 465.8847 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 433.3931 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 436.4203 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 453.0746 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 444.9476 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 415.9323\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 409.3462 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 365.1167 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 392.0596 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 398.5793 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 362.4922\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 347.8997\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 328.8595 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 336.4348\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 313.8978\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 319.1412 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 302.8255 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 316.8015 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 318.1357 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 297.1601 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 292.0703 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 299.4952 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 315.8478 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 297.4594\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 298.3852\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 312.5271 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 313.9523 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 290.6360\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 261.0666 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 293.3021 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 296.2892 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 560884.4375\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 343328.7188\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 195647.3281\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 106852.6875\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55288.5508 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25265.9297\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11763.9102 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5269.8213\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2880.3843\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1989.1420\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1796.5984\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1768.4360\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1756.1539\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1781.0304\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1667.5063\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1578.8777\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1610.2114\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1592.0795\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1599.3822\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1418.4031\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1302.5444\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1349.3353\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1325.3041\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1249.6552\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1334.2667\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1280.3561\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1125.7058\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1135.0029\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1090.6473\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1105.7242\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1162.2543\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1076.9551\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1079.0062\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1012.0188\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 949.5414 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 934.3088 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 879.0427\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 875.8486 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 852.7737 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 835.6769 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 774.2228 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 839.9789 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 753.2444 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 696.8307 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 715.5939 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 706.3936 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 670.5026 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 677.6051 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 640.4902 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 603.0742 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 10017.7656\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7158.4253\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5787.0415\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4748.5830\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3523.8801\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3370.8098\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2625.8127\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1975.0770\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1683.1476\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1295.5162\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1207.9882\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1015.8396\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 872.5807\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 764.4649 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 664.9051 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 533.4039\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 492.5359 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 433.7165 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 380.8160\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 326.8847\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 313.6750\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 262.5772 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 253.7310 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 219.0451\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 203.2819 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 174.5598 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 166.8777 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140.2901 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142.0565 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 138.5134 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 133.2858\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 128.2310\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 131.4641\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122.2259 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121.6309 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 120.2823 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117.7164 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110.6168\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 108.3525\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 117.8710\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 113.1862\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 108.7356\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 102.7726\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 107.9857 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 126.7854 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 101.3083\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 112.4958\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 120.5587\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 109.6042\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 106.7675\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 322162.2500\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 188323.3125\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 102658.8516\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51793.7891 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24972.3359\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12026.4883 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5688.6973\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3184.0146\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1877.3555\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1587.8479\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1203.8899\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1103.7732\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1097.9957\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1067.1763\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1037.7426\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 919.2345\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1162.1328\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1170.0372\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1041.6056\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 821.6016 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 985.0353 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 901.7123  \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 915.3653\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1027.7418\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 872.9548 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 895.9311  \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 946.2723 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1043.7762\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 772.3817 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 997.8658 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 803.5604 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 761.5336\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 666.9075 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 619.4648 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 719.0807 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 642.5588 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 733.2081 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 741.1370 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 710.1686 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 747.2090\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 663.0458 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 644.5162\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 549.6812\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 553.8245\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 649.1653 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 524.9027\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 563.7263 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 554.4209 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 486.1233 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 535.3661 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 2092.8691\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1033.3256\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 799.4351 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 725.6616 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 614.9742 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 601.3382 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 497.4787 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 459.3435 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 441.9675 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 468.7235 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 388.8650 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 370.1883 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 332.5749 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 325.3964 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 335.6464 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 320.8046 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 272.0851 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 275.0653\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 257.4899\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 233.4458 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 263.5387\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 227.8631\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 209.4660\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 202.1328\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 199.2036 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 188.8415\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 214.4891 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 174.1432 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 187.7146 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 191.9815 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 175.0534 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 179.8070 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162.4874 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 168.6663 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168.0064 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 158.1051\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145.1118 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 159.4470 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148.9465 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 155.7870 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143.2797 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146.4008 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137.5859\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137.1570 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146.2875 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148.6082 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135.0264 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137.5610 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126.5059 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129.3259\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 368967.5000\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 250764.8438\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153377.9844\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 88686.2031  \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43294.1953 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19091.6016 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8283.2422\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6563.3052\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5035.5825\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5159.4897\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4596.2129\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4583.2397\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4108.8730\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3734.5266\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3645.8928\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3609.4456\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3467.0259\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3141.0447\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2960.2109\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2843.5027\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2810.6067\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2651.6692\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2396.6833\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2146.5618\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2099.0588\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1959.6528\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1807.3809\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1595.2029\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1727.2710\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1558.1567\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1397.8987\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1269.3745\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1232.4337\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1110.9567\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1018.3629\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1063.4539\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 939.1895 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 830.8109\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 730.6188 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 724.0587\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 692.6198\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 610.0864\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 558.4508\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 493.0778 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 451.7071\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 415.9603\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 401.9751\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 348.0414\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 337.2868 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 331.0027 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 30090.9961\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6379.6177\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1456.2544\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1498.6630\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1351.3392\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1322.1135\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1360.9215\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1199.2479\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1204.5168\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1239.2061\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1138.6202\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1199.5065\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1207.2069\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 990.7004 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 903.4765 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1007.1946\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1006.9742\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 997.1735 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 906.7177 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 809.3345 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 784.8209 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 748.8303 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 694.6676 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 685.2543\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 675.3282\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 615.6591\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 539.7769 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 523.4575 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 528.0065 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 535.5657\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 478.1118 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 462.4626 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 429.5631 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 413.3651 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 397.3791 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 362.3693 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 329.2609 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 340.2864 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 313.1373 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 276.0050 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 275.9403 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 240.5603 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 245.8364 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 240.6469 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 220.7643 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 227.8423 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 194.3342 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 170.1146 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168.2657 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 174.0808 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 54751.1016\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35090.1250 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22451.2852 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12220.7812 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4893.0591\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1387.4880\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 541.9396 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 436.6669 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 375.8702 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 411.6025 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 400.6026\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 389.8610\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 387.3243 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 355.7013 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 341.3471\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 322.0425 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 306.8433 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 305.9180 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 313.9340 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 269.6898 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 264.4875 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 303.0414 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 261.8828 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 247.5571 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 265.1125\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 217.4690 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 232.5520 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 225.5318 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 230.1659 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 225.4915\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 207.1858 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 187.1277\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 192.7478 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 206.6988 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 194.1594 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 199.1847 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 177.7259 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 190.4823 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 172.6651 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169.5680 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 173.3957 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 183.5494\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163.0500 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 179.2170 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153.3067 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161.4379 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 166.0021 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 162.1426 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 148.7136\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156.7657 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 320705.7812\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 180843.9375\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 83121.4219  \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26578.0723 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6697.2886\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3769.3867\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3533.1172\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2931.2043\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2929.9712\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2529.7429\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2342.0264\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2184.8145\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1915.5110\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1678.6661\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1558.3431\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1287.9912\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1355.5360\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1211.8104\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1150.4408\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1071.7500\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 980.3329 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 935.7460  \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 873.2055 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 834.4692 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 829.1273 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 711.6254 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 686.3042\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 671.8807\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 636.2499 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 649.0075 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 554.4526 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 596.3653 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 546.7038 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 502.4795 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 497.5531 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 424.3455 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 453.2577 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 457.2969 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 397.5539 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 404.8531 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 399.8603 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 381.3880 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 409.2805 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 366.1699 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 356.3695 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 337.2261 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 343.0302 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 335.8977 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 305.9278 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 319.4208\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 14045.4912\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5383.9810\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4149.2104\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3012.7119\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2171.5811\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1659.1475\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1282.2074\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1328.4023\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1086.7938\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 969.6045 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 981.2880 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 815.7686  \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 721.1676\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 682.9893\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 597.5293\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 528.7241 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 480.9307\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 458.1303 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 446.3914 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 376.1616 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 362.5290\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 326.2756 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 274.0715 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 283.2206\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 258.4266\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 246.3685\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 232.7670 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 221.2310 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 204.1327 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 201.8886 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 185.3102 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 188.4302 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164.9005 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 186.6068 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168.9458 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158.0649 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162.7336 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 141.8588\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165.5191 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 159.8723 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151.2865 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139.6346 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138.3824\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143.7209 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148.2305 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130.7751 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138.1120 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144.7371 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 150.3292\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142.0289 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 66637.5391\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16307.6143 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4328.0083\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3450.8784\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3259.9006\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2917.9980\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2701.8562\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2290.4656\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1671.6370\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1421.5908\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1131.7882\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 940.3500 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 828.1985\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 775.1728 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 644.7648\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 584.3063 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 567.9134 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 494.3142 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 437.9822 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 413.7940 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 384.2975 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 364.2442 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 339.8498 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 285.5840 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 289.4258 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 276.4951 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 255.5948 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 239.5988 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 227.8844 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 230.4297 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 208.7211 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 207.4867\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 184.4491\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 184.5561 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165.3074 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164.6547 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 155.8562 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 175.5729 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 147.9907 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154.6004 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150.3357\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135.4095 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 136.0267\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135.9229 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126.4294 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129.5994 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 133.7687 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131.0701 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 132.3118\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119.3130\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12135.1250\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3073.9019\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1081.8978\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 568.7648  \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 437.4308\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 376.6321 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 388.0510\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 388.4797 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 312.7261 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 270.8043 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 287.5531\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 263.4612 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 241.1009\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 241.9864\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 234.6053\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 241.8404\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 227.0850\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 224.0474\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 222.7616 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 234.8105\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 225.7565\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 218.1737 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 197.5754\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 212.5396 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 210.1024\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 198.3148 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 194.0162\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 193.3503 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 191.8723\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 187.7565 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 191.9181 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 189.7853 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 177.7485 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 190.7366 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 177.3761 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 177.2758 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 170.6073 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 182.9204 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 171.5324 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 165.2607 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 170.4288 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161.5642 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150.5608 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 176.0044 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162.3792 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153.8432 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158.3976 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152.4701 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 147.6388\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143.3517 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 78347.2422\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25297.1152 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7259.5088\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3807.2227\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3222.2219\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2882.8250\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2703.8579\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2487.9885\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2300.5542\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2100.4919\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1932.6012\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1549.3676\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1475.2423\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1315.7157\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1211.3254\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 979.5836  \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 780.4767\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 743.6878\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 674.7156\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 601.2303 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 528.8325 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 547.3562 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 453.3163 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 394.9014 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 391.6556 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 352.3590 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 353.3902 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 325.2574 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 293.7253 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 267.2213\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 275.3801 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 260.6457 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 228.9354\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 241.8204 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 247.1266 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 232.2559\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 244.0061\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 243.5917 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 212.1089 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 208.7657\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 222.3689\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 196.5763\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 195.2630\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 198.9318\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 199.9524 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 190.8662\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 178.5905 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 177.8747 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 171.8187 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164.9772 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 79492.3672 \n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18790.7324\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4425.8457\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4323.3945\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3124.0342\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3017.4854\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3033.0120\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2926.7976\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2541.8381\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2095.7107\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2152.6643\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1921.5933\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1690.3951\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1790.5198\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1336.9946\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1394.4937\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1196.2825\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1117.0757\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 967.4178\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 982.8185 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 991.5759 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 827.3564\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 845.5466 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 693.6268\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 709.9739 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 608.4363\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 588.7638 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 504.3479 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 474.3147\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463.9368\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 443.8860\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 430.4567\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 397.1723\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 389.5249\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 379.4035\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 380.1997\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 347.0635\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 331.2819 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 317.5004\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 303.0337\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 279.9108\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 302.5966 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 288.5821\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 298.0048 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 261.7591\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 265.0407 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 257.1467 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 239.3696\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 249.5395\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 214.7266 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 80682.7266\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22255.9473 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8127.8599 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7002.7017\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6222.2412\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5409.0083\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5445.9951\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5071.2515\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4341.5869\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4134.2178\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4038.9670\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3613.0408\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3292.5400\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2901.3955\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2721.8372\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2350.5557\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2308.1272\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2231.4600\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2116.8157\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1899.7986\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1723.0416\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1605.4961\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1460.4539\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1503.4894\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1340.3516\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1206.0826\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1115.3866\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1058.0046\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 964.2346  \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 989.3813 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 901.6831 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 789.3547\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 771.1389 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 662.8354 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 649.3963 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 539.8859 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 537.0368 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 515.1776 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 497.6494\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 433.2759\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 398.1193 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 392.1132 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 386.8727 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 309.6159 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 342.5943\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 288.3979 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 282.5348 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 240.7069 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 261.2016 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 231.4795 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 261522.9219\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113934.9688\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34559.6250\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8756.4229\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7477.1421\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6782.9771\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6327.6953\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5680.9561\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5508.7759\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4874.9341\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4745.5728\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4049.4260\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3643.3491\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3433.1367\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3226.6611\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2555.1602\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2713.6648\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2280.2393\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2099.7148\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1775.7054\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1844.8063\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1603.5343\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1367.6647\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1300.6937\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1089.0354\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1051.6625\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 924.0881 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 940.1567 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 815.1854\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 754.3703\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 676.7111 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 621.9604\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 543.5009 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 544.8976\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 504.5414\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463.6217\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 448.3269\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 416.0652\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 408.7339\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 396.1014\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 360.7684\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 358.6501\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 282.7434\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 265.0031 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 267.1450 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 243.7041 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 251.5826 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 231.5407 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 222.8034 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 206.8665 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 30707.0312\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6431.6006\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3090.6780\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2676.4031\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1886.4188\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1403.2976\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1012.1459\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 935.1925 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 763.2524 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 570.8512 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 510.8234 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 458.1205 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 399.0570 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 345.2553 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 343.5165\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 314.8929 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 328.2666 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 273.2352 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 247.5022 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 272.1292 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 246.4423 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 244.1844 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 241.4786\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 241.3431 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 257.4406 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 244.6518 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 228.2282 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 216.5211\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 220.4422 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 213.7297 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 213.2764 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 189.6492 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 212.7570 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 193.6676 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 185.4862\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 201.9720\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 187.5177 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 185.3472 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 194.3032\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 179.9799 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160.0318 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161.3970\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162.0040 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169.0502 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 172.4788\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163.0838 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160.8504\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152.8670 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146.4865 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158.2373 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3608.1973\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1869.2369\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1349.5947\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 989.2828  \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 917.5394 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 753.3421 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 626.2409\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 582.1867\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 472.7448 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 427.5011 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 409.9683 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 415.7828\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 365.2764\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 359.6880\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 288.6725 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 289.4178\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 273.0365\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 263.9292\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 240.2423\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 250.2774\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 232.0949\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 204.9695 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 210.0992\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 196.1280\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 198.0554\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 200.5195 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 188.8964\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 187.0265\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173.1939\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 171.4141\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 180.7016\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154.4438\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 164.8921\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145.7413\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153.5645\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150.5497\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148.5309\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151.3220\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145.4960\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 133.5859\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129.8540\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143.7778\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134.3619\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137.2984\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127.5480\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139.3541\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129.0495\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 136.8787\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135.0617 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 123.7762 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 129663.4375\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 40078.6875 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6628.8330 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1668.0898\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1694.0465\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1455.6727\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1300.5847\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1334.2491\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1248.6588\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1265.0842\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1203.1278\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1176.6061\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1188.3290\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1077.1399\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1028.5996\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1004.4756\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 980.0899 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1016.1874\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 882.0561 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 868.1434 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 850.9949\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 797.5451 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 769.4703 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 773.5453 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 728.8016 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 696.9253 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 759.5558  \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 634.4329 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 652.4721 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 584.6543 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 590.8241 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 614.9531 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 577.4175 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 562.4261 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 512.2705 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 507.1186 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 479.4226 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 484.3007 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 500.7224 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 452.2669 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 453.0735 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 407.7076 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 388.5779 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 384.0023 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 378.8775 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 371.0463 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 348.2533 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 390.3273 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 365.9153 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 344.4833 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 29799.2930\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6806.0210\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 908.0416 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 499.9102\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 451.7378 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 437.7244\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 404.0046\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 340.2967\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 335.6778 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 315.2453 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 308.9770\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 275.0324\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 277.0001 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 313.6080\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 280.0215\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 239.0528\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 263.5708\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 233.1964\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 239.6411\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 219.3405\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 233.8880\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 215.3433\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 219.0209\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 197.7209\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 183.5340\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 188.2911\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 185.3875\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 197.4543\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 197.5703\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 180.6825\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 189.8552\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169.2575\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 190.2220\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173.8152\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 178.5944\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 188.1502\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168.2684\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163.1988\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 172.6094\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150.3658\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149.1548\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146.5560\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 165.5518\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156.3129\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 170.9623\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162.4762\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152.7145\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148.8550\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148.8033 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157.1776\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3242.0911\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1924.5138\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1066.0216\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 773.5031 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 652.3048 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488.5777 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 385.6224 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 346.4835\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 284.9960 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 261.7569\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 211.3997 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 199.6581 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173.6870 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162.0689 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144.2828 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 136.0189 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131.5514 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134.0864\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122.0302\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137.2718 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118.8641\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111.5484 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 128.1388 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118.5845 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 123.1363 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 107.1489\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.1827\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.5143\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.0263 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.3016\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109.9796 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118.4633\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109.4006\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 102.3403 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 108.0399 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110.6756\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122.4682\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.9355\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 106.9269 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.1284 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119.8430 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 103.7471\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111.5640\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120.5986 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 106.2391 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.1026 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 104.7057\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109.6294\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111.3765\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114.4618 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 12359.5127\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2003.0189\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1334.5538\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1084.6060\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 871.8475 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 727.0407\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 619.1118\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 625.5396 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 495.6330\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 446.8330\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 430.1050\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 337.4045\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 359.7878\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 325.1037\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 261.4747\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 257.4676\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 241.5687\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 217.3884\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 197.5526\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 192.7411\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 166.5017\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154.7988\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143.9823\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142.3567\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126.0382\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122.6527\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 124.1155\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119.3074\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114.3428\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 107.7146 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109.4590\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 108.4106\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109.1853\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 106.2786\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 103.2806\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 94.5066\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.8084 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.0394\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110.1753 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 105.6334 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 98.3884\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 94.9727\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 102.0217\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 95.2420\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 105.8166\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 89.8784\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 99.9366\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 104.4871\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 96.8903\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 105.6216\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 155728.4062\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 75136.1797\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27449.6406\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10022.3799 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6774.1890\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5974.3965\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6120.3779\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5605.8247\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5399.2939\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4920.8418\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4442.2651\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4067.4272\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3729.1697\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3792.9656\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3365.8533\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2948.2915\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3006.1650\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2557.1338\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2348.8921\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2233.0259\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1940.0848\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1862.8464\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1797.6865\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1749.7113\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1661.7582\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1484.9703\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1348.8120\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1237.8468\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1303.6301\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1114.6801\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1076.0087\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 940.3947 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 863.1289 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 827.9608\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 795.6703  \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 687.3203 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 650.8798\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 593.8945 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 583.1913\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 574.0501 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 541.9910 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 491.0435 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 479.8203\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 411.1362\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 430.8636 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 364.2379 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 341.5910 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 320.5751 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 319.9611 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 294.0763 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 282067.4688\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 101158.1094\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28027.8730 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12299.9912 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10944.4375 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9540.6426 \n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8057.3223\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7879.0239\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6872.0503\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5769.1074\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5685.1357\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4885.7534\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4600.5308\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4490.0576\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3769.2822\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3367.8257\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3131.1448\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3188.7913\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2729.0579\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2530.0408\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2307.4717\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2209.5483\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1996.5841\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1944.3687\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1943.2373\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1819.6960\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1666.8790\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1532.2435\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1557.8350\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1596.7927\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1378.0607\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1342.3892\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1261.4557\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1310.8308\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1210.2848\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1111.4340\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1092.6243\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1045.6801\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 969.1604\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 931.8126\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 899.5699\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 870.2675 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 780.4507 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 862.2433\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 760.1129 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 730.2433\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 735.5901\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 760.4561 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 685.3921 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 712.5950\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 210775.3438\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 94214.5156 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34671.7969 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8858.4268 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3750.3296\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2835.3008\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2619.5232\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2518.2249\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2363.1997\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2194.7100\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2206.1326\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2004.1746\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1676.9656\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1478.9218\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1512.3256\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1527.7137\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1259.6630\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1238.1554\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1125.1985\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1109.2550\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1057.5660\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 919.0953  \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 930.2675  \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 811.5800 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 784.6242  \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 775.6266 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 720.4216\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 777.1636 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 650.1174\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 616.9366 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 629.5215\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 606.3281\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 616.9919 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527.4017 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527.3555\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 525.0201\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 496.9157 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 489.6229 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 467.4154\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463.8339 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 475.0961 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 466.5072 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 400.7908 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 421.7086 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 432.8591 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 390.1722\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 378.6593 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 391.4124 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 384.3056 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 355.2921 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 32060.8008\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7780.8687\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6101.1807\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5173.6348\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5125.1279\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4691.1704\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3673.2671\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3219.7935\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2607.6582\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2204.8711\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2087.2607\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1695.1089\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1573.5592\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1261.1866\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1142.3820\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1033.9928\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 888.2219\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 780.3713\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 773.9579\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 756.5272 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 615.8582\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 582.6830\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 606.5055\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 535.1890\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 478.7383\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 465.2241\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 501.0941\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 479.4753\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 460.6312\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 448.1940\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 401.3504\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 414.4573\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 374.9847 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 366.2314\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 372.4160\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 369.9690 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 343.2643\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 317.0004\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 273.0709 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 344.0159 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 287.0395\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 246.6080\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 266.3231\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 282.7684\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 270.8216\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 256.2366\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 243.2886\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 256.9795 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 248.6511\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 248.5068\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3732.2554\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 877.4335  \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 584.8773 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 456.3721\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 374.1254\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 278.1316\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 242.9155\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 198.1662 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 191.2256 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 185.7082 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 188.6700\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167.1874\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151.8561 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152.0562\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149.8256 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143.4106\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150.8331 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139.9978 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137.6097\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146.2378 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135.6763 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151.8379 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121.3586 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130.5774 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142.6299 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142.8862 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120.0195 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 128.0266\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129.0766 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122.2813\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.5152 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131.9680 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127.5336 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118.6809 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 117.2329\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118.4495 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 106.4749\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125.4354\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 123.1293 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 108.7492\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117.9136\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110.4177 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111.9217\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122.3138 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 123.5082 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110.4152\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.7693\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.2146 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 106.7158\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120.8264 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 8060.3149\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2755.0461\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2244.8210\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1865.8140\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1730.8757\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1442.3608\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1247.0989\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1041.8314\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 918.7313 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 848.8443 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 670.2403 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 620.7596\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 535.5986\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 474.9034\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 429.3679\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 379.2602\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 334.2668\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 282.1863\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 273.4207\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 254.1629\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 209.4345\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 192.5556\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 183.6823\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 178.4171\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161.9573 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149.5935\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150.1704\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145.2778\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 136.2840\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129.0490\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 128.3593\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129.0501\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122.9482\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.5913\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114.6956\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.5783\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 107.3408 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110.7012\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119.1784\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.9961\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.1259\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112.8858\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.6463\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 104.6276\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 102.3665\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109.2608\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111.4468\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 106.5242\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.2213\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.5230\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 10728.0303\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2237.7444\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2110.8118\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1862.8511\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1481.2104\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1651.2783\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1138.2043\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 950.3179 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 726.9518 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 679.6348 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 621.3289 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 580.5400  \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 466.4345 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 376.5789 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 329.0819 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 319.9596 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 307.6630 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 317.7756 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 295.4496 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 258.7359 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 251.5270 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 239.3667 \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 218.7520 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 201.7108 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 206.7565 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 194.1843 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 195.0087 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 199.6309 \n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 208.8668 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 183.5354\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 180.6687 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 195.8573 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 181.6379 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173.3976 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 185.6192 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 170.4815 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169.4748 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156.8636 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162.7649 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 179.6524 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168.6667 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163.7503 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154.3601 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 160.6232 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158.2388 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163.3158 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140.2329\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158.1708\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 150.2860\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158.0048 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 1560.0640\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 769.4227 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 650.2548 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 564.7078 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 510.8011 \n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 451.3254\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 405.5055 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 406.3867 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 367.6963 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 305.5752 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 320.3498 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 302.6297 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 286.9472 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 292.3586 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 259.5549 \n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 244.4965 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 233.3445 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 257.6298 \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 244.4626 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 219.3314 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 218.2691 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 211.3961\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 184.4770\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 184.1645\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169.8077 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 174.6816\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 166.0694\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 161.9586\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 159.2807\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158.6785\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151.7254\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151.5480\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 146.2121\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139.8860\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149.4715\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144.1887\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144.8484\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134.8407\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142.7807\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141.7036 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130.8048\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139.5273\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 132.7864 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129.3684 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137.2574 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 136.7278 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130.9373 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 131.9993 \n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135.5977 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 133.4518 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 69384.5234\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9413.1914  \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3756.4822\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4026.4492\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3123.1299\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2689.9514\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2383.9958\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2386.2371\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2243.2119\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1653.7091\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1687.9731\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1547.9688\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1384.8501\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1341.2274\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1214.5510\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1140.8612\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1119.5145\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 954.5117  \n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 996.3109 \n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 826.5491 \n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 788.2401 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 736.7024  \n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 628.7700 \n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 583.9256 \n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 604.1850 \n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 491.8746 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 473.3697 \n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 444.7943\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 377.4737 \n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 349.9750 \n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 325.0936 \n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 343.4977 \n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 313.0818 \n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 318.9476 \n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 294.9701 \n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 266.7329 \n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 276.2929 \n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 278.4373 \n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 250.9361 \n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 281.9940 \n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 265.4515 \n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 247.9884 \n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 233.5357 \n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 240.2278 \n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 225.1170 \n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 245.8948 \n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 210.9641 \n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 210.9546\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 231.6487 \n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 226.4081 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 820.4731 \n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 553.3182 \n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 442.9520 \n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 391.8101 \n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 331.5493\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 309.9724\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 286.4982 \n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 246.8711 \n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 243.7531 \n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 220.3770 \n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 188.5805 \n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 204.6254 \n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 179.3049 \n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167.0045 \n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 153.5510\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 149.2867 \n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 130.4212 \n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137.2073\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 121.3335\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112.5229\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110.0861 \n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 97.9516\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 94.9065\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 105.9188\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 91.7275\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 98.7891 \n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 87.5905\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 84.0946\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 89.3020\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 83.5158\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 86.9767\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 79.6896\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 82.5996\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 74.8369\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 92.2887\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 88.2239\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 79.2205\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 75.4009\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 72.7873\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 73.9579\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 75.4730\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 80.4402\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 95.7711\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 73.1294\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 74.5303\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 73.1054\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 72.5896\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 71.9174\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 77.8537\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 71.6354\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 195.4864\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.1265\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.1369\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.7450\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.7971\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 184.9971\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.6198\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.8848\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.2800\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 55583.8047\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 24737.4590\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 10303.6133\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4484.7314\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2469.4692\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1833.1593\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1619.0312\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1516.6024\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1436.3087\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1363.9465\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1289.8165\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1222.4097\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1157.8678\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1098.1798\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1044.4586\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 991.8992\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 944.4233\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 899.0418\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 856.3539\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 816.5812\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 778.1198\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 743.3038\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 709.5226\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 678.0349\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 646.4836\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 617.0240\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 590.1562\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 562.2872\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 537.5319\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 512.9465\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 490.3064\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 469.0122\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 448.2514\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 429.1963\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 409.4016\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 392.5014\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 375.0661\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 360.4814\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 343.7713\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 329.7565\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 316.3385\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 303.4326\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 290.4470\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 278.8711\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 268.2427\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 257.3793\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 247.4074\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 238.3051\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 229.4916\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.8205\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 125283.0391\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 39011.9961\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 7605.3452\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2468.2791\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2086.8423\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1897.8655\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1746.3013\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1609.3082\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1476.8024\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1359.7435\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1260.7388\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1173.2386\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1093.5065\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1026.2974\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 951.8401\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 895.9115\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 838.8342\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 790.5164\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 741.7260\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 697.2722\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 656.5405\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 615.4159\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 577.5327\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 543.6865\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 515.8473\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 487.0963\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 463.7015\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 441.8817\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 421.8430\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 403.8188\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 385.5973\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 370.2223\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 355.7893\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 344.7630\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 331.3349\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 318.5394\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.7161\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 297.0022\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 286.9931\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 277.7814\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 269.0534\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 262.0051\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 253.1913\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 246.7560\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 239.6892\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 233.4345\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 226.9704\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.9779\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.0703\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 210.7674\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 3s 4ms/step - loss: 12625.1650\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 10030.2021\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 8065.5723\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6425.2983\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 4866.4805\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3242.0530\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2120.4553\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1471.2649\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1073.6545\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 756.9409\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 550.3776\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 427.4798\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 356.8592\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 298.6287\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 264.8290\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 246.8159\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 224.9442\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.4353\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 203.3499\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.7292\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.0437\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 179.1854\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 174.9226\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 169.2849\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.5419\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 170.6505\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 160.4728\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.9860\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 153.0738\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 154.2500\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.0624\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.7969\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.8817\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5031\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.4805\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 136.7478\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 135.1765\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 134.7484\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.4144\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.0550\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.0587\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.4239\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.1518\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.9619\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.7185\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.7970\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2548\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.4219\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.8074\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.8902\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 22601.0527\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2101.8430\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1674.7241\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1359.8499\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1189.1342\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1042.5892\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 909.2733\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 805.0887\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 712.5146\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 640.1479\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 579.1648\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 529.5468\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 490.4142\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 459.4897\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 434.2842\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 410.7221\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 392.6015\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 375.3965\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 360.7758\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 346.2092\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 335.3695\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 323.4358\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 312.9038\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 304.0631\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 294.0333\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 281.2805\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 274.7093\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 263.9821\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 259.1476\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 250.1104\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 235.8661\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 234.8682\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 224.4173\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 219.2393\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.9637\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 202.9915\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 195.2852\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 188.6807\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 181.2146\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.9064\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.2347\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 163.5591\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.0875\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.0490\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.4540\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.6544\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.6265\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.4447\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.6124\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 134.5120\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 1125261.8750\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 809296.9375\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 574637.0625\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 379287.6250\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209895.0156\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 102179.6641\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 45082.8320\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 18359.1543\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7872.4697\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4313.1099\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3346.3228\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3085.9172\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2999.5098\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2953.1631\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2899.0598\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2844.8442\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2792.0928\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2744.0159\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2693.9128\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2642.8706\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2594.5242\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2545.0962\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2496.9824\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2450.7190\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2401.8220\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2355.1116\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2309.9336\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2265.5225\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2221.3145\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2180.8250\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2135.9197\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2099.0413\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2053.5435\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2017.9714\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1979.3181\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1944.4069\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1908.8053\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1874.7761\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1840.4360\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1808.4418\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1776.1902\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1745.9019\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1718.1073\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1685.4960\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1657.2727\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1630.3040\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1603.3859\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1577.0540\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1553.1954\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1527.0676\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 7549.3262\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4487.6826\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3773.3003\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2496.0117\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1556.0214\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1107.8608\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 890.4734\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 762.6194\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 664.9025\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 601.0165\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 548.6841\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 506.9653\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 470.4088\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 431.6620\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 403.0029\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 383.3683\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 349.9891\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 328.0033\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 310.3185\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 284.9230\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 269.3373\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 252.1360\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 236.4270\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 218.9290\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 206.4193\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.1081\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 183.6430\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 172.8249\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.1173\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 157.2525\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 151.0762\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 146.7368\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 141.4271\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 134.9405\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 131.6390\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 127.0110\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.3090\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 122.7637\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.5175\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118.7945\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.4821\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.5802\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.0154\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 112.1308\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 110.9431\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 110.1622\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.5902\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.5866\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 108.4623\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 108.8753\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 19999.2559\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 10176.8057\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7587.1333\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 5095.5195\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3329.6252\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2168.0281\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1509.3109\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1071.8040\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 831.5590\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 699.3813\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 632.4992\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 587.2253\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 563.7095\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 543.8563\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 528.6308\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 516.8422\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 509.2059\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 499.8421\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 490.2045\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 495.0204\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 476.5843\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 471.2142\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 463.7813\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 448.7458\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 448.3009\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 447.1419\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 422.3508\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 409.9830\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 403.6679\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 399.0692\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 386.0367\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 376.8534\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 374.5228\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 360.3075\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 352.8669\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 347.2863\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 343.4332\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 330.8208\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 320.7438\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 318.3161\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 303.6102\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 295.6233\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 287.9428\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 275.9463\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 271.1829\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 255.7380\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 243.9299\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 232.9269\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 224.0642\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.9949\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 23836.3418\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 11182.0918\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 9790.1221\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 8880.0898\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 8090.0522\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7306.7324\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6643.7163\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6054.4863\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5545.9521\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5028.9570\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4588.3335\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4158.3286\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3762.4309\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3383.5295\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3029.0386\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2690.7156\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2382.7571\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2113.0608\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1865.9391\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1647.2881\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1442.6804\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1264.5270\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1113.0344\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 981.2164\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 861.1873\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 762.2917\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 675.2779\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 603.2032\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 539.0079\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 483.5826\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 435.6992\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 394.5573\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 360.7846\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 332.4722\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 304.7788\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 283.1294\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 262.5569\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 245.7747\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 228.9739\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 217.4746\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.0221\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.4604\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.4290\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.3129\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 170.7409\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.0525\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.7168\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8102\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.1240\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145.8186\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 441669.5938\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194757.5000\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 64767.4414\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 16476.7578\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6965.7686\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6163.2197\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5856.8213\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5569.5933\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5289.0938\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5023.3013\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4749.3174\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4498.6958\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4264.3330\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4025.6055\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3795.4949\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3578.0115\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3348.9844\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3073.2622\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2589.0923\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2120.6968\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1767.1267\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1436.5197\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1158.5000\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 959.3544\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 799.7084\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 676.6378\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 578.9185\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 505.4910\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 444.8553\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 395.8858\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 356.8250\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 326.2810\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 302.4719\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 284.2703\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 265.3962\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 257.8969\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 245.1576\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 240.6932\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 230.1726\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 227.8752\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 221.9156\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 218.6452\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 215.1626\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.2177\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.6264\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 208.2816\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.6408\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.9443\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.5762\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.3768\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 1946.7926\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1355.0781\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 865.6440\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 520.5475\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 363.0448\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 287.1335\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 242.9128\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 218.9944\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 204.7189\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.1782\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 175.4118\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 162.9874\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.4634\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.0005\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 140.3072\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 133.4343\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.8751\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.3237\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.4725\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.2415\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.1485\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 108.2814\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 105.9594\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.7888\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 106.0072\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 98.5609\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 98.6161\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 97.5987\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 95.7365\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 90.7196\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 92.3457\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 89.0909\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 90.5562\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 85.1559\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 87.3117\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 83.0478\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 82.1899\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 81.7393\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 82.1742\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 82.9493\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 78.8791\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 81.2658\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 78.9764\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 78.2183\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 74.5702\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 77.0626\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 74.8400\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 75.9552\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 74.2905\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 75.4655\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 10836.6973\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6977.3896\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4793.9512\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2955.0015\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1904.7738\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1373.5785\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1063.3679\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 848.4989\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 705.7231\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 602.1992\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 520.6647\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 450.6326\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 400.4606\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 353.7795\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 317.6439\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 287.7083\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 263.6071\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 243.3234\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 228.3152\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 213.2458\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 197.4385\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.6314\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.1190\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 183.0049\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.3047\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.0908\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.8189\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 152.3839\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 146.3960\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.8389\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 139.0334\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.8677\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.6074\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 129.2845\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.0857\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.1715\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 123.6470\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.1986\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.9500\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.3974\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.0925\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.4700\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.5103\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.3496\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 110.5839\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.7848\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.7292\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 110.9253\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 110.6589\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 107.1868\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 86208.1250\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 32185.8086\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 10204.5615\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4944.7827\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4245.4814\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4029.0757\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3813.3179\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3600.9087\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3392.8647\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3195.6436\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3003.6978\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2820.0728\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2646.3867\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2479.6636\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2326.0098\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2184.3066\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2042.0106\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1907.3951\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1791.7299\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1677.4814\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1563.9244\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1466.7740\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1375.0636\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1289.5809\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1209.8003\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1133.8734\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1067.9470\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 999.1722\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 939.1974\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 884.4536\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 832.2217\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 787.5107\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 741.4672\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 697.9198\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 659.1786\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 622.3859\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 589.0100\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 558.1813\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 529.9622\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 501.5971\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 475.5609\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 452.8060\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 428.1855\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 407.7615\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 389.2130\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 369.7745\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 351.7990\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 336.2738\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 319.2515\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 306.0346\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 17360.4004\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 6473.0415\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4491.9521\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3464.6550\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2863.8621\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2364.5935\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1941.5283\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1589.2231\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1294.4843\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1042.5315\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 829.7714\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 629.4059\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 487.1271\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 382.9254\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 309.9382\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 262.0535\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.1537\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.9176\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 180.9607\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 168.0610\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.6045\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.4350\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.5157\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.2042\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.5342\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.7661\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 125.5050\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.6354\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.3756\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.4908\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.0764\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.1819\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 112.0691\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 111.0552\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.9457\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 108.4442\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 108.0097\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 106.7278\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 107.0527\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 105.6321\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.3515\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 102.5947\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 101.8827\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 101.7986\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.7309\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 100.6443\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 100.7646\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 99.8624\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 98.1630\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 98.7497\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 446433.3438\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 306231.0625\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192926.8281\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 111652.6172\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 60177.7305\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 30994.9902\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 15704.8877\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 8506.0713\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5505.7534\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4358.8247\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3980.5435\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3837.4973\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3762.6956\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3706.8352\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3647.0298\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3593.4985\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3537.2803\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3480.7407\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3425.3088\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3369.9500\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3314.8416\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3262.1648\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3206.3369\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3155.9275\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3097.1033\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3043.5559\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2994.7610\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 2941.3323\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2891.2532\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2838.9480\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2788.9016\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2740.7324\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2694.0134\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2647.1367\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2598.4163\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2553.0542\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2509.8276\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2466.0410\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2422.0352\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2379.8147\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2336.3335\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2296.5601\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2256.6621\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2218.0476\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2177.8860\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2141.1042\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2102.5430\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2068.5876\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2031.0354\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1996.0165\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 212109.0938\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 118475.2734\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 63428.6719\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 31388.4824\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 14043.2539\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6500.2827\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4093.3538\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3503.2434\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3314.8093\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3164.3694\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3013.9380\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2877.3445\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2747.1221\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2626.5481\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2504.2844\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2390.9565\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2286.5642\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2183.5847\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2086.9260\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1994.6643\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1907.7163\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1828.3268\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1749.5647\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1671.7050\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1606.5065\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1532.8717\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1467.7227\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1400.8129\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1337.9158\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1277.3767\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1221.3953\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1166.7316\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1114.7185\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1066.4510\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1019.6125\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 975.6799\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 935.4954\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 899.7402\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 863.7120\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 831.9548\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 802.2735\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 773.2972\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 747.3757\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 722.8458\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 699.3820\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 678.2060\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 655.2816\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 636.1890\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 616.0808\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 597.9192\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 3741.2993\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2572.9172\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2201.0398\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1843.6162\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1503.4274\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1206.4161\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 989.2642\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 819.6628\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 715.8218\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 637.7278\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 578.7937\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 533.0668\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 494.4476\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 464.8956\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 438.7289\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 418.5859\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 402.7744\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 390.8206\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 379.5139\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 369.3416\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 360.2350\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 352.8688\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 344.2259\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 338.2605\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 330.8583\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 325.1880\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 319.3091\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 313.0380\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 309.9976\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 304.3898\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 299.8831\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 294.4766\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 289.5469\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 284.6665\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 280.5517\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 275.9060\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 271.2030\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 267.0349\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 263.4010\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 259.2369\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 256.7039\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 251.6741\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 248.4468\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 244.8379\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 241.8802\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 237.4599\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 234.1038\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 231.0572\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 227.8709\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 224.2373\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 1517.5911\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1166.6802\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 925.3905\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 733.1796\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 590.8279\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 501.3402\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 410.5291\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 355.5874\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 315.3436\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 274.2785\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 250.6728\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 225.9836\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 211.1508\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 192.5035\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.3554\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 174.8242\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 164.7093\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 158.2799\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149.5427\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 148.6525\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.3953\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.3363\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.6379\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.8911\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.1289\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.0111\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.3973\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.2938\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.7357\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.0607\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.4255\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.8772\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 112.8834\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.5197\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 112.4120\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 111.9854\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 108.4624\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.0472\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 111.1126\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.5703\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 106.5824\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 105.8424\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 110.7200\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 107.4222\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 107.0030\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 106.4246\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.9003\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 108.4305\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.4258\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 105.7090\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 241033.7812\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177424.7969\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 111045.1172\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 60109.7969\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 30912.3379\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 16283.9316\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 9897.8789\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7494.6406\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6785.2573\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6456.6587\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6287.5957\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6120.3511\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5965.0723\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5812.3711\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5651.2974\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5495.5117\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5339.8301\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5193.1846\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5038.9902\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4888.8105\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4746.8711\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4604.7231\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4467.2637\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 4332.2061\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4203.1323\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4069.5562\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3946.6155\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3827.6372\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3709.0974\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3589.5933\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3484.0457\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3373.7646\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3269.8933\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3168.2766\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3075.4785\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2976.6716\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2885.2090\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2793.9978\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2709.5142\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2627.7124\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2547.7031\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2468.3574\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2395.7627\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2323.4746\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2252.7114\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2188.0449\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2120.5415\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2061.2681\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1999.1989\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1942.1368\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 32290.5410\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 8110.2817\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5838.5547\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4636.7549\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3733.4036\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2937.4094\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2297.8364\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1820.3685\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1459.2784\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1212.5121\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1025.7375\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 894.1245\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 788.6019\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 713.2277\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 644.9717\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 587.8194\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 538.6061\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 495.5325\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 460.0889\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 426.6733\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 397.1875\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 373.8007\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 351.4579\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 330.9229\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 311.5133\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 292.3575\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 276.5744\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 262.8636\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 250.5724\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 238.1140\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 228.7233\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.5470\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.2831\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.1533\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 198.2746\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.7374\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.6521\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 182.5356\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 176.0825\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.5277\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.7828\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.4236\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.8983\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 154.8923\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.8293\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.4953\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.2743\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 142.1542\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 138.0977\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.5937\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 5ms/step - loss: 14257.6494\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3088.8704\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2200.2593\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1912.7698\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1684.1288\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1483.6691\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1310.6616\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1167.2378\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1034.3650\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 933.6497\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 852.9406\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 788.2877\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 737.1822\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 692.5801\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 653.9496\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 620.3298\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 597.1901\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 568.8618\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 546.2064\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 527.1856\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 507.7859\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 493.1793\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 477.9658\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 463.8389\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 451.3690\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 440.3342\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 429.5053\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 419.4400\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 407.8767\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 396.6783\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 386.3195\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 377.9585\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 368.1367\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 360.8057\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 351.3163\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 343.4426\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 336.2194\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 333.4404\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 325.1882\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 317.6210\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 312.1354\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.9036\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 301.8253\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 296.8205\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 292.6746\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 287.6116\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 282.6596\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 280.8149\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 276.0473\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 270.7370\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 3s 4ms/step - loss: 741244.3125\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 504591.7188\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 347350.9688\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 229031.0625\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 133440.5938\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 70509.6562\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 34727.8047\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 16022.5742\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7262.7158\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 3691.1414\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2421.6580\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2016.7991\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1884.5348\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1821.4884\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1777.5977\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1734.1500\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1692.1697\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1649.6028\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1608.9774\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1568.7412\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1523.9595\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1484.3064\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1441.9546\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1402.7480\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1363.9695\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1327.2227\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1288.0431\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1248.6383\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1212.2451\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1175.4661\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1139.8157\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1108.3662\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1070.8121\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1038.1117\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1006.4494\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 975.4897\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 943.5764\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 914.3784\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 885.2527\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 858.0138\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 829.7387\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 803.0253\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 777.6234\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 752.8453\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 730.6630\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 707.1565\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 684.3318\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 663.7776\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 641.1832\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 621.7078\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 5ms/step - loss: 26290.0801\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7553.8081\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6619.9336\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 6122.6392\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5675.9326\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5276.6567\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 4876.2422\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4522.7832\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4182.1870\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3854.0593\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3559.1487\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3266.1714\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 3007.7229\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2747.8586\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2527.1899\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2292.1160\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2123.7275\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1903.5969\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1723.3270\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 5ms/step - loss: 1545.0725\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1410.7399\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1257.5575\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1127.3318\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1012.3130\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 903.8940\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 815.1931\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 730.6457\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 652.8488\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 585.4880\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 531.7407\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 480.7994\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 436.3807\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 397.6735\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 366.8476\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 348.0776\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 319.5295\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 300.3695\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 278.6374\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 263.8427\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 253.0430\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 250.6905\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 234.4379\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 223.0859\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.4931\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 209.7799\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 205.0999\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 203.5492\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196.9943\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 194.6138\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 191.1311\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 2110079.0000\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1430635.6250\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 982536.2500\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 679031.9375\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 466914.5625\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 318612.3750\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216171.1250\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 145724.6094\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 97253.8672\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 64148.1602\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 42009.8789\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 27060.1660\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 17410.4902\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 11093.5439\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 7143.2817\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4693.7666\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3223.5151\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2345.4155\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1842.2871\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1552.5120\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1390.9495\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1296.1039\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1236.5880\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1198.5870\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1170.5200\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1147.6332\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1125.7935\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1105.7048\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1086.8317\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1067.4506\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1049.1420\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1030.1007\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1010.9336\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 992.1696\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 972.9452\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 954.6568\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 936.8129\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 918.7277\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 901.2070\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 883.5109\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 866.1933\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 849.0819\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 832.6958\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 816.1296\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 800.5404\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 784.9216\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 769.5060\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 754.4241\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 739.6733\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 725.3428\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 166930.6250\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 80685.3281\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 35259.4609\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 14397.4492\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6002.9863\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3102.6956\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2210.2908\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1965.5142\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1890.3710\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1842.8309\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1800.1517\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1758.3156\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1715.5824\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1673.7426\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1631.6588\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1591.7566\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1550.9353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1512.8528\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1476.0040\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1438.9760\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1402.8066\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1367.5826\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1334.4500\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1302.9851\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1269.8000\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1240.7714\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1212.6639\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1183.1228\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1154.3357\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1127.7124\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1102.7843\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1077.7474\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1054.0001\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1030.6393\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1009.7326\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 987.8989\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 967.7808\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 947.4924\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 928.9302\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 909.7217\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 892.3984\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 874.7195\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 855.8464\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 839.2484\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 822.5527\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 808.7889\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 790.9761\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 775.9673\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 761.5258\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 748.2940\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 5ms/step - loss: 1585.4553\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1094.4685\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 804.0493\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 632.4162\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 504.1748\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 405.6617\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 327.0668\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 259.2899\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 217.1363\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.9676\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 166.1142\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 147.3710\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.7961\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 128.1956\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.1160\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 117.7328\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.4773\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.4277\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 107.4896\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.8857\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 105.6633\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 103.2000\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 100.8240\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.6423\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 98.5265\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 94.7998\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 92.9602\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 91.8891\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 94.7816\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 91.2611\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 89.4263\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 86.8109\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 87.4133\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 85.5888\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 84.4134\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 81.6597\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 82.2027\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 80.3781\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 84.6616\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 82.5978\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 78.7875\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 77.3812\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 77.4570\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 75.5890\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 77.4220\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 73.8453\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 76.1319\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 72.1479\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 74.0424\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 72.4688\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 146147.2031\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 57811.7188\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 18934.3594\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5985.0547\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2904.3579\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2475.2903\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2404.3162\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2357.9722\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2311.8374\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2256.4084\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2200.0005\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2137.8530\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2066.4917\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2001.3890\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1932.7244\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 1870.4368\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1805.3365\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1743.4174\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1679.8894\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1621.0925\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1565.9679\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1512.1736\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1457.6560\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1404.8931\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1356.8041\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1310.3977\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1266.1101\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1220.8121\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1177.5708\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1137.6940\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1092.1780\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1052.2365\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1010.4918\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 970.3643\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 931.5767\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 895.8952\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 856.5168\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 821.7252\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 788.0124\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 752.4099\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 718.5768\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 687.5304\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 658.4763\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 626.3097\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 598.7700\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 569.5721\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 542.1182\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 516.6633\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 494.9073\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 471.3994\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 234741.4219\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 115325.6172\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 49954.2266\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 19408.5996\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6476.7095\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3646.6575\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3388.9082\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3185.8606\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3014.4153\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2865.5745\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2728.3462\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2598.5571\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2483.1260\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2368.0835\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2266.7563\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2165.2515\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2074.2312\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1982.1267\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1900.8107\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1820.4158\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1747.4021\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1675.1569\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1609.0103\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1541.3318\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1479.1973\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1421.4984\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1366.0118\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1313.8811\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1262.5991\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1216.2684\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1169.9901\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1125.7013\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1085.7285\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1044.0725\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1007.6505\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 971.8348\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 938.3329\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 906.7673\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 874.9658\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 845.1877\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 817.6151\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 791.0684\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 764.7399\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 740.6957\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 717.4510\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 694.9328\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 676.5530\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 651.2303\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 630.4380\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 610.3897\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 726352.9375\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 481227.9688\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 310683.4375\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 196099.3281\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120971.4297\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 72645.1328\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 42448.3477\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 24188.7656\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 13682.0518\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7872.5610\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4831.1914\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3322.4934\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 2609.2192\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2263.8591\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2107.1255\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2022.0409\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1968.7815\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1925.5029\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1886.4728\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1849.3143\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1811.4056\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1774.2101\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1736.5653\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1699.5116\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1661.8497\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1623.6641\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1586.5181\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1549.5255\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1513.2202\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1476.3749\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1440.3297\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1404.4945\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1369.8790\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1334.4105\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1299.7175\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1266.0758\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1232.5837\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1199.0043\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1166.9995\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1135.7550\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1103.5240\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1073.0342\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1043.9243\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1012.7322\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 985.5911\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 956.3222\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 927.8948\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 901.6401\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 874.9751\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 849.6145\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 524677.3750\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 313956.6875\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167728.3281\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 80204.9062\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 35084.9727\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 15534.7656\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 8955.0010\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7237.7339\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6826.0342\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6636.0396\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6461.1504\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6282.9507\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6104.4048\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5931.2017\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5760.0913\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5588.9565\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5415.2690\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5247.5630\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5086.9297\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4927.5884\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 4778.4829\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4622.2705\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4480.3384\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4337.5161\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4205.3320\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4077.2871\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 3947.4900\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3828.2451\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3719.7168\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3603.0693\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3499.0974\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3393.5164\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3296.8083\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3199.5576\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3109.3325\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3028.6321\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2944.3789\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2867.5867\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2800.7249\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2733.3965\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2655.3064\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2591.8652\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2539.3340\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2471.2292\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2419.7712\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2362.8469\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2311.3743\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2264.5444\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2214.1177\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2166.1504\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 1647.9021\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1236.7448\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1097.3425\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1013.1685\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 942.0532\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 864.6387\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 803.2812\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 750.8034\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 692.2418\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 651.0074\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 598.8667\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 551.3585\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 513.8533\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 486.9383\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 442.8506\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 413.2915\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 385.7175\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 361.8966\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 337.5861\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 312.1421\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 293.4742\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 272.8116\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 254.3604\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 239.0455\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 224.7452\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 212.8405\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 201.6869\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 188.0005\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 178.0861\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 167.4050\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.2074\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.0729\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 144.8931\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.1664\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.8153\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 127.0928\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 122.7769\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.8785\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.6229\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 111.1845\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.8093\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 108.5800\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.6570\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 103.5722\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 102.5269\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 102.0696\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 99.6510\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 99.5886\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 99.3862\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 100.9434\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 556412.6875\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 305085.5938\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 149901.4531\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 66263.7969\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 27248.9512\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 11973.9863\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7336.9287\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6054.7437\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5678.8184\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5445.0576\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5223.4116\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5011.8779\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4786.9487\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4584.0669\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4362.6533\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4157.1875\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3958.4429\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3759.6997\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 3566.9861\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 3388.1204\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3208.5569\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3040.8616\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2872.4131\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2717.9580\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2569.6853\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2427.2769\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2294.9426\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2173.5977\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2054.0901\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1936.9749\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1833.4745\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1735.3519\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1641.7881\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1552.6174\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1475.3635\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1397.2917\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1328.8813\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1264.1333\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1203.1646\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1147.5253\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1095.4569\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1048.8477\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1005.0291\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 961.9523\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 923.0601\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 886.8823\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 854.6706\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 823.9754\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 795.0149\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 766.7927\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 9435.8086\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 5925.5186\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4077.0405\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3099.5520\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2564.1135\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2241.8315\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2033.7433\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 1894.1385\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1794.4896\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1722.8948\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1674.1826\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1642.4497\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1619.4469\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1601.7987\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1587.3156\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1575.1390\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1564.8293\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1556.4241\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1548.7970\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1542.6835\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1538.1127\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1534.2360\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1531.1637\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1528.5020\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1526.0872\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1523.9469\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1521.9000\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1520.0131\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1518.2618\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1516.5251\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1514.8235\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1513.1873\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1511.5764\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1510.0190\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1508.4948\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1506.9933\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1505.4861\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1503.9933\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1502.5128\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1501.0078\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1499.5144\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1498.0358\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1496.5399\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1495.0411\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1493.5615\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1492.0701\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1490.5793\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1489.0890\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1487.5999\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1486.0857\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 8700.5078\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2661.5486\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1951.4163\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1731.4783\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1417.6434\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1145.3186\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1000.9486\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 894.1902\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 798.1227\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 704.3888\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 608.1990\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 532.0046\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 466.8228\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 411.6975\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 366.4407\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 323.8353\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 289.2743\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 257.6649\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 234.1187\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 220.2237\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 200.7930\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 187.9079\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 175.3758\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 165.6652\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.2833\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 151.8704\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 145.7322\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141.0211\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 137.3679\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 133.6282\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 130.2368\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 129.0189\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 126.0657\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 124.6230\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 124.7912\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.1818\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.0676\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.0772\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 118.1702\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.8739\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 116.0932\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 115.7931\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.0044\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.4023\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 113.0453\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 112.1668\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 111.8720\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 110.7502\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 110.6475\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 110.7326\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 1080300.7500\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 704883.6250\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 462469.7812\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 305393.4688\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 201460.3438\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 131564.1719\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 85168.7344\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 54694.4023\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 35016.5234\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 22285.3496\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 14075.9990\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 8948.2598\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5807.6924\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3974.0889\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2952.4414\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2413.0583\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2129.7693\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1978.0570\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1896.6635\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1843.7847\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1805.3466\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1773.8242\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1744.2723\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1716.8883\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1689.4240\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1664.4369\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1639.0004\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1613.8010\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1588.9774\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1564.4043\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1539.9397\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1516.3031\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1492.1295\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1469.4847\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1445.4132\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1423.1444\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1400.4160\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1378.3716\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1356.2015\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1333.7102\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1311.5272\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1290.0250\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1267.9783\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1246.5309\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1225.7780\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1204.2375\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1183.1394\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1162.3914\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1142.0769\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1121.5967\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 289641.5312\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120751.4141\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 43542.3828\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 15006.1084\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6607.2676\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4799.3530\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4400.5796\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4214.2417\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4037.0750\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3811.1826\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3552.1116\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3295.9458\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3010.1121\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2797.3269\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2673.0183\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2567.5349\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2458.9160\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2334.1702\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2204.3228\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2018.7843\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1857.7032\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1706.6324\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1564.4778\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1442.7815\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1331.4857\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1228.5282\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1139.9750\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1062.6326\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 992.8214\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 933.7061\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 866.5430\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 809.4687\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 760.3499\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 710.9690\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 663.5748\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 623.6636\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 584.8134\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 548.7856\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 515.7435\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 489.4457\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 457.6046\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 432.8177\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 408.1632\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 397.3946\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 368.2676\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 357.7552\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 339.6717\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 321.9016\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 307.9603\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 302.0301\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 715.0741\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 543.3290\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 407.0077\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 319.2950\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 257.9692\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 218.0217\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 185.8646\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 165.6931\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.7467\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 135.7120\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 127.8042\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 121.5149\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 118.6963\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 118.1457\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 112.6255\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 108.8157\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.7036\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 107.6851\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 112.9460\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 106.6489\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.2303\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.8170\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 108.1294\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 108.9483\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 121.6006\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 113.7800\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.8799\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 110.8227\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 106.6065\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 106.9882\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 105.6102\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 105.2471\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 106.8743\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 105.5658\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 103.9669\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 106.0598\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 104.6310\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 106.6504\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 105.8756\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.1888\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 104.5929\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.8121\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.3288\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.3401\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.7194\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 106.1190\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.4235\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 104.4280\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.0729\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 107.6739\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 612042.5000\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 419291.2188\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 264197.8438\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 141012.8594\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 57703.9492\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 18458.6328\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6088.4805\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3657.2029\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3318.9214\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3162.4834\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 3016.1277\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 2861.0010\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2721.4077\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2574.9990\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2441.0249\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2312.4424\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2195.5881\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2071.1926\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1958.3193\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1852.9811\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1749.5165\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1658.8722\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1567.6484\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1488.4320\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1409.2537\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1335.0995\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1264.9741\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1203.4600\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1143.4215\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1088.8198\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1037.4872\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 992.6675\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 947.5153\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 906.8962\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 870.0774\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 834.4880\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 802.5947\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 771.9529\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 744.1952\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 720.0104\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 695.8226\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 674.8778\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 653.6668\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 635.6124\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 618.7534\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 601.4127\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 587.0723\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 573.4564\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 559.0638\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 547.3374\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 2s 4ms/step - loss: 15172.5654\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5810.3198\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2221.3120\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1230.3987\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1044.4171\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 994.4976\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 949.2028\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 901.6852\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 855.0113\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 808.6555\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 767.3231\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 728.2899\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 690.4292\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 655.2853\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 625.0979\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 597.2814\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 568.4039\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 542.6182\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 517.3433\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 494.4724\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 472.5674\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 449.4939\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 429.2181\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 409.7306\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 390.7602\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 373.0658\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 357.6350\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 339.3445\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 324.0284\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 308.0814\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 293.7199\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 280.2609\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 268.6339\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 256.7874\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 245.9826\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 235.5635\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 226.0015\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.6980\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 207.9426\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 200.6033\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 193.3609\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 186.5148\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 180.2406\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 173.6851\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 168.0836\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 162.3258\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.9450\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 153.3058\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 148.2269\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 143.8472\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 726543.1250\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 431943.5938\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 239273.5000\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 120896.2578\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 56573.4375\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 26042.2891\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 13744.6377\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 9958.2773\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 8870.0391\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 8532.6777\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 8365.6582\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 8217.1416\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 8076.6353\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7929.7246\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7783.6021\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7634.3042\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7485.1177\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7358.1929\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7188.6455\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7048.0259\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6905.2358\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6762.0728\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6623.1235\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 6481.6680\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6357.3652\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6212.4404\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6081.2407\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5955.4985\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5816.4961\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5701.6123\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5575.7998\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5449.7495\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5323.1567\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5210.5161\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5092.1401\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4976.9302\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4863.1587\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4761.3804\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4650.2510\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4548.0991\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4444.7295\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4339.3989\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4237.3545\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4142.1392\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4047.9429\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3958.9111\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3868.1987\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3776.8225\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 3692.5266\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3605.1738\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 4ms/step - loss: 148577.7812\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 88775.1094\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 40359.1797\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 14013.9482\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7222.8892\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6426.5825\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5756.1948\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5195.6514\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4672.2236\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4191.7344\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3734.3728\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3266.3232\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2850.4495\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2454.8354\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 2060.1135\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1645.7487\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1317.6173\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1082.7521\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 923.8626\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 812.5859\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 735.5322\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 681.0485\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 636.7197\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 601.0352\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 571.6570\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 547.1486\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 525.6489\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 507.0744\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 487.4452\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 471.3533\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 453.7425\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 437.7472\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 424.3296\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 410.1746\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 396.0997\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 384.5451\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 372.7276\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 362.0782\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 351.0507\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 341.4194\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 331.3770\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 322.1960\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 313.8444\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 306.9771\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 298.1756\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 290.5117\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 284.0454\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 278.0298\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 270.6486\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 264.8799\n",
      "10/10 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "mse_A = []\n",
    "r2_A = []\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    #Split Data to Train and Test Set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #Compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    #fit the model\n",
    "    model.fit(X_train, y_train, epochs=50)\n",
    "\n",
    "    #predict output on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse_A.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_A.append(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_Mean: 289.64\n",
      "mse_StdDev: 288.95\n"
     ]
    }
   ],
   "source": [
    "print('mse_Mean: {:.2f}'.format(np.mean(mse_A)))\n",
    "print('mse_StdDev: {:.2f}'.format(np.std(mse_A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2_Mean: -0.05\n",
      "R^2_StdDev: 1.07\n"
     ]
    }
   ],
   "source": [
    "print('R^2_Mean: {:.2f}'.format(np.mean(r2_A)))\n",
    "print('R^2_StdDev: {:.2f}'.format(np.std(r2_A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><font color=\"red\">B. MODEL WITH NORMALIZED DATA</font></strong>\n",
    "\n",
    "<strong>Network Properties:</strong>\n",
    "<ul>\n",
    "  <li>Hidden Layer: 1</li>\n",
    "  <li>Nodes: 10</li>\n",
    "  <li>Activation Function: ReLU</li>\n",
    "  <li>Optimizer: Adam</li>\n",
    "  <li>Loss Function: Mean Squared Error</li>\n",
    "  <li>Epochs: 50</li>\n",
    "</ul>\n",
    "\n",
    "Model is retrain with normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm = (X - X.mean()) / X.std()\n",
    "X_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "mse_B = []\n",
    "r2_B = []\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    #Split Data to Train and Test Set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size = 0.3)\n",
    "\n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #Compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    #fit the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "\n",
    "    #predict output on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse_B.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_B.append(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_Mean: 369.15\n",
      "mse_StdDev: 95.88\n"
     ]
    }
   ],
   "source": [
    "print('mse_Mean: {:.2f}'.format(np.mean(mse_B)))\n",
    "print('mse_StdDev: {:.2f}'.format(np.std(mse_B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2_Mean: -0.33\n",
      "R^2_StdDev: 0.36\n"
     ]
    }
   ],
   "source": [
    "print('R^2_Mean: {:.2f}'.format(np.mean(r2_B)))\n",
    "print('R^2_StdDev: {:.2f}'.format(np.std(r2_B)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><font color=\"red\">C. MODEL WITH 100 EPOCHS</font></strong>\n",
    "\n",
    "<strong>Network Properties:</strong>\n",
    "<ul>\n",
    "  <li>Hidden Layer: 1</li>\n",
    "  <li>Nodes: 10</li>\n",
    "  <li>Activation Function: ReLU</li>\n",
    "  <li>Optimizer: Adam</li>\n",
    "  <li>Loss Function: Mean Squared Error</li>\n",
    "  <li>Epochs: 100</li>\n",
    "</ul>\n",
    "\n",
    "Model is retrained with 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    }
   ],
   "source": [
    "mse_C = []\n",
    "r2_C = []\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    #Split Data to Train and Test Set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size = 0.3)\n",
    "\n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #Compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    #fit the model\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "\n",
    "    #predict output on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse_C.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_C.append(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_Mean: 166.82\n",
      "mse_StdDev: 22.64\n"
     ]
    }
   ],
   "source": [
    "print('mse_Mean: {:.2f}'.format(np.mean(mse_C)))\n",
    "print('mse_StdDev: {:.2f}'.format(np.std(mse_C)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2_Mean: 0.39\n",
      "R^2_StdDev: 0.09\n"
     ]
    }
   ],
   "source": [
    "print('R^2_Mean: {:.2f}'.format(np.mean(r2_C)))\n",
    "print('R^2_StdDev: {:.2f}'.format(np.std(r2_C)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><font color=\"red\">D. MODEL WITH 3 HIDDEN LAYERS</font></strong>\n",
    "\n",
    "<strong>Network Properties:</strong>\n",
    "<ul>\n",
    "  <li>Hidden Layers: 3</li>\n",
    "  <li>Nodes: 10</li>\n",
    "  <li>Activation Function: ReLU</li>\n",
    "  <li>Optimizer: Adam</li>\n",
    "  <li>Loss Function: Mean Squared Error</li>\n",
    "  <li>Epochs: 100</li>\n",
    "</ul>\n",
    "\n",
    "Model is retrained with 3 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    }
   ],
   "source": [
    "mse_D = []\n",
    "r2_D = []\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    #Split Data to Train and Test Set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size = 0.3)\n",
    "\n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #Compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    #fit the model\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "\n",
    "    #predict output on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse_D.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_D.append(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_Mean: 95.76\n",
      "mse_StdDev: 22.17\n"
     ]
    }
   ],
   "source": [
    "print('mse_Mean: {:.2f}'.format(np.mean(mse_D)))\n",
    "print('mse_StdDev: {:.2f}'.format(np.std(mse_D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2_Mean: 0.66\n",
      "R^2_StdDev: 0.08\n"
     ]
    }
   ],
   "source": [
    "print('R^2_Mean: {:.2f}'.format(np.mean(r2_D)))\n",
    "print('R^2_StdDev: {:.2f}'.format(np.std(r2_D)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. iNTERPRET - Analyze and Interpret Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing all evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>STEPS</td><td>MSE: Mean</td><td>MSE: StdDev</td><td>R^2: Mean</td><td>R^2: StdDev</td></tr>\n",
       "<tr><td>A    </td><td>289.64   </td><td>288.95     </td><td>-0.05    </td><td>1.07       </td></tr>\n",
       "<tr><td>B    </td><td>369.15   </td><td>95.88      </td><td>-0.33    </td><td>0.36       </td></tr>\n",
       "<tr><td>C    </td><td>166.82   </td><td>22.64      </td><td>0.39     </td><td>0.09       </td></tr>\n",
       "<tr><td>D    </td><td>95.76    </td><td>22.17      </td><td>0.66     </td><td>0.08       </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "tabletest = [['STEPS','MSE: Mean','MSE: StdDev','R^2: Mean','R^2: StdDev'],\n",
    "         ['A', round(np.mean(mse_A),2), round(np.std(mse_A),2), round(np.mean(r2_A),2), round(np.std(r2_A),2)],\n",
    "         ['B', round(np.mean(mse_B),2), round(np.std(mse_B),2), round(np.mean(r2_B),2), round(np.std(r2_B),2)],\n",
    "         ['C', round(np.mean(mse_C),2), round(np.std(mse_C),2), round(np.mean(r2_C),2), round(np.std(r2_C),2)],\n",
    "         ['D', round(np.mean(mse_D),2), round(np.std(mse_D),2), round(np.mean(r2_D),2), round(np.std(r2_D),2)]]\n",
    "\n",
    "display(HTML(tabulate.tabulate(tabletest, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>From the results above, we can clearly see that by applying:</strong>\n",
    "<ul>\n",
    "  <li>Data Normalization,</li>\n",
    "  <li>Increasing Epochs,</li>\n",
    "  <li>and Increasing Hidden Layers</li>\n",
    "</ul>\n",
    "\n",
    "<strong>the mean of MSE has gone down, while the mean of R^2 has gone up indicating that the model accuracy is getting better.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
